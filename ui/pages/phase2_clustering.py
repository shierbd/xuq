"""
Phase 2: å¤§ç»„èšç±»é¡µé¢
"""
import streamlit as st
import subprocess
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from storage.repository import PhraseRepository, ClusterMetaRepository
from storage.models import Phrase


def render():
    st.markdown('<div class="main-header">ğŸ”„ Phase 2: å¤§ç»„èšç±»</div>', unsafe_allow_html=True)

    st.markdown("""
    ### åŠŸèƒ½è¯´æ˜

    ä½¿ç”¨HDBSCANç®—æ³•å¯¹æ‰€æœ‰çŸ­è¯­è¿›è¡Œè¯­ä¹‰èšç±»ï¼Œç”Ÿæˆ60-100ä¸ªå¤§ç»„ã€‚

    **ç®—æ³•**: HDBSCAN (Hierarchical Density-Based Spatial Clustering)
    **Embeddingæ¨¡å‹**: all-MiniLM-L6-v2 (384ç»´)

    **è¾“å‡º**:
    - `phrases.cluster_id_A` æ›´æ–°
    - `cluster_meta` è¡¨å¡«å……ï¼ˆLevel Aï¼‰
    - Embeddingç¼“å­˜æ–‡ä»¶
    """)

    st.markdown("---")

    # é…ç½®åŒºåŸŸ
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### âš™ï¸ èšç±»å‚æ•°")

        min_cluster_size = st.slider(
            "æœ€å°èšç±»å¤§å° (min_cluster_size)",
            min_value=10,
            max_value=100,
            value=30,
            step=5,
            help="ç°‡å¿…é¡»åŒ…å«çš„æœ€å°çŸ­è¯­æ•°ã€‚å¢å¤§æ­¤å€¼ä¼šå¾—åˆ°æ›´å°‘ã€æ›´å¤§çš„ç°‡"
        )

        min_samples = st.slider(
            "æœ€å°æ ·æœ¬æ•° (min_samples)",
            min_value=1,
            max_value=10,
            value=3,
            help="æ ¸å¿ƒç‚¹çš„æœ€å°é‚»å±…æ•°ã€‚å¢å¤§æ­¤å€¼ä¼šå¾—åˆ°æ›´ç´§å¯†çš„ç°‡"
        )

        st.markdown("### ğŸ’¾ ç¼“å­˜é€‰é¡¹")

        use_cache = st.checkbox(
            "ä½¿ç”¨Embeddingç¼“å­˜",
            value=True,
            help="å¦‚æœå­˜åœ¨ç¼“å­˜æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½è€Œä¸é‡æ–°è®¡ç®—"
        )

        force_recalculate = st.checkbox(
            "å¼ºåˆ¶é‡æ–°è®¡ç®—Embeddings",
            value=False,
            help="å¿½ç•¥ç¼“å­˜ï¼Œé‡æ–°è®¡ç®—æ‰€æœ‰Embeddings"
        )

        st.markdown("### ğŸ§ª æµ‹è¯•é€‰é¡¹")

        use_test_limit = st.checkbox("ä½¿ç”¨æµ‹è¯•é™åˆ¶", value=False)

        test_limit = 0
        if use_test_limit:
            test_limit = st.number_input(
                "æµ‹è¯•çŸ­è¯­æ•°é‡",
                min_value=100,
                max_value=10000,
                value=1000,
                step=100
            )

    with col2:
        st.markdown("### ğŸ“Š å½“å‰çŠ¶æ€")

        try:
            with PhraseRepository() as repo:
                stats = repo.get_statistics()
                total_phrases = stats.get('total_count', 0)
                st.metric("çŸ­è¯­æ€»æ•°", f"{total_phrases:,}")

                # è®¡ç®—æœªèšç±»çš„çŸ­è¯­æ•°
                unclustered = repo.session.query(Phrase).filter(
                    Phrase.cluster_id_A.is_(None)
                ).count()
                st.metric("æœªèšç±»çŸ­è¯­", f"{unclustered:,}")

            with ClusterMetaRepository() as cluster_repo:
                clusters_A = cluster_repo.get_all_clusters('A')
                st.metric("å·²æœ‰å¤§ç»„æ•°", len(clusters_A))

                if clusters_A:
                    st.markdown("**ç°æœ‰å¤§ç»„ç»Ÿè®¡:**")
                    sizes = [c.size for c in clusters_A]
                    st.text(f"  å¹³å‡å¤§å°: {sum(sizes)//len(sizes):,}")
                    st.text(f"  æœ€å¤§: {max(sizes):,}")
                    st.text(f"  æœ€å°: {min(sizes):,}")

            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
            cache_dir = project_root / "data" / "cache"
            cache_files = list(cache_dir.glob("embeddings_round*.npz")) if cache_dir.exists() else []

            st.markdown("**Embeddingç¼“å­˜:**")
            if cache_files:
                st.success(f"âœ… æ‰¾åˆ° {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶")
                for cache_file in cache_files:
                    st.text(f"  {cache_file.name}")
            else:
                st.warning("âš ï¸ æ— ç¼“å­˜æ–‡ä»¶ï¼Œéœ€è¦è®¡ç®—Embeddings")

        except Exception as e:
            st.error(f"æ— æ³•è·å–çŠ¶æ€: {str(e)}")

    st.markdown("---")

    # å‚æ•°é¢„è§ˆ
    st.markdown("### ğŸ¯ å½“å‰é…ç½®é¢„è§ˆ")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.info(f"**æœ€å°èšç±»å¤§å°**: {min_cluster_size}")
    with col2:
        st.info(f"**æœ€å°æ ·æœ¬æ•°**: {min_samples}")
    with col3:
        st.info(f"**ä½¿ç”¨ç¼“å­˜**: {'æ˜¯' if use_cache and not force_recalculate else 'å¦'}")

    # é¢„æœŸç»“æœæç¤º
    st.markdown("""
    **é¢„æœŸç»“æœ**:
    - èšç±»å¤ªå¤šï¼ˆ>100ä¸ªï¼‰â†’ å¢å¤§ `min_cluster_size` å’Œ `min_samples`
    - èšç±»å¤ªå°‘ï¼ˆ<40ä¸ªï¼‰â†’ å‡å° `min_cluster_size` å’Œ `min_samples`
    - å™ªéŸ³ç‚¹è¿‡å¤šï¼ˆ>40%ï¼‰â†’ å‡å° `min_samples`
    """)

    st.markdown("---")

    # æ“ä½œæŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 2])

    with col1:
        start_button = st.button("ğŸš€ å¼€å§‹èšç±»", type="primary", use_container_width=True)

    with col2:
        if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€", use_container_width=True):
            st.rerun()

    # æ‰§è¡Œèšç±»
    if start_button:
        st.markdown("### ğŸ“ æ‰§è¡Œæ—¥å¿—")

        # æ„å»ºå‘½ä»¤
        script_path = project_root / "scripts" / "run_phase2_clustering.py"

        cmd = [
            sys.executable,
            str(script_path),
            f"--min-cluster-size={min_cluster_size}",
            f"--min-samples={min_samples}"
        ]

        if use_cache and not force_recalculate:
            cmd.append("--use-cache")

        if force_recalculate:
            cmd.append("--force-recalculate")

        if use_test_limit:
            cmd.append(f"--test-limit={test_limit}")

        # æ˜¾ç¤ºå‘½ä»¤
        st.code(" ".join(cmd), language="bash")

        # æ‰§è¡Œ
        with st.spinner("æ­£åœ¨æ‰§è¡Œèšç±»ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."):
            try:
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                    universal_newlines=True
                )

                # åˆ›å»ºæ—¥å¿—è¾“å‡ºåŒºåŸŸ
                log_container = st.empty()
                log_lines = []

                # å®æ—¶è¯»å–è¾“å‡º
                for line in process.stdout:
                    log_lines.append(line.strip())
                    log_container.text_area(
                        "è¾“å‡ºæ—¥å¿—",
                        "\n".join(log_lines[-50:]),
                        height=400
                    )

                process.wait()

                if process.returncode == 0:
                    st.success("âœ… Phase 2 èšç±»å®Œæˆï¼")
                    st.balloons()

                    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
                    with ClusterMetaRepository() as cluster_repo:
                        clusters_A = cluster_repo.get_all_clusters('A')
                        st.metric("ç”Ÿæˆå¤§ç»„æ•°", len(clusters_A))

                        sizes = [c.size for c in clusters_A]
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("å¹³å‡å¤§å°", f"{sum(sizes)//len(sizes):,}")
                        with col2:
                            st.metric("æœ€å¤§ç»„", f"{max(sizes):,}")
                        with col3:
                            st.metric("æœ€å°ç»„", f"{min(sizes):,}")

                    st.info("ğŸ“Š ä¸‹ä¸€æ­¥: å‰å¾€ Phase 3 è¿›è¡Œäººå·¥ç­›é€‰")
                else:
                    st.error(f"âŒ èšç±»å¤±è´¥ï¼Œé€€å‡ºä»£ç : {process.returncode}")

            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}")

    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### èšç±»æµç¨‹

        1. **åŠ è½½æ•°æ®**: ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰çŸ­è¯­
        2. **è®¡ç®—Embeddings**: ä½¿ç”¨Sentence Transformeræ¨¡å‹ï¼ˆå¯ç¼“å­˜ï¼‰
        3. **HDBSCANèšç±»**: åŸºäºå¯†åº¦çš„å±‚æ¬¡èšç±»
        4. **ä¿å­˜ç»“æœ**: æ›´æ–°æ•°æ®åº“å’Œç”ŸæˆCSVæŠ¥å‘Š

        ### å‚æ•°è°ƒæ•´å»ºè®®

        **min_cluster_size** (æœ€å°èšç±»å¤§å°):
        - é»˜è®¤: 30
        - å¢å¤§ â†’ æ›´å°‘ã€æ›´å¤§çš„ç°‡ï¼ˆé€‚åˆæ•°æ®é‡å¤§æ—¶ï¼‰
        - å‡å° â†’ æ›´å¤šã€æ›´å°çš„ç°‡ï¼ˆé€‚åˆå‘ç°ç»†ç²’åº¦æ¨¡å¼ï¼‰

        **min_samples** (æœ€å°æ ·æœ¬æ•°):
        - é»˜è®¤: 3
        - å¢å¤§ â†’ æ›´ç´§å¯†ã€æ›´ä¿å®ˆçš„ç°‡ï¼ˆå™ªéŸ³ç‚¹æ›´å¤šï¼‰
        - å‡å° â†’ æ›´æ¾æ•£ã€æ›´æ¿€è¿›çš„ç°‡ï¼ˆå™ªéŸ³ç‚¹æ›´å°‘ï¼‰

        ### æ€§èƒ½ä¼˜åŒ–

        - **é¦–æ¬¡è¿è¡Œ**: éœ€è¦è®¡ç®—Embeddingsï¼Œæ—¶é—´è¾ƒé•¿ï¼ˆ5ä¸‡æ¡çº¦éœ€5-10åˆ†é’Ÿï¼‰
        - **åç»­è¿è¡Œ**: ä½¿ç”¨ç¼“å­˜ï¼Œä»…éœ€èšç±»è®¡ç®—ï¼ˆ5ä¸‡æ¡çº¦éœ€1-2åˆ†é’Ÿï¼‰
        - **æµ‹è¯•æ¨¡å¼**: ä½¿ç”¨1000æ¡æ•°æ®å¿«é€ŸéªŒè¯å‚æ•°æ•ˆæœ

        ### è¾“å‡ºæ–‡ä»¶

        - `data/output/clusters_levelA.csv` - å¤§ç»„èšç±»æŠ¥å‘Š
        - `data/cache/embeddings_round1.npz` - Embeddingsç¼“å­˜
        """)

    # æ•…éšœæ’æŸ¥
    with st.expander("ğŸ”§ æ•…éšœæ’æŸ¥"):
        st.markdown("""
        ### å¸¸è§é—®é¢˜

        **Q: å†…å­˜ä¸è¶³ (MemoryError)**
        - ä½¿ç”¨æµ‹è¯•é™åˆ¶å…ˆè¿è¡Œå°æ•°æ®é‡
        - å‡å° `EMBEDDING_BATCH_SIZE`ï¼ˆåœ¨ config/settings.pyï¼‰
        - å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº

        **Q: èšç±»ç»“æœä¸ç†æƒ³**
        - ç°‡å¤ªå¤šï¼ˆ>100ï¼‰: å¢å¤§ min_cluster_size åˆ° 40-50
        - ç°‡å¤ªå°‘ï¼ˆ<40ï¼‰: å‡å° min_cluster_size åˆ° 20-25
        - å™ªéŸ³ç‚¹å¤ªå¤šï¼ˆ>50%ï¼‰: å‡å° min_samples åˆ° 2

        **Q: Embeddingè®¡ç®—å¾ˆæ…¢**
        - é¦–æ¬¡è®¡ç®—æ˜¯æ­£å¸¸çš„ï¼ˆä¸€æ¬¡æ€§ï¼‰
        - ç¡®ä¿å‹¾é€‰"ä½¿ç”¨Embeddingç¼“å­˜"
        - è€ƒè™‘ä½¿ç”¨GPUåŠ é€Ÿï¼ˆéœ€å®‰è£…torch-cudaï¼‰

        **Q: ç¼“å­˜æ–‡ä»¶æŸå**
        - å‹¾é€‰"å¼ºåˆ¶é‡æ–°è®¡ç®—Embeddings"
        - æˆ–æ‰‹åŠ¨åˆ é™¤ `data/cache/` ç›®å½•ä¸‹çš„ç¼“å­˜æ–‡ä»¶
        """)
