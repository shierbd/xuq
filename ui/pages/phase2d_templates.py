"""
Phase 2D: Template Discovery Results Viewer
å±•ç¤ºæ•°æ®é©±åŠ¨å‘ç°çš„æœç´¢æ¨¡æ¿å’Œäº§å“å®ä½“
"""
import streamlit as st
import json
from pathlib import Path
from typing import Dict, List

# é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent.parent


def load_templates() -> Dict:
    """åŠ è½½å‘ç°çš„æ¨¡æ¿"""
    file_path = project_root / 'outputs' / 'discovered_templates.json'
    if file_path.exists():
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []


def load_products() -> Dict:
    """åŠ è½½è¯†åˆ«çš„äº§å“"""
    file_path = project_root / 'outputs' / 'product_entities.json'
    if file_path.exists():
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def load_variables() -> Dict:
    """åŠ è½½å˜é‡æå–ç»“æœ"""
    file_path = project_root / 'outputs' / 'variable_extraction_results.json'
    if file_path.exists():
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def load_detailed_matches() -> Dict:
    """åŠ è½½è¯¦ç»†åŒ¹é…æ•°æ®"""
    file_path = project_root / 'outputs' / 'detailed_matches.json'
    if file_path.exists():
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {'total_matches': 0, 'matches': []}


def load_all_phrases() -> List[Dict]:
    """åŠ è½½æ‰€æœ‰åŸå§‹çŸ­è¯­æ•°æ®"""
    from storage.repository import PhraseRepository
    from storage.models import Phrase

    try:
        with PhraseRepository() as repo:
            phrases = repo.session.query(Phrase).all()
            return [{
                'phrase': p.phrase,
                'volume': p.volume,
                'source': p.source,
                'status': p.status
            } for p in phrases]
    except Exception as e:
        st.error(f"åŠ è½½åŸå§‹æ•°æ®å¤±è´¥: {str(e)}")
        return []


def render_page():
    """æ¸²æŸ“é¡µé¢"""
    st.title("ğŸ“Š Phase 2D: æ•°æ®é©±åŠ¨çš„æ¨¡æ¿å‘ç°ä¸äº§å“æå–")
    st.markdown("---")

    # åŠ è½½æ•°æ®
    templates = load_templates()
    products_data = load_products()
    variables_data = load_variables()
    detailed_data = load_detailed_matches()  # æ–°å¢ï¼šåŠ è½½è¯¦ç»†åŒ¹é…æ•°æ®

    # æ¦‚è§ˆç»Ÿè®¡
    st.header("ğŸ¯ æ•°æ®æ¦‚è§ˆ")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "å‘ç°çš„æ¨¡æ¿æ•°",
            len(templates),
            help="é«˜é¢‘æœç´¢æ¨¡æ¿ï¼ˆä»125KçŸ­è¯­ä¸­è‡ªç„¶æ¶Œç°ï¼‰"
        )

    with col2:
        total_vars = variables_data.get('statistics', {}).get('unique_variables', 0) if variables_data else 0
        valid_vars = len(variables_data.get('top_variables', [])) if variables_data else 0
        st.metric(
            "æœ‰æ•ˆå˜é‡æ•°",
            f"{valid_vars}/{total_vars}",
            help="é€šè¿‡äº¤å‰éªŒè¯çš„é«˜è´¨é‡å˜é‡"
        )

    with col3:
        total_products = products_data.get('total_products', 0)
        st.metric(
            "è¯†åˆ«çš„äº§å“æ•°",
            total_products,
            help="DeepSeek AIè¯†åˆ«çš„çœŸå®äº§å“/å·¥å…·"
        )

    with col4:
        high_value = products_data.get('statistics', {}).get('high_value_products', 0)
        st.metric(
            "é«˜ä»·å€¼äº§å“æ•°",
            high_value,
            help="å•†ä¸šä»·å€¼â‰¥70çš„äº§å“"
        )

    st.markdown("---")

    # TabåŒºåŸŸ
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ” å‘ç°çš„æ¨¡æ¿",
        "ğŸ è¯†åˆ«çš„äº§å“",
        "ğŸ“ˆ æå–ç»Ÿè®¡",
        "ğŸ“‹ è¯¦ç»†æ•°æ®"  # æ–°å¢Tab
    ])

    # Tab 1: æ¨¡æ¿å±•ç¤º
    with tab1:
        st.header("å‘ç°çš„æœç´¢æ¨¡æ¿")
        st.markdown("*è¿™äº›æ¨¡æ¿æ˜¯ä»æ•°æ®ä¸­å‘ç°çš„ï¼Œå¹¶éé¢„è®¾ï¼*")

        if not templates:
            st.warning("æœªæ‰¾åˆ°æ¨¡æ¿æ•°æ®ã€‚è¯·å…ˆè¿è¡Œ `python core/template_discovery.py`")
        else:
            # ç­›é€‰å™¨
            col1, col2 = st.columns([1, 1])
            with col1:
                min_freq = st.slider(
                    "æœ€å°é¢‘æ¬¡",
                    min_value=1,
                    max_value=max(t['match_count'] for t in templates),
                    value=10
                )

            # è¿‡æ»¤æ¨¡æ¿
            filtered_templates = [t for t in templates if t['match_count'] >= min_freq]

            st.markdown(f"**æ˜¾ç¤º {len(filtered_templates)} ä¸ªæ¨¡æ¿ï¼ˆé¢‘æ¬¡ >= {min_freq}ï¼‰**")

            # å±•ç¤ºæ¨¡æ¿
            for i, template in enumerate(filtered_templates, 1):
                with st.expander(
                    f"**{i}. {template['template_pattern']}** - "
                    f"ï¼ˆå‡ºç° {template['match_count']} æ¬¡ï¼‰",
                    expanded=(i <= 5)
                ):
                    st.markdown(f"**é”šç‚¹è¯**: `{template['anchor']}`")
                    st.markdown(f"**é¢‘æ¬¡**: {template['match_count']} æ¬¡")

                    st.markdown("**ç¤ºä¾‹çŸ­è¯­**:")
                    for j, example in enumerate(template['example_phrases'][:5], 1):
                        st.text(f"  {j}. {example}")

    # Tab 2: äº§å“å±•ç¤º
    with tab2:
        st.header("DeepSeek AIè¯†åˆ«çš„äº§å“")

        if not products_data or products_data.get('total_products', 0) == 0:
            st.warning("æœªæ‰¾åˆ°äº§å“æ•°æ®ã€‚è¯·å…ˆè¿è¡Œ `python core/product_identifier.py`")
        else:
            products = products_data.get('products', [])

            # ç»Ÿè®¡ä¿¡æ¯
            st.markdown(f"**äº§å“æ€»æ•°**: {len(products)}")
            st.markdown(f"**å¹³å‡å•†ä¸šä»·å€¼**: {products_data['statistics']['avg_commercial_value']:.1f}/100")

            # ç±»åˆ«åˆ†å¸ƒ
            categories = products_data['statistics']['categories']
            if categories:
                st.markdown("**ç±»åˆ«åˆ†å¸ƒ**:")
                for category, count in categories.items():
                    st.text(f"  â€¢ {category}: {count} ä¸ªäº§å“")

            st.markdown("---")

            # ç­›é€‰å™¨
            col1, col2 = st.columns([1, 1])
            with col1:
                selected_category = st.selectbox(
                    "æŒ‰ç±»åˆ«ç­›é€‰",
                    ["å…¨éƒ¨"] + list(categories.keys())
                )

            with col2:
                min_value = st.slider(
                    "æœ€ä½å•†ä¸šä»·å€¼",
                    min_value=0,
                    max_value=100,
                    value=0
                )

            # è¿‡æ»¤äº§å“
            filtered_products = products
            if selected_category != "å…¨éƒ¨":
                filtered_products = [p for p in filtered_products if p['category'] == selected_category]
            filtered_products = [p for p in filtered_products if p['commercial_value'] >= min_value]

            st.markdown(f"**æ˜¾ç¤º {len(filtered_products)} ä¸ªäº§å“**")

            # å±•ç¤ºäº§å“
            for i, product in enumerate(filtered_products, 1):
                with st.container():
                    st.markdown(f"### {i}. {product['product_name']}")

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ç±»åˆ«", product['category'])
                    with col2:
                        st.metric("å•†ä¸šä»·å€¼", f"{product['commercial_value']}/100")
                    with col3:
                        st.metric("é¢‘æ¬¡", product['frequency'])

                    st.markdown(f"**æè¿°**: {product['description']}")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.text(f"æ¨¡æ¿åŒ¹é…æ•°: {product['template_match_count']}")
                    with col2:
                        if product['total_volume'] > 0:
                            st.text(f"æ€»æœç´¢é‡: {product['total_volume']:,}")

                    st.markdown("---")

    # Tab 3: ç»Ÿè®¡ä¿¡æ¯
    with tab3:
        st.header("æå–ç»Ÿè®¡")

        # æ¨¡æ¿ç»Ÿè®¡
        if templates:
            st.subheader("ğŸ“Š æ¨¡æ¿å‘ç°ç»Ÿè®¡")

            col1, col2 = st.columns(2)
            with col1:
                st.metric("å‘ç°çš„æ¨¡æ¿æ€»æ•°", len(templates))
                st.metric("æœ€é«˜é¢‘æ¬¡", max(t['match_count'] for t in templates))

            with col2:
                total_matches = sum(t['match_count'] for t in templates)
                st.metric("æ¨¡æ¿åŒ¹é…æ€»æ¬¡æ•°", total_matches)
                st.metric("å¹³å‡é¢‘æ¬¡", f"{total_matches/len(templates):.1f}")

            # é¢‘æ¬¡åˆ†å¸ƒ
            st.markdown("**é¢‘æ¬¡åˆ†å¸ƒ**:")
            freq_bins = {"1-10": 0, "11-50": 0, "51-100": 0, "100+": 0}
            for t in templates:
                freq = t['match_count']
                if freq <= 10:
                    freq_bins["1-10"] += 1
                elif freq <= 50:
                    freq_bins["11-50"] += 1
                elif freq <= 100:
                    freq_bins["51-100"] += 1
                else:
                    freq_bins["100+"] += 1

            for bin_range, count in freq_bins.items():
                st.text(f"  {bin_range} æ¬¡å‡ºç°: {count} ä¸ªæ¨¡æ¿")

        st.markdown("---")

        # å˜é‡ç»Ÿè®¡
        if variables_data:
            st.subheader("ğŸ“Š å˜é‡æå–ç»Ÿè®¡")
            stats = variables_data.get('statistics', {})

            col1, col2 = st.columns(2)
            with col1:
                st.metric("çŸ­è¯­åŒ¹é…æ€»æ•°", stats.get('total_matches', 0))
                st.metric("æå–çš„å”¯ä¸€å˜é‡æ•°", stats.get('unique_variables', 0))

            with col2:
                st.metric("æœ‰æ•ˆå˜é‡æ•°ï¼ˆäº¤å‰éªŒè¯ï¼‰", len(variables_data.get('top_variables', [])))
                retention = len(variables_data.get('top_variables', [])) / max(stats.get('unique_variables', 1), 1) * 100
                st.metric("ä¿ç•™ç‡", f"{retention:.1f}%")

        st.markdown("---")

        # äº§å“ç»Ÿè®¡
        if products_data and products_data.get('total_products', 0) > 0:
            st.subheader("ğŸ“Š äº§å“è¯†åˆ«ç»Ÿè®¡")

            col1, col2 = st.columns(2)
            with col1:
                st.metric("è¯†åˆ«çš„äº§å“æ€»æ•°", products_data['total_products'])
                st.metric("å¹³å‡å•†ä¸šä»·å€¼", f"{products_data['statistics']['avg_commercial_value']:.1f}")

            with col2:
                st.metric("é«˜ä»·å€¼äº§å“ï¼ˆâ‰¥70ï¼‰", products_data['statistics']['high_value_products'])

            st.markdown("**ç±»åˆ«åˆ†å¸ƒ**:")
            for category, count in products_data['statistics']['categories'].items():
                st.text(f"  â€¢ {category}: {count} ä¸ªäº§å“")

    # Tab 4: è¯¦ç»†æ•°æ®å±•ç¤ºï¼ˆè¡¨æ ¼å½¢å¼ï¼‰
    with tab4:
        st.header("ğŸ“‹ æ•°æ®è¡¨æ ¼è§†å›¾")

        # æ•°æ®è§†å›¾é€‰æ‹©
        data_view = st.radio(
            "é€‰æ‹©æ•°æ®è§†å›¾",
            ["æ¨¡æ¿åŒ¹é…æ•°æ® (3,513æ¡)", "å…¨éƒ¨åŸå§‹æ•°æ® (125,315æ¡)"],
            horizontal=True
        )

        st.markdown("---")

        if data_view == "æ¨¡æ¿åŒ¹é…æ•°æ® (3,513æ¡)":
            # æ˜¾ç¤ºåŒ¹é…æ•°æ®
            if not detailed_data['matches']:
                st.warning("æœªæ‰¾åˆ°è¯¦ç»†åŒ¹é…æ•°æ®ã€‚è¯·å…ˆè¿è¡Œ `python core/variable_extractor.py`")
            else:
                matches = detailed_data['matches']

                st.markdown(f"**æ•°æ®è¯´æ˜**: ä»125,315æ¡åŸå§‹çŸ­è¯­ä¸­åŒ¹é…åˆ°25ä¸ªæ¨¡æ¿çš„{len(matches)}æ¡æ•°æ®")
                st.markdown("---")

                # ç­›é€‰å™¨
                st.subheader("ğŸ” ç­›é€‰æ¡ä»¶")

                col1, col2, col3 = st.columns(3)

                with col1:
                    # æŒ‰æ¨¡æ¿ç­›é€‰
                    all_templates = sorted(set(m['template_pattern'] for m in matches))
                    selected_templates = st.multiselect(
                        "æŒ‰æ¨¡æ¿ç­›é€‰ (å¯å¤šé€‰)",
                        ["å…¨éƒ¨"] + all_templates,
                        default=["å…¨éƒ¨"]
                    )

                with col2:
                    # æŒ‰å…³é”®è¯ç­›é€‰
                    keyword_filter = st.text_input(
                        "æŒ‰å…³é”®è¯ç­›é€‰",
                        placeholder="è¾“å…¥å…³é”®è¯...",
                        help="æ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼Œå¤§å°å†™ä¸æ•æ„Ÿ"
                    )

                with col3:
                    # æŒ‰é¢‘æ¬¡ç­›é€‰
                    min_volume = st.number_input(
                        "æœ€ä½æœç´¢é‡",
                        min_value=0,
                        value=0
                    )

                # åº”ç”¨ç­›é€‰
                filtered_matches = matches

                # ç­›é€‰1: æ¨¡æ¿
                if "å…¨éƒ¨" not in selected_templates and selected_templates:
                    filtered_matches = [m for m in filtered_matches if m['template_pattern'] in selected_templates]

                # ç­›é€‰2: å…³é”®è¯
                if keyword_filter:
                    filtered_matches = [m for m in filtered_matches if keyword_filter.lower() in m['phrase_lower']]

                # ç­›é€‰3: é¢‘æ¬¡
                if min_volume > 0:
                    filtered_matches = [m for m in filtered_matches if m['volume'] >= min_volume]

                st.markdown(f"**ç­›é€‰åæ•°æ®é‡**: {len(filtered_matches)} æ¡")
                st.markdown("---")

                # è½¬æ¢ä¸ºDataFrameæ ¼å¼
                import pandas as pd

                table_data = []
                for i, match in enumerate(filtered_matches, 1):
                    # æå–ç¬¬ä¸€ä¸ªå˜é‡
                    first_var = list(match['variables'].values())[0] if match['variables'] else ''

                    # å˜é‡ä½ç½®ä¿¡æ¯
                    var_pos_str = ''
                    if match.get('variable_positions'):
                        var_pos_str = ', '.join([f"{v[2]}:[{v[0]}:{v[1]}]" for v in match['variable_positions']])

                    table_data.append({
                        'åºå·': i,
                        'åŸå§‹çŸ­è¯­': match['phrase'],
                        'æœç´¢é‡': match['volume'],
                        'æ¨¡æ¿': match['template_pattern'],
                        'é”šç‚¹': match['template_anchor'],
                        'æå–å˜é‡': first_var,
                        'å‰ç¼€': match.get('prefix', ''),
                        'åç¼€': match.get('suffix', ''),
                        'å˜é‡ä½ç½®': var_pos_str
                    })

                df = pd.DataFrame(table_data)

                # æ˜¾ç¤ºè¡¨æ ¼ï¼ˆæ”¯æŒæ’åºã€æœç´¢ï¼‰
                st.dataframe(
                    df,
                    use_container_width=True,
                    height=600,
                    hide_index=True
                )

                # ä¸‹è½½æŒ‰é’®
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å½“å‰ç­›é€‰ç»“æœä¸ºCSV",
                    data=csv,
                    file_name="template_matches.csv",
                    mime="text/csv"
                )

        else:
            # æ˜¾ç¤ºå…¨éƒ¨åŸå§‹æ•°æ®
            st.markdown(f"**æ•°æ®è¯´æ˜**: æ‰€æœ‰125,315æ¡åŸå§‹çŸ­è¯­æ•°æ®")
            st.markdown("---")

            # åŠ è½½åŸå§‹æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
            with st.spinner("æ­£åœ¨åŠ è½½å…¨éƒ¨åŸå§‹æ•°æ®..."):
                all_phrases = load_all_phrases()

            if not all_phrases:
                st.error("æ— æ³•åŠ è½½åŸå§‹æ•°æ®")
            else:
                st.markdown(f"**æ•°æ®æ€»é‡**: {len(all_phrases):,} æ¡")

                # ç­›é€‰å™¨
                st.subheader("ğŸ” ç­›é€‰æ¡ä»¶")

                col1, col2 = st.columns(2)

                with col1:
                    keyword_filter = st.text_input(
                        "æŒ‰å…³é”®è¯ç­›é€‰çŸ­è¯­",
                        placeholder="è¾“å…¥å…³é”®è¯...",
                        key="all_phrases_keyword"
                    )

                with col2:
                    min_volume_all = st.number_input(
                        "æœ€ä½æœç´¢é‡",
                        min_value=0,
                        value=0,
                        key="all_phrases_volume"
                    )

                # åº”ç”¨ç­›é€‰
                filtered_phrases = all_phrases

                if keyword_filter:
                    filtered_phrases = [p for p in filtered_phrases if keyword_filter.lower() in p['phrase'].lower()]

                if min_volume_all > 0:
                    filtered_phrases = [p for p in filtered_phrases if p['volume'] >= min_volume_all]

                st.markdown(f"**ç­›é€‰åæ•°æ®é‡**: {len(filtered_phrases):,} æ¡")
                st.markdown("---")

                # è½¬æ¢ä¸ºDataFrame
                import pandas as pd

                df_all = pd.DataFrame(filtered_phrases)
                df_all.insert(0, 'åºå·', range(1, len(df_all) + 1))

                # é‡å‘½ååˆ—ä¸ºä¸­æ–‡
                df_all = df_all.rename(columns={
                    'phrase': 'åŸå§‹çŸ­è¯­',
                    'volume': 'æœç´¢é‡',
                    'source': 'æ¥æº',
                    'status': 'çŠ¶æ€'
                })

                # æ˜¾ç¤ºè¡¨æ ¼
                st.dataframe(
                    df_all,
                    use_container_width=True,
                    height=600,
                    hide_index=True
                )

                # ä¸‹è½½æŒ‰é’®
                csv_all = df_all.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å½“å‰ç­›é€‰ç»“æœä¸ºCSV",
                    data=csv_all,
                    file_name="all_phrases.csv",
                    mime="text/csv"
                )

    # æ•°æ®æºä¿¡æ¯
    st.markdown("---")
    st.info("""
    **æ•°æ®é©±åŠ¨çš„æ–¹æ³•è®º**:
    1. å¯¹125,315ä¸ªçŸ­è¯­è¿›è¡ŒN-gramé¢‘æ¬¡åˆ†æ
    2. ä»é«˜é¢‘æ¨¡å¼ä¸­å‘ç°æ¨¡æ¿ï¼ˆP75é˜ˆå€¼ï¼‰
    3. ä½¿ç”¨å‘ç°çš„æ¨¡æ¿æå–å˜é‡
    4. äº¤å‰éªŒè¯ï¼ˆå˜é‡å¿…é¡»åŒ¹é…â‰¥2ä¸ªæ¨¡æ¿ï¼‰
    5. ä½¿ç”¨DeepSeek AIè¿›è¡Œäº§å“è¯†åˆ«

    **è¯¦ç»†æ•°æ®Tabè¯´æ˜**:
    - å±•ç¤ºæ‰€æœ‰3,513æ¡åŒ¹é…æ•°æ®
    - æ”¯æŒæŒ‰æ¨¡æ¿ã€å…³é”®è¯ã€æœç´¢é‡ç­›é€‰
    - å®Œæ•´æ˜¾ç¤ºï¼šåŸå§‹çŸ­è¯­ã€æ¨¡æ¿ã€å‰ç¼€ã€åç¼€ã€å˜é‡ä½ç½®
    - æ”¯æŒåˆ†é¡µæµè§ˆ
    """)


if __name__ == "__main__":
    render_page()
