"""
Phase 2E: å›è¨€æ–¹æ³• - é•¿å°¾å˜é‡æå–
UIç•Œé¢å®ç°
"""
import streamlit as st
import json
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from storage.repository import PhraseRepository
from storage.models import Phrase
from storage.word_segment_repository import WordSegmentRepository
from core.junyan_method import (
    JunyanTemplateExtractor,
    JunyanVariableExtractor,
    JunyanQualityAnalyzer
)
from utils.keyword_segmentation import segment_keywords
from collections import Counter


def load_all_phrases():
    """åŠ è½½æ‰€æœ‰çŸ­è¯­æ•°æ®"""
    try:
        with PhraseRepository() as repo:
            phrases_db = repo.session.query(Phrase).all()
            return [p.phrase for p in phrases_db]
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
        return []


def render():
    """æ¸²æŸ“å›è¨€æ–¹æ³•é¡µé¢"""
    st.title("ğŸ¯ Phase 2E: å›è¨€æ–¹æ³• - é•¿å°¾å˜é‡æå–")

    st.markdown("""
    ### ğŸ’¡ å›è¨€æ–¹æ³•æ ¸å¿ƒæ€è·¯

    åŸºäºç”¨æˆ·æœç´¢ç‰¹å¾çš„**æ¨¡æ¿-å˜é‡åŒå‘æå–æ³•**ï¼š

    1. **æ­¥éª¤1ï¼šæå–æ¨¡æ¿** â† ä»å°‘é‡ç§å­è¯ä¸­å‘ç°æœç´¢æ¨¡æ¿
    2. **æ­¥éª¤2ï¼šæå–å˜é‡** â† ç”¨æ¨¡æ¿ä»å¤§é‡æ•°æ®ä¸­æå–å˜é‡
    3. **è´¨é‡åˆ†æ** â† åˆ†æé¦–å­—/æœ«å­—ï¼Œè¯†åˆ«è„æ•°æ®
    4. **å¾ªç¯è¿­ä»£** â† å˜é‡å¯ä½œä¸ºæ–°ç§å­è¯ï¼Œé‡å¤æ­¥éª¤1

    **æ ¸å¿ƒåŸåˆ™**ï¼š
    - ç§å­è¯è¦**äººå·¥æŒ‘é€‰**ï¼Œç¡®ä¿åœ¨ç›®æ ‡åœºæ™¯ä¸‹ä¸€å®šæ­£ç¡®
    - æ¨¡æ¿è¦**äººå·¥ç­›é€‰**ï¼Œç¡®ä¿{X}ä½ç½®å¤§æ¦‚ç‡æ˜¯ç›®æ ‡æ•°æ®
    - äº¤å‰éªŒè¯ï¼šå˜é‡èƒ½åŒ¹é…å¤šä¸ªæ¨¡æ¿ = è´¨é‡é«˜
    """)

    st.markdown("---")

    # åŠ è½½æ•°æ®
    if 'junyan_phrases' not in st.session_state:
        with st.spinner("æ­£åœ¨åŠ è½½çŸ­è¯­æ•°æ®..."):
            st.session_state.junyan_phrases = load_all_phrases()

    phrases = st.session_state.junyan_phrases
    st.info(f"ğŸ“Š å½“å‰æ•°æ®é‡: {len(phrases):,} æ¡çŸ­è¯­")

    # TabåŒºåŸŸ
    tab0, tab1, tab2, tab3 = st.tabs([
        "ğŸ” æ­¥éª¤0ï¼šè·å–ç§å­è¯",
        "ğŸ“ æ­¥éª¤1ï¼šæå–æ¨¡æ¿",
        "ğŸ¯ æ­¥éª¤2ï¼šæå–å˜é‡",
        "ğŸ“Š è´¨é‡åˆ†æ"
    ])

    # ========================================================================
    # Tab 0: è·å–ç§å­è¯ï¼ˆé€šè¿‡åˆ†è¯ï¼‰
    # ========================================================================
    with tab0:
        st.header("ğŸ” æ­¥éª¤0ï¼šä»é•¿å°¾è¯åˆ†è¯è·å–ç§å­è¯")

        st.markdown("""
        **æ“ä½œè¯´æ˜**ï¼š
        1. ç³»ç»Ÿä¼šå¯¹æ‰€æœ‰é•¿å°¾è¯è¿›è¡Œè‡ªåŠ¨åˆ†è¯
        2. ç»Ÿè®¡è¯é¢‘ï¼Œå±•ç¤ºé«˜é¢‘è¯æ±‡
        3. **äººå·¥ç­›é€‰**ï¼šå‹¾é€‰ç¡®å®šæ­£ç¡®çš„è¯ä½œä¸ºç§å­è¯
        4. è‡ªåŠ¨å¡«å……åˆ°ã€æ­¥éª¤1ã€‘çš„ç§å­è¯è¾“å…¥æ¡†

        **ç­›é€‰æ ‡å‡†**ï¼š
        - âœ… ç¡®å®šåœ¨ç›®æ ‡åœºæ™¯ä¸‹ä¸€å®šæ­£ç¡®ï¼ˆå¦‚å•†å“åã€å“ç‰Œåã€ç±»ç›®åï¼‰
        - âœ… å…·æœ‰ä»£è¡¨æ€§ï¼Œèƒ½ä»£è¡¨ä¸€ç±»äº‹ç‰©
        - âŒ é¿å…é€šç”¨è¯ï¼ˆå¦‚ï¼šthe, of, çš„, äº†ï¼‰
        - âŒ é¿å…æ— æ„ä¹‰è¯
        """)

        col1, col2 = st.columns([1, 1])

        with col1:
            min_word_freq = st.slider(
                "è¯é¢‘ç­›é€‰é˜ˆå€¼",
                min_value=1,
                max_value=100,
                value=10,
                help="åªæ˜¾ç¤ºå‡ºç°æ¬¡æ•°>=æ­¤å€¼çš„è¯"
            )

        with col2:
            max_display = st.number_input(
                "æœ€å¤šæ˜¾ç¤ºè¯æ•°",
                min_value=50,
                max_value=1000,
                value=200,
                step=50,
                help="æ˜¾ç¤ºTop Nä¸ªé«˜é¢‘è¯"
            )

        load_btn = st.button(
            "ğŸ“¥ ä»Phase 0åŠ è½½åˆ†è¯ç»“æœ",
            type="primary",
            use_container_width=True
        )

        if load_btn:
            # Check if segmentation results exist
            with st.spinner("æ­£åœ¨æ£€æŸ¥åˆ†è¯ç»“æœ..."):
                with WordSegmentRepository() as ws_repo:
                    stats = ws_repo.get_statistics()
                    total_words = stats.get('total_words', 0)

                if total_words == 0:
                    st.error("âŒ æœªæ‰¾åˆ°åˆ†è¯ç»“æœï¼è¯·å…ˆå‰å¾€ **Phase 0 Tab 1** æ‰§è¡Œåˆ†è¯")
                else:
                    st.info(f"ğŸ“Š å½“å‰åˆ†è¯ç»“æœï¼š{total_words:,} ä¸ªè¯/çŸ­è¯­")

                    with st.spinner(f"æ­£åœ¨ä»Phase 0åŠ è½½åˆ†è¯ç»“æœ..."):
                        # Load words and phrases from word_segments table
                        with WordSegmentRepository() as ws_repo:
                            word_counter, ngram_counter, _, _, _, _ = ws_repo.load_segmentation_results(
                                min_word_frequency=min_word_freq,
                                min_ngram_frequency=min_word_freq
                            )

                        # Merge words and phrases as candidate seed words
                        all_candidates = Counter()
                        all_candidates.update(word_counter)
                        all_candidates.update(ngram_counter)

                        # Filter by length (at least 2 characters)
                        filtered_candidates = [
                            (word, freq)
                            for word, freq in all_candidates.most_common()
                            if len(word) >= 2
                        ]

                        # Save to session_state
                        st.session_state.candidate_seeds = filtered_candidates[:max_display]

                    st.success(f"âœ… å·²åŠ è½½ {len(all_candidates):,} ä¸ªå€™é€‰ç§å­è¯ï¼ˆåŒ…æ‹¬å•è¯å’ŒçŸ­è¯­ï¼‰ï¼Œç­›é€‰åæ˜¾ç¤º {len(st.session_state.candidate_seeds)} ä¸ª")

        # æ˜¾ç¤ºå€™é€‰ç§å­è¯
        if 'candidate_seeds' in st.session_state:
            candidate_seeds = st.session_state.candidate_seeds

            st.markdown("---")
            st.subheader(f"ğŸ“‹ å€™é€‰ç§å­è¯ï¼ˆ{len(candidate_seeds)} ä¸ªï¼‰")

            st.markdown("""
            **æ“ä½œæç¤º**ï¼š
            - å‹¾é€‰ä½ è®¤ä¸ºæ­£ç¡®çš„ç§å­è¯
            - å»ºè®®é€‰æ‹©10-30ä¸ª
            - ç‚¹å‡»"åº”ç”¨é€‰æ‹©"æŒ‰é’®ï¼Œè‡ªåŠ¨å¡«å……åˆ°æ­¥éª¤1
            """)

            # é€‰æ‹©æ¡†
            selected_seeds = []

            # åˆ†åˆ—å±•ç¤º
            cols_per_row = 3
            rows = (len(candidate_seeds) + cols_per_row - 1) // cols_per_row

            for row in range(min(rows, 20)):  # æœ€å¤šæ˜¾ç¤º20è¡Œï¼Œé¿å…å¤ªé•¿
                cols = st.columns(cols_per_row)

                for col_idx in range(cols_per_row):
                    word_idx = row * cols_per_row + col_idx
                    if word_idx < len(candidate_seeds):
                        word, freq = candidate_seeds[word_idx]

                        with cols[col_idx]:
                            is_selected = st.checkbox(
                                f"**{word}** ({freq}æ¬¡)",
                                key=f"seed_select_{word_idx}"
                            )
                            if is_selected:
                                selected_seeds.append(word)

            # åº”ç”¨æŒ‰é’®
            if selected_seeds:
                st.markdown("---")
                st.success(f"å·²é€‰æ‹© {len(selected_seeds)} ä¸ªç§å­è¯")

                if st.button("âœ… åº”ç”¨é€‰æ‹©åˆ°æ­¥éª¤1", type="primary"):
                    # ä¿å­˜åˆ°session_state
                    st.session_state.selected_seed_words = selected_seeds
                    st.success("âœ… å·²è‡ªåŠ¨å¡«å……åˆ°æ­¥éª¤1ï¼è¯·åˆ‡æ¢åˆ°ã€æ­¥éª¤1ï¼šæå–æ¨¡æ¿ã€‘Tab")

                # é¢„è§ˆ
                with st.expander("ğŸ” é¢„è§ˆé€‰æ‹©çš„ç§å­è¯"):
                    st.write(", ".join(selected_seeds))

    # ========================================================================
    # Tab 1: æå–æ¨¡æ¿
    # ========================================================================
    with tab1:
        st.header("ğŸ“ æ­¥éª¤1ï¼šä»ç§å­è¯æå–æ¨¡æ¿")

        st.markdown("""
        **æ“ä½œè¯´æ˜**ï¼š
        1. åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­ï¼Œæ¯è¡Œè¾“å…¥ä¸€ä¸ªç§å­è¯ï¼ˆæˆ–ä»ã€æ­¥éª¤0ã€‘è‡ªåŠ¨å¡«å……ï¼‰
        2. ç§å­è¯è¦æ±‚ï¼š**ç¡®å®šåœ¨ç›®æ ‡åœºæ™¯ä¸‹ä¸€å®šæ­£ç¡®**ï¼ˆå¦‚å•†å“åã€ç±»ç›®åç­‰ï¼‰
        3. å»ºè®®ï¼šå…ˆè¾“å…¥10-20ä¸ªç§å­è¯æµ‹è¯•æ•ˆæœ
        4. ç‚¹å‡»"å¼€å§‹æå–æ¨¡æ¿"æŒ‰é’®æ‰§è¡Œ
        """)

        # è‡ªåŠ¨å¡«å……ä»æ­¥éª¤0é€‰æ‹©çš„ç§å­è¯
        default_seeds = ""
        if 'selected_seed_words' in st.session_state:
            default_seeds = "\n".join(st.session_state.selected_seed_words)
            st.success(f"âœ… å·²è‡ªåŠ¨å¡«å…… {len(st.session_state.selected_seed_words)} ä¸ªç§å­è¯ï¼ˆæ¥è‡ªæ­¥éª¤0ï¼‰")

        col1, col2 = st.columns([2, 1])

        with col1:
            seed_words_input = st.text_area(
                "ç§å­è¯åˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                value=default_seeds,
                placeholder="ç¤ºä¾‹ï¼š\nandroid\niphone\npixel\nsamsung\nhuawei",
                height=200,
                help="äººå·¥æŒ‘é€‰çš„ã€ç¡®å®šæ­£ç¡®çš„ç›®æ ‡è¯"
            )

        with col2:
            min_template_freq = st.number_input(
                "æ¨¡æ¿æœ€å°é¢‘æ¬¡",
                min_value=1,
                value=5,
                help="æ¨¡æ¿è‡³å°‘å‡ºç°å¤šå°‘æ¬¡æ‰ä¿ç•™"
            )

            extract_btn = st.button(
                "ğŸš€ å¼€å§‹æå–æ¨¡æ¿",
                type="primary",
                use_container_width=True
            )

        if extract_btn:
            # è§£æç§å­è¯
            seed_words = [
                line.strip()
                for line in seed_words_input.strip().split('\n')
                if line.strip()
            ]

            if not seed_words:
                st.error("è¯·è¾“å…¥ç§å­è¯ï¼")
            elif not phrases:
                st.error("è¯·å…ˆåŠ è½½çŸ­è¯­æ•°æ®ï¼")
            else:
                with st.spinner(f"æ­£åœ¨ä» {len(seed_words)} ä¸ªç§å­è¯ä¸­æå–æ¨¡æ¿..."):
                    # æ‰§è¡Œæå–
                    extractor = JunyanTemplateExtractor(phrases)
                    templates = extractor.extract_templates_from_seeds(
                        seed_words=seed_words,
                        min_frequency=min_template_freq
                    )

                    # ä¿å­˜åˆ°session_state
                    st.session_state.junyan_templates = templates

                st.success(f"âœ… æå–å®Œæˆï¼å‘ç° {len(templates)} ä¸ªæ¨¡æ¿")

        # æ˜¾ç¤ºç»“æœ
        if 'junyan_templates' in st.session_state:
            templates = st.session_state.junyan_templates

            st.markdown("---")
            st.subheader(f"ğŸ“‹ å‘ç°çš„æ¨¡æ¿ï¼ˆ{len(templates)} ä¸ªï¼‰")

            # ç­›é€‰å™¨
            col1, col2 = st.columns(2)
            with col1:
                min_freq_filter = st.slider(
                    "ç­›é€‰ï¼šæœ€å°é¢‘æ¬¡",
                    min_value=1,
                    max_value=max(t['frequency'] for t in templates) if templates else 100,
                    value=5
                )

            filtered = [t for t in templates if t['frequency'] >= min_freq_filter]

            st.markdown(f"**æ˜¾ç¤º {len(filtered)} ä¸ªæ¨¡æ¿ï¼ˆé¢‘æ¬¡ >= {min_freq_filter}ï¼‰**")

            # é€‰æ‹©æ¡†ï¼šç”¨äºåç»­æå–å˜é‡
            selected_templates = []

            for i, template in enumerate(filtered, 1):
                with st.expander(
                    f"**{i}. {template['template_pattern']}** "
                    f"ï¼ˆé¢‘æ¬¡: {template['frequency']}, ç§å­è¯: {len(template['matched_seeds'])}ä¸ªï¼‰",
                    expanded=(i <= 5)
                ):
                    col1, col2 = st.columns([3, 2])

                    with col1:
                        st.markdown(f"**æ¨¡æ¿æ¨¡å¼**: `{template['template_pattern']}`")
                        st.markdown(f"**å‡ºç°é¢‘æ¬¡**: {template['frequency']}")
                        st.markdown(f"**åŒ¹é…ç§å­è¯** ({len(template['matched_seeds'])}ä¸ª): {', '.join(template['matched_seeds'][:10])}")

                    with col2:
                        # é€‰æ‹©checkbox
                        is_selected = st.checkbox(
                            "âœ… é€‰æ‹©æ­¤æ¨¡æ¿ç”¨äºæå–å˜é‡",
                            key=f"template_select_{i}"
                        )
                        if is_selected:
                            selected_templates.append(template['template_pattern'])

                    st.markdown("**ç¤ºä¾‹çŸ­è¯­**:")
                    for j, example in enumerate(template['example_phrases'][:5], 1):
                        st.text(f"  {j}. {example}")

            # ä¿å­˜é€‰æ‹©çš„æ¨¡æ¿
            if selected_templates:
                st.session_state.selected_templates = selected_templates
                st.success(f"å·²é€‰æ‹© {len(selected_templates)} ä¸ªæ¨¡æ¿")

                # æ˜¾ç¤ºé€‰æ‹©çš„æ¨¡æ¿
                with st.expander("ğŸ“ æŸ¥çœ‹é€‰æ‹©çš„æ¨¡æ¿"):
                    for i, t in enumerate(selected_templates, 1):
                        st.text(f"{i}. {t}")

    # ========================================================================
    # Tab 2: æå–å˜é‡
    # ========================================================================
    with tab2:
        st.header("ğŸ¯ æ­¥éª¤2ï¼šä»æ¨¡æ¿æå–å˜é‡")

        st.markdown("""
        **æ“ä½œè¯´æ˜**ï¼š
        1. åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­ï¼Œæ¯è¡Œè¾“å…¥ä¸€ä¸ªæ¨¡æ¿ï¼ˆæˆ–ä»æ­¥éª¤1é€‰æ‹©ï¼‰
        2. æ¨¡æ¿æ ¼å¼ï¼šç”¨`{X}`è¡¨ç¤ºå˜é‡ä½ç½®ï¼Œå¦‚ `best way to {X}`
        3. å¯é€‰ï¼šæ·»åŠ åœç”¨è¯ï¼Œè¿‡æ»¤è„æ•°æ®
        4. ç‚¹å‡»"å¼€å§‹æå–å˜é‡"æŒ‰é’®æ‰§è¡Œ
        """)

        # è‡ªåŠ¨å¡«å……ä»æ­¥éª¤1é€‰æ‹©çš„æ¨¡æ¿
        default_templates = ""
        if 'selected_templates' in st.session_state:
            default_templates = "\n".join(st.session_state.selected_templates)

        col1, col2 = st.columns([2, 1])

        with col1:
            templates_input = st.text_area(
                "æ¨¡æ¿åˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œç”¨{X}è¡¨ç¤ºå˜é‡ï¼‰",
                value=default_templates,
                placeholder="ç¤ºä¾‹ï¼š\nbest way to {X}\n{X} books in order\nwhat channel is {X} game on",
                height=200,
                help="äººå·¥ç­›é€‰çš„é«˜è´¨é‡æ¨¡æ¿"
            )

        with col2:
            min_var_freq = st.number_input(
                "å˜é‡æœ€å°é¢‘æ¬¡",
                min_value=1,
                value=3,
                help="å˜é‡è‡³å°‘å‡ºç°å¤šå°‘æ¬¡æ‰ä¿ç•™"
            )

            stop_words_input = st.text_area(
                "åœç”¨è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                placeholder="ç¤ºä¾‹ï¼š\nçš„\näº†\nåœ¨",
                height=100,
                help="ç”¨äºè¿‡æ»¤è„æ•°æ®"
            )

            extract_var_btn = st.button(
                "ğŸš€ å¼€å§‹æå–å˜é‡",
                type="primary",
                use_container_width=True
            )

        if extract_var_btn:
            # è§£ææ¨¡æ¿
            templates = [
                line.strip()
                for line in templates_input.strip().split('\n')
                if line.strip() and '{X}' in line
            ]

            # è§£æåœç”¨è¯
            stop_words = [
                line.strip()
                for line in stop_words_input.strip().split('\n')
                if line.strip()
            ] if stop_words_input.strip() else []

            if not templates:
                st.error("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæ¨¡æ¿ï¼ˆå¿…é¡»åŒ…å«{X}ï¼‰ï¼")
            elif not phrases:
                st.error("è¯·å…ˆåŠ è½½çŸ­è¯­æ•°æ®ï¼")
            else:
                with st.spinner(f"æ­£åœ¨ä» {len(templates)} ä¸ªæ¨¡æ¿ä¸­æå–å˜é‡..."):
                    # æ‰§è¡Œæå–
                    extractor = JunyanVariableExtractor(phrases)
                    result = extractor.extract_variables_from_templates(
                        templates=templates,
                        min_frequency=min_var_freq,
                        stop_words=stop_words
                    )

                    # ä¿å­˜åˆ°session_state
                    st.session_state.junyan_variables = result['variables']
                    st.session_state.junyan_quality = result['quality_analysis']

                st.success(f"âœ… æå–å®Œæˆï¼å‘ç° {len(result['variables'])} ä¸ªæœ‰æ•ˆå˜é‡")

        # æ˜¾ç¤ºç»“æœ
        if 'junyan_variables' in st.session_state:
            variables = st.session_state.junyan_variables

            st.markdown("---")
            st.subheader(f"ğŸ“‹ æå–çš„å˜é‡ï¼ˆ{len(variables)} ä¸ªï¼‰")

            # ç»Ÿè®¡
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å˜é‡æ€»æ•°", len(variables))
            with col2:
                avg_freq = sum(v['frequency'] for v in variables) / len(variables) if variables else 0
                st.metric("å¹³å‡é¢‘æ¬¡", f"{avg_freq:.1f}")
            with col3:
                avg_templates = sum(v['template_match_count'] for v in variables) / len(variables) if variables else 0
                st.metric("å¹³å‡åŒ¹é…æ¨¡æ¿æ•°", f"{avg_templates:.1f}")

            # ç­›é€‰å™¨
            col1, col2 = st.columns(2)
            with col1:
                min_freq_filter = st.slider(
                    "ç­›é€‰ï¼šæœ€å°é¢‘æ¬¡",
                    min_value=1,
                    max_value=max(v['frequency'] for v in variables) if variables else 100,
                    value=3,
                    key="var_freq_filter"
                )
            with col2:
                min_template_filter = st.slider(
                    "ç­›é€‰ï¼šæœ€å°æ¨¡æ¿æ•°",
                    min_value=1,
                    max_value=max(v['template_match_count'] for v in variables) if variables else 10,
                    value=2,
                    key="var_template_filter"
                )

            filtered_vars = [
                v for v in variables
                if v['frequency'] >= min_freq_filter and v['template_match_count'] >= min_template_filter
            ]

            st.markdown(f"**æ˜¾ç¤º {len(filtered_vars)} ä¸ªå˜é‡**")

            # è¡¨æ ¼å±•ç¤º
            import pandas as pd

            df_data = []
            for i, var in enumerate(filtered_vars, 1):
                df_data.append({
                    'åºå·': i,
                    'å˜é‡': var['variable_text'],
                    'é¢‘æ¬¡': var['frequency'],
                    'åŒ¹é…æ¨¡æ¿æ•°': var['template_match_count'],
                    'åŒ¹é…æ¨¡æ¿': ', '.join(var['matched_templates'][:3]) + ('...' if len(var['matched_templates']) > 3 else '')
                })

            df = pd.DataFrame(df_data)

            st.dataframe(
                df,
                use_container_width=True,
                height=400,
                hide_index=True
            )

            # CSVå¯¼å‡º
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å˜é‡åˆ—è¡¨ä¸ºCSV",
                data=csv,
                file_name="junyan_variables.csv",
                mime="text/csv"
            )

            # ä¿å­˜ä¸ºJSON
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜ç»“æœåˆ°outputsç›®å½•"):
                    output_dir = project_root / 'outputs'
                    output_dir.mkdir(exist_ok=True)

                    output_data = {
                        'total_variables': len(variables),
                        'variables': variables,
                        'quality_analysis': st.session_state.junyan_quality
                    }

                    output_file = output_dir / 'junyan_variables.json'
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(output_data, f, indent=2, ensure_ascii=False)

                    st.success(f"âœ… å·²ä¿å­˜åˆ° {output_file}")

    # ========================================================================
    # Tab 3: è´¨é‡åˆ†æ
    # ========================================================================
    with tab3:
        st.header("ğŸ“Š è´¨é‡åˆ†æ")

        if 'junyan_quality' not in st.session_state:
            st.warning("è¯·å…ˆåœ¨ã€æ­¥éª¤2ã€‘ä¸­æå–å˜é‡ï¼")
        else:
            quality = st.session_state.junyan_quality

            st.markdown("""
            **è´¨é‡åˆ†æè¯´æ˜**ï¼š
            - **é¦–å­—/æœ«å­—é¢‘æ¬¡**ï¼šè¯†åˆ«é«˜é¢‘æ— æ„ä¹‰å­—ç¬¦ï¼Œç”¨äºæ·»åŠ åœç”¨è¯
            - **æ¨¡æ¿-å˜é‡æ˜ å°„**ï¼šæŸ¥çœ‹æ¯ä¸ªæ¨¡æ¿æå–äº†å“ªäº›å˜é‡
            """)

            # é¦–å­—åˆ†æ
            st.subheader("ğŸ”¤ å˜é‡é¦–å­—é¢‘æ¬¡åˆ†æ")
            first_char_freq = quality['first_char_freq']

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Top 20 é¦–å­—**:")
                for i, (char, freq) in enumerate(list(first_char_freq.items())[:20], 1):
                    st.text(f"{i}. '{char}' - {freq} æ¬¡")

            with col2:
                # å™ªéŸ³è¯†åˆ«
                analyzer = JunyanQualityAnalyzer()
                noise_analysis = analyzer.analyze_noise_patterns(quality)

                st.markdown("**âš ï¸ é«˜é¢‘æ— æ„ä¹‰é¦–å­—ï¼ˆå»ºè®®æ·»åŠ åœç”¨è¯ï¼‰**:")
                if noise_analysis['high_freq_first_chars']:
                    for char in noise_analysis['high_freq_first_chars']:
                        st.warning(f"'{char}' - {first_char_freq[char]} æ¬¡")
                else:
                    st.success("æœªå‘ç°æ˜æ˜¾å™ªéŸ³")

            st.markdown("---")

            # æœ«å­—åˆ†æ
            st.subheader("ğŸ”¤ å˜é‡æœ«å­—é¢‘æ¬¡åˆ†æ")
            last_char_freq = quality['last_char_freq']

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Top 20 æœ«å­—**:")
                for i, (char, freq) in enumerate(list(last_char_freq.items())[:20], 1):
                    st.text(f"{i}. '{char}' - {freq} æ¬¡")

            with col2:
                st.markdown("**âš ï¸ é«˜é¢‘æ— æ„ä¹‰æœ«å­—ï¼ˆå»ºè®®æ·»åŠ åœç”¨è¯ï¼‰**:")
                if noise_analysis['high_freq_last_chars']:
                    for char in noise_analysis['high_freq_last_chars']:
                        st.warning(f"'{char}' - {last_char_freq[char]} æ¬¡")
                else:
                    st.success("æœªå‘ç°æ˜æ˜¾å™ªéŸ³")

            st.markdown("---")

            # æ¨¡æ¿-å˜é‡æ˜ å°„
            st.subheader("ğŸ”— æ¨¡æ¿-å˜é‡æ˜ å°„")
            template_variable_map = quality['template_variable_map']

            for template, variables in template_variable_map.items():
                with st.expander(f"**{template}** - æå–äº† {len(variables)} ä¸ªå˜é‡"):
                    st.markdown(f"**å‰20ä¸ªå˜é‡**: {', '.join(variables[:20])}")

    # åº•éƒ¨è¯´æ˜
    st.markdown("---")
    st.info("""
    **ğŸ’¡ å›è¨€æ–¹æ³•ä½¿ç”¨å»ºè®®**ï¼š

    1. **ç§å­è¯é€‰æ‹©**ï¼šç¡®ä¿ç§å­è¯åœ¨ç›®æ ‡åœºæ™¯ä¸‹ä¸€å®šæ­£ç¡®ï¼Œè´¨é‡>æ•°é‡
    2. **æ¨¡æ¿ç­›é€‰**ï¼šäººå·¥æ£€æŸ¥Topæ¨¡æ¿ï¼Œé€‰æ‹©{X}ä½ç½®å¤§æ¦‚ç‡æ˜¯ç›®æ ‡æ•°æ®çš„
    3. **åœç”¨è¯ä¼˜åŒ–**ï¼šæ ¹æ®è´¨é‡åˆ†æçš„é¦–å­—/æœ«å­—é¢‘æ¬¡ï¼Œæ·»åŠ åœç”¨è¯è¿‡æ»¤è„æ•°æ®
    4. **å¾ªç¯è¿­ä»£**ï¼šä»æå–çš„é«˜è´¨é‡å˜é‡ä¸­é€‰æ‹©æ–°ç§å­è¯ï¼Œé‡å¤æ­¥éª¤1-2
    5. **å¤šè½®è¿­ä»£**ï¼šé€šå¸¸2-3è½®è¿­ä»£å¯ä»¥è·å¾—æœ€ä½³ç»“æœ
    """)


if __name__ == "__main__":
    render()
