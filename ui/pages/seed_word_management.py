"""
è¯æ ¹ç®¡ç†é¡µé¢
ç®¡ç†seed_wordçš„åˆ†ç±»ã€å®šä¹‰å’Œéœ€æ±‚å…³è”
"""
import streamlit as st
import pandas as pd
from pathlib import Path
import sys
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from storage.repository import SeedWordRepository, PhraseRepository, DemandRepository
from storage.word_segment_repository import WordSegmentRepository
from storage.models import SeedWord


# Tokenæ¡†æ¶å¸¸é‡
TOKEN_TYPES = {
    'intent': 'æ„å›¾è¯ï¼ˆç”¨æˆ·æƒ³è¦ä»€ä¹ˆï¼‰',
    'action': 'åŠ¨ä½œè¯ï¼ˆç”¨æˆ·è¦åšä»€ä¹ˆï¼‰',
    'object': 'å¯¹è±¡è¯ï¼ˆæ¶‰åŠä»€ä¹ˆä¸œè¥¿ï¼‰',
    'other': 'å…¶ä»–ï¼ˆæ•°å­—ã€åœ°åã€å“ç‰Œç­‰ï¼‰'
}

TOKEN_TYPE_EXAMPLES = {
    'intent': 'ç¤ºä¾‹: best, top, cheap, free, how to, guide, tutorial',
    'action': 'ç¤ºä¾‹: download, buy, create, install, compare, learn',
    'object': 'ç¤ºä¾‹: calculator, phone, software, app, template',
    'other': 'ç¤ºä¾‹: 2024, windows, google, new york, python'
}

PRIORITY_LEVELS = {
    'high': 'é«˜ä¼˜å…ˆçº§',
    'medium': 'ä¸­ä¼˜å…ˆçº§',
    'low': 'ä½ä¼˜å…ˆçº§'
}

STATUS_TYPES = {
    'active': 'æ´»è·ƒ',
    'paused': 'æš‚åœ',
    'archived': 'å½’æ¡£'
}


def render():
    """æ¸²æŸ“è¯æ ¹ç®¡ç†é¡µé¢"""
    st.title("ğŸŒ± è¯æ ¹ç®¡ç†")

    st.markdown("""
    **åŠŸèƒ½è¯´æ˜**:
    - æŸ¥çœ‹å’Œç®¡ç†æ‰€æœ‰è¯æ ¹ï¼ˆseed_wordï¼‰
    - ä½¿ç”¨Tokenæ¡†æ¶å¯¹è¯æ ¹è¿›è¡Œåˆ†ç±»ï¼ˆintent/action/object/otherï¼‰
    - æ”¯æŒå¤šåˆ†ç±»ï¼šä¸€ä¸ªè¯æ ¹å¯ä»¥åŒæ—¶å±äºå¤šä¸ªç±»åˆ«
    - ä¸ºè¯æ ¹æ·»åŠ å®šä¹‰ã€ä¸šåŠ¡ä»·å€¼å’Œä½¿ç”¨åœºæ™¯
    - å…³è”è¯æ ¹ä¸éœ€æ±‚å¡ç‰‡
    - æŸ¥çœ‹è¯æ ¹çš„æ‰©å±•ç»Ÿè®¡ï¼ˆæ‰©å±•äº†å¤šå°‘ä¸ªçŸ­è¯­ï¼‰
    """)

    # åˆ›å»ºTabå¯¼èˆª
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š è¯æ ¹åˆ—è¡¨",
        "â• æ·»åŠ /ç¼–è¾‘è¯æ ¹",
        "ğŸ”— è¯æ ¹ä¸éœ€æ±‚å…³è”",
        "ğŸ“ˆ è¯æ ¹ç»Ÿè®¡"
    ])

    # Tab 1: è¯æ ¹åˆ—è¡¨
    with tab1:
        render_seed_word_list()

    # Tab 2: æ·»åŠ /ç¼–è¾‘è¯æ ¹
    with tab2:
        render_add_edit_seed_word()

    # Tab 3: è¯æ ¹ä¸éœ€æ±‚å…³è”
    with tab3:
        render_seed_demand_linking()

    # Tab 4: è¯æ ¹ç»Ÿè®¡
    with tab4:
        render_seed_statistics()


def render_seed_word_list():
    """æ¸²æŸ“è¯æ ¹åˆ—è¡¨"""
    st.header("ğŸ“Š è¯æ ¹åˆ—è¡¨")

    # ç­›é€‰é€‰é¡¹
    col1, col2, col3 = st.columns(3)

    with col1:
        filter_type = st.selectbox(
            "æŒ‰ä¸»è¦ç±»åˆ«ç­›é€‰",
            options=['å…¨éƒ¨'] + list(TOKEN_TYPES.keys()),
            format_func=lambda x: 'å…¨éƒ¨ç±»åˆ«' if x == 'å…¨éƒ¨' else f"{x} - {TOKEN_TYPES.get(x, x)}"
        )

    with col2:
        filter_status = st.selectbox(
            "æŒ‰çŠ¶æ€ç­›é€‰",
            options=['å…¨éƒ¨'] + list(STATUS_TYPES.keys()),
            format_func=lambda x: 'å…¨éƒ¨çŠ¶æ€' if x == 'å…¨éƒ¨' else STATUS_TYPES.get(x, x)
        )

    with col3:
        verified_only = st.checkbox("ä»…æ˜¾ç¤ºå·²å®¡æ ¸", value=False)

    # ä»æ•°æ®åº“åŠ è½½è¯æ ¹
    try:
        with SeedWordRepository() as repo:
            # æ ¹æ®ç­›é€‰æ¡ä»¶æŸ¥è¯¢
            if filter_type == 'å…¨éƒ¨':
                seeds = repo.get_all_seed_words(
                    status=None if filter_status == 'å…¨éƒ¨' else filter_status,
                    verified_only=verified_only
                )
            else:
                # å…ˆæŒ‰ä¸»è¦ç±»åˆ«ç­›é€‰
                seeds = repo.get_all_seed_words(
                    primary_token_type=filter_type,
                    status=None if filter_status == 'å…¨éƒ¨' else filter_status,
                    verified_only=verified_only
                )

        if not seeds:
            st.info("æš‚æ— è¯æ ¹æ•°æ®ã€‚è¯·åœ¨'æ·»åŠ /ç¼–è¾‘è¯æ ¹'é€‰é¡¹å¡ä¸­æ·»åŠ è¯æ ¹ï¼Œæˆ–ä»ç°æœ‰æ•°æ®è‡ªåŠ¨å¯¼å…¥ã€‚")

            # æä¾›å¿«é€Ÿå¯¼å…¥æŒ‰é’®
            st.markdown("---")
            st.subheader("ğŸš€ å¿«é€Ÿå¯¼å…¥")
            st.markdown("ä»phrasesè¡¨ä¸­æå–æ‰€æœ‰å”¯ä¸€çš„seed_wordå¹¶å¯¼å…¥åˆ°è¯æ ¹ç®¡ç†è¡¨ä¸­ã€‚")

            if st.button("ğŸ“¥ ä»Phrasesè¡¨å¯¼å…¥è¯æ ¹", type="primary"):
                import_seeds_from_phrases()

            return

        # è·å–æ‰€æœ‰è¯æ ¹çš„ç¿»è¯‘
        seed_words_list = [s.seed_word for s in seeds]
        translations = {}
        with WordSegmentRepository() as ws_repo:
            for word in seed_words_list:
                ws = ws_repo.get_word_segment(word)
                if ws and ws.translation:
                    translations[word] = ws.translation

        # è½¬æ¢ä¸ºDataFrame
        df_data = []
        for seed in seeds:
            # è§£ætoken_types
            try:
                token_types_list = json.loads(seed.token_types) if seed.token_types else [seed.primary_token_type]
            except:
                token_types_list = [seed.primary_token_type] if seed.primary_token_type else []

            token_types_str = ', '.join([f"{t}" for t in token_types_list])

            df_data.append({
                'ID': seed.seed_id,
                'è¯æ ¹': seed.seed_word,
                'ä¸­æ–‡': translations.get(seed.seed_word, '-'),
                'ä¸»è¦ç±»åˆ«': seed.primary_token_type or '-',
                'æ‰€æœ‰ç±»åˆ«': token_types_str or '-',
                'æ‰©å±•æ•°': seed.expansion_count or 0,
                'æ€»æœç´¢é‡': seed.total_volume or 0,
                'å¹³å‡é¢‘æ¬¡': seed.avg_frequency or 0,
                'çŠ¶æ€': STATUS_TYPES.get(seed.status, seed.status),
                'ä¼˜å…ˆçº§': PRIORITY_LEVELS.get(seed.priority, seed.priority),
                'å·²å®¡æ ¸': 'âœ“' if seed.verified else 'âœ—',
                'å®šä¹‰': seed.definition[:50] + '...' if seed.definition and len(seed.definition) > 50 else seed.definition or '-'
            })

        df = pd.DataFrame(df_data)

        # æ˜¾ç¤ºç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("è¯æ ¹æ€»æ•°", len(seeds))
        col2.metric("å·²å®¡æ ¸", sum(1 for s in seeds if s.verified))
        col3.metric("æ€»æ‰©å±•æ•°", sum(s.expansion_count or 0 for s in seeds))
        col4.metric("å¹³å‡æ‰©å±•æ•°", int(sum(s.expansion_count or 0 for s in seeds) / len(seeds)) if seeds else 0)

        st.markdown("---")

        # æ˜¾ç¤ºè¡¨æ ¼
        st.dataframe(
            df,
            width='stretch',
            height=400,
            hide_index=True
        )

        # æ‰¹é‡æ“ä½œ
        st.markdown("---")
        st.subheader("âš™ï¸ æ‰¹é‡æ“ä½œ")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            if st.button("ğŸ”„ æ›´æ–°æ‰€æœ‰è¯æ ¹ç»Ÿè®¡", help="ä»phrasesè¡¨é‡æ–°è®¡ç®—æ‰€æœ‰è¯æ ¹çš„æ‰©å±•æ•°ã€æ€»æœç´¢é‡ç­‰"):
                with st.spinner("æ­£åœ¨æ›´æ–°ç»Ÿè®¡ä¿¡æ¯..."):
                    with SeedWordRepository() as repo:
                        success_count = repo.batch_update_all_stats()
                    st.success(f"âœ“ æˆåŠŸæ›´æ–° {success_count} ä¸ªè¯æ ¹çš„ç»Ÿè®¡ä¿¡æ¯")
                    st.rerun()

        with col2:
            if st.button("ğŸ“¥ åŒæ­¥æ–°è¯æ ¹", help="ä»phrasesè¡¨å¯¼å…¥å°šæœªæ·»åŠ çš„seed_word"):
                import_seeds_from_phrases()

        with col3:
            if st.button("ğŸ¤– æ‰¹é‡è‡ªåŠ¨åˆ†ç±»", help="ä½¿ç”¨LLMä¸ºæ‰€æœ‰æœªåˆ†ç±»è¯æ ¹è‡ªåŠ¨åˆ†é…Tokenç±»åˆ«"):
                auto_classify_seeds()

        with col4:
            # ç»Ÿè®¡æ²¡æœ‰ç¿»è¯‘çš„è¯æ ¹æ•°é‡
            untranslated_count = sum(1 for word in seed_words_list if translations.get(word, '-') == '-')
            if st.button("ğŸŒ æ‰¹é‡ç¿»è¯‘", help=f"ç¿»è¯‘æ²¡æœ‰ä¸­æ–‡çš„è¯æ ¹ï¼ˆ{untranslated_count}ä¸ªï¼‰"):
                batch_translate_seeds(seed_words_list, translations)

        # è¯¦ç»†æŸ¥çœ‹åŒºåŸŸ
        st.markdown("---")
        st.subheader("ğŸ” è¯¦ç»†æŸ¥çœ‹")

        selected_seed_word = st.selectbox(
            "é€‰æ‹©è¦æŸ¥çœ‹è¯¦æƒ…çš„è¯æ ¹",
            options=[s.seed_word for s in seeds],
            key="detail_view_selector"
        )

        if selected_seed_word:
            show_seed_word_detail(selected_seed_word)

    except Exception as e:
        st.error(f"åŠ è½½è¯æ ¹åˆ—è¡¨å¤±è´¥: {str(e)}")
        import traceback
        st.error(traceback.format_exc())


def render_add_edit_seed_word():
    """æ¸²æŸ“æ·»åŠ /ç¼–è¾‘è¯æ ¹"""
    st.header("â• æ·»åŠ /ç¼–è¾‘è¯æ ¹")

    # é€‰æ‹©æ“ä½œæ¨¡å¼
    mode = st.radio(
        "é€‰æ‹©æ“ä½œ",
        options=['æ·»åŠ æ–°è¯æ ¹', 'ç¼–è¾‘ç°æœ‰è¯æ ¹'],
        horizontal=True
    )

    if mode == 'ç¼–è¾‘ç°æœ‰è¯æ ¹':
        # åŠ è½½ç°æœ‰è¯æ ¹åˆ—è¡¨
        try:
            with SeedWordRepository() as repo:
                all_seeds = repo.get_all_seed_words()

            if not all_seeds:
                st.warning("æš‚æ— è¯æ ¹å¯ç¼–è¾‘ï¼Œè¯·å…ˆæ·»åŠ è¯æ ¹ã€‚")
                return

            selected_word = st.selectbox(
                "é€‰æ‹©è¦ç¼–è¾‘çš„è¯æ ¹",
                options=[s.seed_word for s in all_seeds]
            )

            # åŠ è½½é€‰ä¸­è¯æ ¹çš„æ•°æ®
            with SeedWordRepository() as repo:
                seed_obj = repo.get_seed_word(selected_word)

            # è§£æç°æœ‰æ•°æ®
            try:
                existing_types = json.loads(seed_obj.token_types) if seed_obj.token_types else []
            except:
                existing_types = []

            if not existing_types and seed_obj.primary_token_type:
                existing_types = [seed_obj.primary_token_type]

        except Exception as e:
            st.error(f"åŠ è½½è¯æ ¹æ•°æ®å¤±è´¥: {str(e)}")
            return
    else:
        selected_word = None
        seed_obj = None
        existing_types = []

    # è¡¨å•
    with st.form("seed_word_form"):
        st.subheader("ğŸ“ åŸºæœ¬ä¿¡æ¯")

        col1, col2 = st.columns(2)

        with col1:
            if mode == 'æ·»åŠ æ–°è¯æ ¹':
                seed_word_input = st.text_input(
                    "è¯æ ¹æ–‡æœ¬ *",
                    value="",
                    help="è¾“å…¥seed_wordï¼ˆè‹±æ–‡å°å†™ï¼‰"
                )
            else:
                seed_word_input = st.text_input(
                    "è¯æ ¹æ–‡æœ¬",
                    value=selected_word,
                    disabled=True
                )

        with col2:
            status = st.selectbox(
                "çŠ¶æ€",
                options=list(STATUS_TYPES.keys()),
                format_func=lambda x: STATUS_TYPES[x],
                index=list(STATUS_TYPES.keys()).index(seed_obj.status if seed_obj else 'active')
            )

        st.markdown("---")
        st.subheader("ğŸ·ï¸ Tokenåˆ†ç±»")

        # Tokenç±»åˆ«é€‰æ‹©ï¼ˆå¤šé€‰ï¼‰
        st.markdown("**é€‰æ‹©æ‰€æœ‰é€‚ç”¨çš„ç±»åˆ«** (å¯å¤šé€‰):")

        selected_types = []
        for token_type, description in TOKEN_TYPES.items():
            col1, col2 = st.columns([1, 3])
            with col1:
                is_checked = st.checkbox(
                    f"{token_type}",
                    value=token_type in existing_types,
                    key=f"type_{token_type}"
                )
            with col2:
                st.caption(f"{description} - {TOKEN_TYPE_EXAMPLES[token_type]}")

            if is_checked:
                selected_types.append(token_type)

        # ä¸»è¦ç±»åˆ«é€‰æ‹©
        if selected_types:
            primary_type = st.selectbox(
                "ä¸»è¦ç±»åˆ« *",
                options=selected_types,
                format_func=lambda x: f"{x} - {TOKEN_TYPES[x]}",
                index=selected_types.index(seed_obj.primary_token_type) if seed_obj and seed_obj.primary_token_type in selected_types else 0,
                help="å¦‚æœé€‰æ‹©äº†å¤šä¸ªç±»åˆ«ï¼Œè¯·æŒ‡å®šä¸»è¦ç±»åˆ«ç”¨äºæ’åºå’Œç­›é€‰"
            )
        else:
            primary_type = None
            st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªTokenç±»åˆ«")

        st.markdown("---")
        st.subheader("ğŸ“– å®šä¹‰ä¸åœºæ™¯")

        definition = st.text_area(
            "è¯æ ¹å®šä¹‰",
            value=seed_obj.definition if seed_obj else "",
            help="è§£é‡Šè¿™ä¸ªè¯æ ¹çš„å«ä¹‰å’Œç”¨é€”",
            height=100
        )

        business_value = st.text_area(
            "å•†ä¸šä»·å€¼",
            value=seed_obj.business_value if seed_obj else "",
            help="è¯´æ˜è¿™ä¸ªè¯æ ¹çš„å•†ä¸šä»·å€¼å’Œé‡è¦æ€§",
            height=100
        )

        user_scenario = st.text_area(
            "ç”¨æˆ·åœºæ™¯",
            value=seed_obj.user_scenario if seed_obj else "",
            help="æè¿°ç”¨æˆ·åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹ä¼šä½¿ç”¨ç›¸å…³å…³é”®è¯",
            height=100
        )

        st.markdown("---")
        st.subheader("âš™ï¸ å…¶ä»–è®¾ç½®")

        col1, col2, col3 = st.columns(3)

        with col1:
            priority = st.selectbox(
                "ä¼˜å…ˆçº§",
                options=list(PRIORITY_LEVELS.keys()),
                format_func=lambda x: PRIORITY_LEVELS[x],
                index=list(PRIORITY_LEVELS.keys()).index(seed_obj.priority if seed_obj else 'medium')
            )

        with col2:
            verified = st.checkbox(
                "å·²å®¡æ ¸",
                value=seed_obj.verified if seed_obj else False
            )

        with col3:
            confidence = st.selectbox(
                "ç½®ä¿¡åº¦",
                options=['high', 'medium', 'low'],
                format_func=lambda x: {'high': 'é«˜', 'medium': 'ä¸­', 'low': 'ä½'}[x],
                index=['high', 'medium', 'low'].index(seed_obj.confidence if seed_obj else 'medium')
            )

        notes = st.text_area(
            "å¤‡æ³¨",
            value=seed_obj.notes if seed_obj else "",
            help="å…¶ä»–è¡¥å……è¯´æ˜"
        )

        # æäº¤æŒ‰é’®
        submitted = st.form_submit_button(
            "ğŸ’¾ ä¿å­˜" if mode == 'ç¼–è¾‘ç°æœ‰è¯æ ¹' else "â• æ·»åŠ è¯æ ¹",
            type="primary"
        )

        if submitted:
            # éªŒè¯
            if not seed_word_input:
                st.error("âŒ è¯æ ¹æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
                return

            if not selected_types:
                st.error("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªTokenç±»åˆ«")
                return

            if not primary_type:
                st.error("âŒ è¯·é€‰æ‹©ä¸»è¦ç±»åˆ«")
                return

            # ä¿å­˜
            try:
                with SeedWordRepository() as repo:
                    seed = repo.create_or_update_seed_word(
                        seed_word=seed_word_input.strip().lower(),
                        token_types=selected_types,
                        primary_token_type=primary_type,
                        definition=definition.strip() if definition else None,
                        business_value=business_value.strip() if business_value else None,
                        user_scenario=user_scenario.strip() if user_scenario else None,
                        status=status,
                        priority=priority,
                        verified=verified,
                        confidence=confidence,
                        notes=notes.strip() if notes else None
                    )

                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    repo.update_expansion_stats(seed_word_input.strip().lower())

                st.success(f"âœ“ è¯æ ¹ '{seed_word_input}' {'æ›´æ–°' if mode == 'ç¼–è¾‘ç°æœ‰è¯æ ¹' else 'æ·»åŠ '}æˆåŠŸï¼")
                st.rerun()

            except Exception as e:
                st.error(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
                import traceback
                st.error(traceback.format_exc())


def render_seed_demand_linking():
    """æ¸²æŸ“è¯æ ¹ä¸éœ€æ±‚å…³è”"""
    st.header("ğŸ”— è¯æ ¹ä¸éœ€æ±‚å…³è”")

    st.markdown("""
    å°†è¯æ ¹ä¸éœ€æ±‚å¡ç‰‡å…³è”ï¼Œå»ºç«‹è¯æ ¹åˆ°éœ€æ±‚çš„æ˜ å°„å…³ç³»ã€‚
    """)

    col1, col2 = st.columns(2)

    # é€‰æ‹©è¯æ ¹
    with col1:
        st.subheader("é€‰æ‹©è¯æ ¹")

        try:
            with SeedWordRepository() as repo:
                all_seeds = repo.get_all_seed_words()

            if not all_seeds:
                st.warning("æš‚æ— è¯æ ¹æ•°æ®")
                return

            selected_seed = st.selectbox(
                "é€‰æ‹©è¯æ ¹",
                options=[s.seed_word for s in all_seeds],
                key="link_seed_selector"
            )

            # æ˜¾ç¤ºè¯æ ¹ä¿¡æ¯
            with SeedWordRepository() as repo:
                seed_obj = repo.get_seed_word(selected_seed)

            if seed_obj:
                st.info(f"**ç±»åˆ«**: {seed_obj.primary_token_type}")
                st.info(f"**æ‰©å±•æ•°**: {seed_obj.expansion_count or 0}")
                if seed_obj.definition:
                    st.info(f"**å®šä¹‰**: {seed_obj.definition[:100]}...")

        except Exception as e:
            st.error(f"åŠ è½½è¯æ ¹å¤±è´¥: {str(e)}")
            return

    # é€‰æ‹©éœ€æ±‚
    with col2:
        st.subheader("é€‰æ‹©éœ€æ±‚")

        try:
            from storage.models import Demand
            with DemandRepository() as repo:
                all_demands = repo.session.query(Demand).all()

            if not all_demands:
                st.warning("æš‚æ— éœ€æ±‚æ•°æ®ï¼Œè¯·å…ˆåœ¨ Phase 5 ä¸­ç”Ÿæˆéœ€æ±‚")
                return

            demand_options = {f"{d.demand_id}: {d.title}": d.demand_id for d in all_demands}

            selected_demand_str = st.selectbox(
                "é€‰æ‹©éœ€æ±‚å¡ç‰‡",
                options=list(demand_options.keys()),
                key="link_demand_selector"
            )

            selected_demand_id = demand_options[selected_demand_str]

            # å…³è”é€‰é¡¹
            is_primary = st.checkbox(
                "è®¾ä¸ºä¸»è¦å…³è”",
                value=False,
                help="æ˜¯å¦å°†æ­¤éœ€æ±‚è®¾ä¸ºè¯¥è¯æ ¹çš„ä¸»è¦å…³è”éœ€æ±‚"
            )

            if st.button("ğŸ”— å»ºç«‹å…³è”", type="primary"):
                try:
                    with SeedWordRepository() as repo:
                        success = repo.link_demand(
                            seed_word=selected_seed,
                            demand_id=selected_demand_id,
                            is_primary=is_primary
                        )

                    if success:
                        st.success(f"âœ“ å·²å°†è¯æ ¹ '{selected_seed}' ä¸éœ€æ±‚ #{selected_demand_id} å…³è”")
                        st.rerun()
                    else:
                        st.error("å…³è”å¤±è´¥")

                except Exception as e:
                    st.error(f"å…³è”å¤±è´¥: {str(e)}")

        except Exception as e:
            st.error(f"åŠ è½½éœ€æ±‚å¤±è´¥: {str(e)}")
            return

    # æ˜¾ç¤ºç°æœ‰å…³è”
    st.markdown("---")
    st.subheader("ğŸ“‹ ç°æœ‰å…³è”")

    if seed_obj and seed_obj.related_demand_ids:
        try:
            demand_ids = json.loads(seed_obj.related_demand_ids)

            if demand_ids:
                st.write(f"è¯æ ¹ **{selected_seed}** å·²å…³è” {len(demand_ids)} ä¸ªéœ€æ±‚:")

                from storage.models import Demand
                with DemandRepository() as repo:
                    for demand_id in demand_ids:
                        demand = repo.session.query(Demand).filter_by(demand_id=demand_id).first()
                        if demand:
                            is_primary_mark = " ğŸŒŸ (ä¸»è¦)" if demand_id == seed_obj.primary_demand_id else ""
                            st.write(f"- #{demand.demand_id}: {demand.title}{is_primary_mark}")
            else:
                st.info("å°šæœªå»ºç«‹å…³è”")
        except:
            st.info("å°šæœªå»ºç«‹å…³è”")
    else:
        st.info("å°šæœªå»ºç«‹å…³è”")


def render_seed_statistics():
    """æ¸²æŸ“è¯æ ¹ç»Ÿè®¡"""
    st.header("ğŸ“ˆ è¯æ ¹ç»Ÿè®¡")

    try:
        with SeedWordRepository() as repo:
            stats = repo.get_statistics()

        # æ€»ä½“ç»Ÿè®¡
        st.subheader("ğŸ“Š æ€»ä½“ç»Ÿè®¡")

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("è¯æ ¹æ€»æ•°", stats['total'])
        col2.metric("å·²å®¡æ ¸æ•°", stats['verified_count'])
        col3.metric("å®¡æ ¸ç‡", f"{stats['verified_rate']}%")

        # æŒ‰ä¸»è¦ç±»åˆ«ç»Ÿè®¡
        st.markdown("---")
        st.subheader("ğŸ·ï¸ æŒ‰ä¸»è¦Tokenç±»åˆ«ç»Ÿè®¡")

        by_type_df = pd.DataFrame([
            {
                'ç±»åˆ«': token_type,
                'ä¸­æ–‡å': TOKEN_TYPES[token_type],
                'æ•°é‡': count
            }
            for token_type, count in stats['by_primary_type'].items()
        ])

        col1, col2 = st.columns([1, 1])

        with col1:
            st.dataframe(by_type_df, width='stretch', hide_index=True)

        with col2:
            if not by_type_df.empty:
                st.bar_chart(by_type_df.set_index('ç±»åˆ«')['æ•°é‡'])

        # æŒ‰çŠ¶æ€ç»Ÿè®¡
        st.markdown("---")
        st.subheader("ğŸ“Œ æŒ‰çŠ¶æ€ç»Ÿè®¡")

        by_status_df = pd.DataFrame([
            {
                'çŠ¶æ€': STATUS_TYPES.get(status, status),
                'æ•°é‡': count
            }
            for status, count in stats['by_status'].items()
        ])

        st.dataframe(by_status_df, width='stretch', hide_index=True)

        # Topè¯æ ¹
        st.markdown("---")
        st.subheader("ğŸ† æ‰©å±•æ•°Top 20è¯æ ¹")

        with SeedWordRepository() as repo:
            all_seeds = repo.get_all_seed_words()

        top_seeds = sorted(all_seeds, key=lambda x: x.expansion_count or 0, reverse=True)[:20]

        if top_seeds:
            top_df = pd.DataFrame([
                {
                    'æ’å': i+1,
                    'è¯æ ¹': s.seed_word,
                    'ä¸»è¦ç±»åˆ«': s.primary_token_type,
                    'æ‰©å±•æ•°': s.expansion_count or 0,
                    'æ€»æœç´¢é‡': s.total_volume or 0,
                    'å¹³å‡é¢‘æ¬¡': s.avg_frequency or 0
                }
                for i, s in enumerate(top_seeds)
            ])

            st.dataframe(top_df, width='stretch', hide_index=True)

    except Exception as e:
        st.error(f"åŠ è½½ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


def show_seed_word_detail(seed_word: str):
    """æ˜¾ç¤ºè¯æ ¹è¯¦ç»†ä¿¡æ¯"""
    try:
        with SeedWordRepository() as repo:
            seed = repo.get_seed_word(seed_word)

        if not seed:
            st.warning(f"æ‰¾ä¸åˆ°è¯æ ¹: {seed_word}")
            return

        # è·å–ç¿»è¯‘
        translation = '-'
        with WordSegmentRepository() as ws_repo:
            ws = ws_repo.get_word_segment(seed_word)
            if ws and ws.translation:
                translation = ws.translation

        # è§£ætoken_types
        try:
            token_types_list = json.loads(seed.token_types) if seed.token_types else []
        except:
            token_types_list = []

        # åŸºæœ¬ä¿¡æ¯
        st.markdown(f"### è¯æ ¹: **{seed.seed_word}** ({translation})")

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("æ‰©å±•æ•°", seed.expansion_count or 0)
        col2.metric("æ€»æœç´¢é‡", seed.total_volume or 0)
        col3.metric("å¹³å‡é¢‘æ¬¡", seed.avg_frequency or 0)
        col4.metric("çŠ¶æ€", STATUS_TYPES.get(seed.status, seed.status))

        # Tokenåˆ†ç±»
        st.markdown("**Tokenåˆ†ç±»**:")
        if token_types_list:
            types_str = ', '.join([f"`{t}` ({TOKEN_TYPES.get(t, t)})" for t in token_types_list])
            st.markdown(f"- æ‰€æœ‰ç±»åˆ«: {types_str}")
        st.markdown(f"- ä¸»è¦ç±»åˆ«: `{seed.primary_token_type}` ({TOKEN_TYPES.get(seed.primary_token_type, '-')})")

        # å®šä¹‰ä¸åœºæ™¯
        if seed.definition:
            st.markdown("**å®šä¹‰**:")
            st.info(seed.definition)

        if seed.business_value:
            st.markdown("**å•†ä¸šä»·å€¼**:")
            st.info(seed.business_value)

        if seed.user_scenario:
            st.markdown("**ç”¨æˆ·åœºæ™¯**:")
            st.info(seed.user_scenario)

        # å…¶ä»–ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        col1.write(f"**ä¼˜å…ˆçº§**: {PRIORITY_LEVELS.get(seed.priority, seed.priority)}")
        col2.write(f"**å·²å®¡æ ¸**: {'âœ“' if seed.verified else 'âœ—'}")
        col3.write(f"**ç½®ä¿¡åº¦**: {seed.confidence}")

        if seed.notes:
            st.markdown("**å¤‡æ³¨**:")
            st.caption(seed.notes)

        # å…³è”éœ€æ±‚
        if seed.related_demand_ids:
            try:
                demand_ids = json.loads(seed.related_demand_ids)
                if demand_ids:
                    st.markdown("**å…³è”éœ€æ±‚**:")
                    from storage.models import Demand
                    with DemandRepository() as demand_repo:
                        for demand_id in demand_ids:
                            demand = demand_repo.session.query(Demand).filter_by(demand_id=demand_id).first()
                            if demand:
                                is_primary = " ğŸŒŸ" if demand_id == seed.primary_demand_id else ""
                                st.write(f"- #{demand.demand_id}: {demand.title}{is_primary}")
            except:
                pass

        # æŸ¥çœ‹æ‰©å±•çš„çŸ­è¯­ï¼ˆæŠ½æ ·ï¼‰
        st.markdown("**æ‰©å±•çš„çŸ­è¯­ï¼ˆå‰20ä¸ªï¼‰**:")
        with PhraseRepository() as phrase_repo:
            phrases = phrase_repo.get_phrases_by_seed_word(seed_word, limit=20)

        if phrases:
            phrases_text = ', '.join([p.phrase for p in phrases])
            st.caption(phrases_text)
        else:
            st.caption("æš‚æ— æ‰©å±•çŸ­è¯­")

    except Exception as e:
        st.error(f"åŠ è½½è¯æ ¹è¯¦æƒ…å¤±è´¥: {str(e)}")


def import_seeds_from_phrases():
    """ä»phrasesè¡¨å¯¼å…¥seed_word"""
    try:
        with st.spinner("æ­£åœ¨ä»phrasesè¡¨å¯¼å…¥è¯æ ¹..."):
            with PhraseRepository() as phrase_repo:
                # è·å–æ‰€æœ‰å”¯ä¸€çš„seed_word
                all_seed_words = phrase_repo.get_all_seed_words()

            if not all_seed_words:
                st.warning("phrasesè¡¨ä¸­æ²¡æœ‰seed_wordæ•°æ®")
                return

            # å¯¼å…¥åˆ°seed_wordsè¡¨
            imported_count = 0
            updated_count = 0

            with SeedWordRepository() as seed_repo:
                for seed_word in all_seed_words:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = seed_repo.get_seed_word(seed_word)

                    if not existing:
                        # åˆ›å»ºæ–°è¯æ ¹ï¼ˆæœªåˆ†ç±»çŠ¶æ€ï¼‰
                        seed_repo.create_or_update_seed_word(
                            seed_word=seed_word,
                            token_types=None,  # å¾…åˆ†ç±»
                            primary_token_type=None,  # å¾…åˆ†ç±»
                            source='auto_import',
                            status='active'
                        )
                        imported_count += 1

                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ— è®ºæ˜¯å¦å·²å­˜åœ¨ï¼‰
                    seed_repo.update_expansion_stats(seed_word)
                    updated_count += 1

            st.success(f"âœ“ å¯¼å…¥å®Œæˆï¼æ–°å¢ {imported_count} ä¸ªè¯æ ¹ï¼Œæ›´æ–°äº† {updated_count} ä¸ªè¯æ ¹çš„ç»Ÿè®¡ä¿¡æ¯ã€‚")

            # è¯¢é—®æ˜¯å¦è‡ªåŠ¨åˆ†ç±»
            if imported_count > 0:
                st.info("ğŸ’¡ æ–°å¯¼å…¥çš„è¯æ ¹å°šæœªåˆ†ç±»ï¼Œå»ºè®®ä½¿ç”¨'ğŸ¤– æ‰¹é‡è‡ªåŠ¨åˆ†ç±»'åŠŸèƒ½ä¸ºå®ƒä»¬è‡ªåŠ¨åˆ†é…Tokenç±»åˆ«ã€‚")

            st.rerun()

    except Exception as e:
        st.error(f"å¯¼å…¥å¤±è´¥: {str(e)}")
        import traceback
        st.error(traceback.format_exc())


def auto_classify_seeds():
    """ä½¿ç”¨LLMè‡ªåŠ¨åˆ†ç±»è¯æ ¹"""
    try:
        # è·å–æœªåˆ†ç±»çš„è¯æ ¹
        with SeedWordRepository() as repo:
            all_seeds = repo.get_all_seed_words()

            # ç­›é€‰æœªåˆ†ç±»çš„è¯æ ¹ï¼ˆprimary_token_typeä¸ºNoneï¼‰
            unclassified = [s for s in all_seeds if not s.primary_token_type]

        if not unclassified:
            st.info("âœ“ æ‰€æœ‰è¯æ ¹éƒ½å·²åˆ†ç±»ï¼Œæ— éœ€å¤„ç†")
            return

        st.info(f"å‘ç° {len(unclassified)} ä¸ªæœªåˆ†ç±»è¯æ ¹ï¼Œå¼€å§‹è‡ªåŠ¨åˆ†ç±»...")

        # æå–è¯æ ¹æ–‡æœ¬
        seed_words = [s.seed_word for s in unclassified]

        # ä½¿ç”¨LLMæ‰¹é‡åˆ†ç±»
        from ai.client import LLMClient

        with st.spinner(f"æ­£åœ¨ä½¿ç”¨LLMåˆ†ç±» {len(seed_words)} ä¸ªè¯æ ¹..."):
            llm = LLMClient()
            classification_results = llm.batch_classify_tokens(seed_words, batch_size=50)

        # ä¿å­˜åˆ†ç±»ç»“æœ
        success_count = 0

        with st.spinner("æ­£åœ¨ä¿å­˜åˆ†ç±»ç»“æœ..."):
            with SeedWordRepository() as repo:
                for result in classification_results:
                    seed_word = result.get('token')
                    token_type = result.get('token_type', 'other')
                    confidence = result.get('confidence', 'medium')

                    if seed_word:
                        # æ›´æ–°è¯æ ¹åˆ†ç±»
                        repo.create_or_update_seed_word(
                            seed_word=seed_word,
                            token_types=[token_type],  # å•åˆ†ç±»
                            primary_token_type=token_type,
                            confidence=confidence,
                            verified=False  # LLMåˆ†ç±»æœªç»äººå·¥å®¡æ ¸
                        )
                        success_count += 1

        st.success(f"âœ“ è‡ªåŠ¨åˆ†ç±»å®Œæˆï¼æˆåŠŸåˆ†ç±» {success_count} ä¸ªè¯æ ¹")
        st.info("ğŸ’¡ LLMåˆ†ç±»ç»“æœå·²æ ‡è®°ä¸º'æœªå®¡æ ¸'ï¼Œå»ºè®®äººå·¥å¤æŸ¥å¹¶è°ƒæ•´")
        st.rerun()

    except Exception as e:
        st.error(f"è‡ªåŠ¨åˆ†ç±»å¤±è´¥: {str(e)}")
        import traceback
        st.error(traceback.format_exc())


def batch_translate_seeds(seed_words_list, existing_translations):
    """æ‰¹é‡ç¿»è¯‘è¯æ ¹ï¼ˆä½¿ç”¨AIï¼‰"""
    try:
        # æ‰¾å‡ºéœ€è¦ç¿»è¯‘çš„è¯æ ¹ï¼ˆæ‰€æœ‰è¯æ ¹éƒ½ç”¨AIé‡æ–°ç¿»è¯‘ï¼Œç¡®ä¿å‡†ç¡®æ€§ï¼‰
        words_to_translate = [
            word for word in seed_words_list
            if existing_translations.get(word, '-') == '-'
        ]

        if not words_to_translate:
            st.info("âœ“ æ‰€æœ‰è¯æ ¹éƒ½å·²æœ‰ç¿»è¯‘ï¼")

            # æä¾›é€‰é¡¹ï¼šæ˜¯å¦è¦ç”¨AIé‡æ–°ç¿»è¯‘æ‰€æœ‰è¯æ ¹
            st.markdown("---")
            st.markdown("**ğŸ”„ é‡æ–°ç¿»è¯‘é€‰é¡¹**")
            st.markdown("ä½¿ç”¨AIé‡æ–°ç¿»è¯‘æ‰€æœ‰è¯æ ¹ï¼Œä»¥è·å¾—æ›´å‡†ç¡®ã€æ›´ç¬¦åˆSEOè¯­å¢ƒçš„ç¿»è¯‘ã€‚")

            if st.button("ğŸ¤– ä½¿ç”¨AIé‡æ–°ç¿»è¯‘æ‰€æœ‰è¯æ ¹", help="ç”¨AIé‡æ–°ç¿»è¯‘æ‰€æœ‰è¯æ ¹ï¼Œæ›¿æ¢ç°æœ‰ç¿»è¯‘"):
                words_to_translate = seed_words_list
            else:
                return

        st.info(f"å‘ç° {len(words_to_translate)} ä¸ªè¯æ ¹éœ€è¦ç¿»è¯‘...")

        # ä½¿ç”¨AIç¿»è¯‘
        from ai.client import LLMClient

        with st.spinner(f"æ­£åœ¨ä½¿ç”¨AIç¿»è¯‘ {len(words_to_translate)} ä¸ªè¯æ ¹..."):
            llm = LLMClient()
            new_translations = llm.batch_translate_seed_words(words_to_translate, batch_size=50)

            # ä¿å­˜åˆ°æ•°æ®åº“
            if new_translations:
                with WordSegmentRepository() as ws_repo:
                    for word, trans in new_translations.items():
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        existing = ws_repo.get_word_segment(word)
                        if existing:
                            # æ›´æ–°ç¿»è¯‘
                            existing.translation = trans
                        else:
                            # åˆ›å»ºæ–°è®°å½•
                            from storage.models import WordSegment
                            from datetime import datetime
                            new_ws = WordSegment(
                                word=word,
                                frequency=0,
                                translation=trans,
                                created_at=datetime.utcnow()
                            )
                            ws_repo.session.add(new_ws)
                    ws_repo.session.commit()

        st.success(f"âœ“ AIç¿»è¯‘å®Œæˆï¼æˆåŠŸç¿»è¯‘ {len(new_translations)} ä¸ªè¯æ ¹")
        st.info("ğŸ’¡ AIç¿»è¯‘æ›´å‡†ç¡®ã€æ›´ç¬¦åˆSEOè¯­å¢ƒï¼Œå·²ä¿å­˜åˆ°æ•°æ®åº“")
        st.rerun()

    except Exception as e:
        st.error(f"æ‰¹é‡ç¿»è¯‘å¤±è´¥: {str(e)}")
        import traceback
        st.error(traceback.format_exc())


if __name__ == "__main__":
    render()
