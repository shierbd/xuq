"""
Phase 0: å…³é”®è¯æ‰©å±•ä¸åˆ†è¯å·¥å…·
ä»æ•°æ®åº“è¯»å–å·²å¯¼å…¥çš„å…³é”®è¯è¿›è¡Œåˆ†è¯ã€åœç”¨è¯ç®¡ç†å’Œé¢‘æ¬¡åˆ†æ
"""
import streamlit as st
import pandas as pd
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from utils.keyword_segmentation import (
    segment_keywords,
    segment_keywords_with_seed_tracking,
    get_sorted_words,
    clean_keywords,
    get_statistics
)
from utils.stopwords import (
    load_stopwords,
    save_stopwords,
    add_stopword,
    remove_stopword,
    reset_to_default,
    get_stopwords_info
)
from utils.translation import translate_words_batch, TRANSLATION_AVAILABLE
from utils.pos_tagging import (
    tag_words_batch,
    get_pos_statistics,
    get_available_categories,
    POS_TAGGING_AVAILABLE
)
from storage.repository import PhraseRepository, SeedWordRepository
from storage.word_segment_repository import WordSegmentRepository
from ui.components.seed_word_tracking import render_seed_word_tracking


# é…ç½®
STOPWORDS_FILE = PROJECT_ROOT / "config" / "stopwords_en.txt"


def main():
    st.title("ğŸ“ Phase 0: å…³é”®è¯æ‰©å±•ä¸åˆ†è¯å·¥å…·")

    # åˆ›å»ºTabå¯¼èˆª
    tab1, tab2 = st.tabs(["ğŸŒ± è¯æ ¹è¿½æº¯", "âœ‚ï¸ åˆ†è¯ä¸ç­›é€‰"])

    # ========== Tab 1: è¯æ ¹è¿½æº¯ ==========
    with tab1:
        render_seed_word_tracking()

    # ========== Tab 2: åˆ†è¯ä¸ç­›é€‰ ==========
    with tab2:
        render_segmentation_tab()


def render_segmentation_tab():
    """æ¸²æŸ“åˆ†è¯ä¸ç­›é€‰tabçš„å†…å®¹"""
    st.markdown("""
    ---
    **ä½¿ç”¨è¯´æ˜**:

    æœ¬å·¥å…·ç”¨äºå…³é”®è¯æ‰©å±•çš„è¿­ä»£å¾ªç¯ä¸­ï¼Œå·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š
    1. **Phase 1: æ•°æ®å¯¼å…¥** - å¯¼å…¥åˆå§‹å…³é”®è¯CSV
    2. **Phase 0: å…³é”®è¯æ‰©å±•**ï¼ˆæœ¬é¡µé¢ï¼‰- åˆ†è¯ã€ç­›é€‰é«˜é¢‘è¯
    3. **æ‰‹åŠ¨æ“ä½œ** - ä½¿ç”¨é«˜é¢‘è¯å»å¤–éƒ¨å·¥å…·ï¼ˆGoogle Autocompleteã€ç›¸å…³æœç´¢ç­‰ï¼‰è·å–æ‰©å±•è¯
    4. **Phase 1: æ•°æ®å¯¼å…¥** - å¯¼å…¥æ‰©å±•åçš„å…³é”®è¯
    5. **Phase 0: å…³é”®è¯æ‰©å±•** - å†æ¬¡åˆ†è¯ç­›é€‰
    6. é‡å¤æ­¥éª¤3-5ï¼Œç›´åˆ°æ»¡æ„
    7. **Phase 2: å¤§ç»„èšç±»** - å¼€å§‹æ­£å¼çš„èšç±»åˆ†æ

    **æ ¸å¿ƒåŠŸèƒ½**:
    - ä»æ•°æ®åº“è¯»å–å·²å¯¼å…¥çš„å…³é”®è¯è¿›è¡Œåˆ†è¯
    - äº¤äº’å¼åœç”¨è¯ç®¡ç†ï¼ˆæ·»åŠ ã€åˆ é™¤ã€é‡ç½®ï¼‰
    - æ”¯æŒæ’åºã€ç¿»è¯‘ï¼ˆå¯é€‰ï¼‰ã€å¯¼å‡ºï¼ˆHTML/CSV/å¤åˆ¶ï¼‰
    - å•è½®æ¬¡å¤„ç†ï¼Œç”±ç”¨æˆ·æ‰‹åŠ¨æ§åˆ¶è¿­ä»£è½®æ¬¡
    """)

    # åˆå§‹åŒ– Session State
    if 'stopwords' not in st.session_state:
        st.session_state.stopwords = load_stopwords(STOPWORDS_FILE)

    if 'word_counter' not in st.session_state:
        st.session_state.word_counter = None

    if 'translations' not in st.session_state:
        st.session_state.translations = {}

    if 'pos_tags' not in st.session_state:
        st.session_state.pos_tags = {}

    if 'selected_words' not in st.session_state:
        st.session_state.selected_words = set()

    if 'word_to_seeds' not in st.session_state:
        st.session_state.word_to_seeds = {}

    if 'keywords_cache' not in st.session_state:
        st.session_state.keywords_cache = None

    if 'phrases_cache' not in st.session_state:
        st.session_state.phrases_cache = None

    # ========== 1. ä»æ•°æ®åº“åŠ è½½å…³é”®è¯ ==========
    st.header("1ï¸âƒ£ åŠ è½½æ•°æ®åº“å…³é”®è¯")

    # ä½¿ç”¨ç¼“å­˜é¿å…æ¯æ¬¡rerunéƒ½é‡æ–°åŠ è½½
    if st.session_state.keywords_cache is None:
        load_data = True
    else:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.success(f"âœ“ å·²åŠ è½½ {len(st.session_state.keywords_cache)} æ¡å…³é”®è¯ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰")
        with col2:
            if st.button("ğŸ”„ é‡æ–°åŠ è½½", help="ä»æ•°æ®åº“é‡æ–°åŠ è½½æ•°æ®"):
                st.session_state.keywords_cache = None
                st.session_state.word_counter = None
                st.session_state.translations = {}
                st.session_state.pos_tags = {}
                st.session_state.selected_words = set()
                st.rerun()
        load_data = False

    if load_data:
        try:
            with PhraseRepository() as repo:
                # è·å–ç»Ÿè®¡ä¿¡æ¯
                stats = repo.get_statistics()
                total_count = stats.get('total_count', 0)

                if total_count == 0:
                    st.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰å…³é”®è¯æ•°æ®ï¼Œè¯·å…ˆåœ¨ Phase 1 ä¸­å¯¼å…¥æ•°æ®")
                    return

                by_source = stats.get('by_source', {})

                # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                col1.metric("æ•°æ®åº“æ€»è¯æ•°", f"{total_count:,}")
                col2.metric("æ•°æ®æ¥æºæ•°", len(by_source))
                col3.metric("çŠ¶æ€", "å·²å°±ç»ª")

                # æ•°æ®æºç­›é€‰
                if by_source:
                    st.subheader("ğŸ“Š æ•°æ®æºç­›é€‰")

                    # æ˜¾ç¤ºå„æ¥æºç»Ÿè®¡
                    source_df = pd.DataFrame([
                        {"æ¥æº": source or "æœªçŸ¥", "æ•°é‡": count}
                        for source, count in by_source.items()
                    ])
                    st.dataframe(source_df, width='stretch')

                    # é€‰æ‹©æ•°æ®æº
                    available_sources = ["å…¨éƒ¨æ•°æ®"] + [s or "æœªçŸ¥" for s in by_source.keys()]
                    selected_source = st.selectbox(
                        "é€‰æ‹©è¦åˆ†è¯çš„æ•°æ®æº",
                        options=available_sources,
                        help="é€‰æ‹©ç‰¹å®šæ¥æºçš„æ•°æ®è¿›è¡Œåˆ†è¯ï¼Œæˆ–é€‰æ‹©'å…¨éƒ¨æ•°æ®'"
                    )

                    # æ ¹æ®é€‰æ‹©åŠ è½½æ•°æ®
                    if selected_source == "å…¨éƒ¨æ•°æ®":
                        # åŠ è½½æ‰€æœ‰æ•°æ®ï¼ˆåˆ†é¡µåŠ è½½ä»¥é¿å…å†…å­˜é—®é¢˜ï¼‰
                        all_phrases = []
                        page = 1
                        page_size = 10000

                        with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                            while True:
                                phrases, total = repo.get_phrases_paginated(page=page, page_size=page_size)
                                if not phrases:
                                    break
                                all_phrases.extend(phrases)
                                page += 1
                                if len(all_phrases) >= total:
                                    break

                        keywords = [p.phrase for p in all_phrases]
                        # åŒæ—¶ç¼“å­˜å®Œæ•´çš„phraseså¯¹è±¡ï¼ˆç”¨äºè·å–seed_wordï¼‰
                        st.session_state.phrases_cache = all_phrases
                        st.info(f"âœ“ å·²é€‰æ‹©å…¨éƒ¨æ•°æ®ï¼Œå…± {len(keywords):,} æ¡å…³é”®è¯")
                    else:
                        # åŠ è½½æŒ‡å®šæ¥æºçš„æ•°æ®
                        source_type = None if selected_source == "æœªçŸ¥" else selected_source
                        all_phrases = []
                        page = 1
                        page_size = 10000

                        with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                            while True:
                                phrases, total = repo.get_phrases_paginated(
                                    page=page,
                                    page_size=page_size,
                                    filters={'source_type': source_type}
                                )
                                if not phrases:
                                    break
                                all_phrases.extend(phrases)
                                page += 1
                                if len(all_phrases) >= total:
                                    break

                        keywords = [p.phrase for p in all_phrases]
                        # åŒæ—¶ç¼“å­˜å®Œæ•´çš„phraseså¯¹è±¡ï¼ˆç”¨äºè·å–seed_wordï¼‰
                        st.session_state.phrases_cache = all_phrases
                        st.info(f"âœ“ å·²é€‰æ‹©æ¥æº '{selected_source}'ï¼Œå…± {len(keywords):,} æ¡å…³é”®è¯")
                else:
                    # æ²¡æœ‰æ¥æºä¿¡æ¯ï¼ŒåŠ è½½æ‰€æœ‰æ•°æ®
                    all_phrases = []
                    page = 1
                    page_size = 10000

                    with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                        while True:
                            phrases, total = repo.get_phrases_paginated(page=page, page_size=page_size)
                            if not phrases:
                                break
                            all_phrases.extend(phrases)
                            page += 1
                            if len(all_phrases) >= total:
                                break

                    keywords = [p.phrase for p in all_phrases]
                    # åŒæ—¶ç¼“å­˜å®Œæ•´çš„phraseså¯¹è±¡ï¼ˆç”¨äºè·å–seed_wordï¼‰
                    st.session_state.phrases_cache = all_phrases
                    st.info(f"ğŸ“Š å…±åŠ è½½ {len(keywords):,} æ¡å…³é”®è¯")

                # ç¼“å­˜åŠ è½½çš„æ•°æ®
                st.session_state.keywords_cache = keywords

        except Exception as e:
            st.error(f"âŒ åŠ è½½æ•°æ®åº“æ•°æ®å¤±è´¥: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
            return
    else:
        # ä½¿ç”¨ç¼“å­˜çš„æ•°æ®
        keywords = st.session_state.keywords_cache

    # ========== 2. åœç”¨è¯ç®¡ç† ==========
    st.header("2ï¸âƒ£ åœç”¨è¯ç®¡ç†")

    tab1, tab2 = st.tabs(["æŸ¥çœ‹åœç”¨è¯", "ç®¡ç†åœç”¨è¯"])

    with tab1:
        stopwords_info = get_stopwords_info(st.session_state.stopwords)

        col1, col2, col3 = st.columns(3)
        col1.metric("åœç”¨è¯æ•°é‡", stopwords_info['total'])
        col2.metric("æ˜¯å¦ä¸ºé»˜è®¤", "æ˜¯" if stopwords_info['is_default'] else "å¦")

        st.write("**å½“å‰åœç”¨è¯ï¼ˆå‰50ä¸ªï¼‰**:")
        st.code(', '.join(sorted(list(st.session_state.stopwords))[:50]))

    with tab2:
        st.subheader("æ·»åŠ åœç”¨è¯")
        new_word = st.text_input("è¾“å…¥è¦æ·»åŠ çš„åœç”¨è¯ï¼ˆå°å†™ï¼‰")
        if st.button("â• æ·»åŠ "):
            if new_word:
                st.session_state.stopwords = add_stopword(
                    st.session_state.stopwords,
                    new_word
                )
                save_stopwords(st.session_state.stopwords, STOPWORDS_FILE)
                st.success(f"âœ“ å·²æ·»åŠ åœç”¨è¯: {new_word}")
                st.rerun()

        st.subheader("åˆ é™¤åœç”¨è¯")
        words_to_remove = st.multiselect(
            "é€‰æ‹©è¦åˆ é™¤çš„åœç”¨è¯",
            options=sorted(list(st.session_state.stopwords))
        )
        if st.button("â– åˆ é™¤é€‰ä¸­"):
            if words_to_remove:
                for word in words_to_remove:
                    st.session_state.stopwords = remove_stopword(
                        st.session_state.stopwords,
                        word
                    )
                save_stopwords(st.session_state.stopwords, STOPWORDS_FILE)
                st.success(f"âœ“ å·²åˆ é™¤ {len(words_to_remove)} ä¸ªåœç”¨è¯")
                st.rerun()

        st.subheader("é‡ç½®ä¸ºé»˜è®¤")
        if st.button("ğŸ”„ é‡ç½®åœç”¨è¯"):
            st.session_state.stopwords = reset_to_default(STOPWORDS_FILE)
            st.success("âœ“ å·²é‡ç½®ä¸ºé»˜è®¤åœç”¨è¯")
            st.rerun()

    # ========== 3. æ‰§è¡Œåˆ†è¯ ==========
    st.header("3ï¸âƒ£ æ‰§è¡Œåˆ†è¯")

    # æ¸…ç†å…³é”®è¯
    keywords_cleaned = clean_keywords(keywords)
    st.info(f"âœ“ æ¸…ç†åå‰©ä½™ {len(keywords_cleaned)} æ¡å…³é”®è¯")

    # åˆ†è¯é…ç½®
    col1, col2, col3 = st.columns(3)
    with col1:
        min_frequency = st.number_input(
            "æœ€å°é¢‘æ¬¡",
            min_value=1,
            value=2,
            help="åªæ˜¾ç¤ºå‡ºç°æ¬¡æ•° >= æ­¤å€¼çš„è¯"
        )

    with col2:
        sort_by = st.selectbox(
            "æ’åºæ–¹å¼",
            options=['frequency', 'alphabetical', 'length'],
            format_func=lambda x: {
                'frequency': 'æŒ‰é¢‘æ¬¡é™åº',
                'alphabetical': 'æŒ‰å­—æ¯å‡åº',
                'length': 'æŒ‰è¯é•¿åº¦é™åº'
            }[x]
        )

    with col3:
        enable_pos_tagging = st.checkbox(
            "å¯ç”¨è¯æ€§æ ‡æ³¨",
            value=True,
            disabled=not POS_TAGGING_AVAILABLE,
            help="ä½¿ç”¨NLTKè¿›è¡Œè‹±æ–‡è¯æ€§æ ‡æ³¨"
        )
        if not POS_TAGGING_AVAILABLE:
            st.info("â„¹ï¸ è¯æ€§æ ‡æ³¨éœ€è¦å®‰è£… nltk åº“")

    if st.button("ğŸš€ å¼€å§‹åˆ†è¯", type="primary"):
        with st.spinner("æ­£åœ¨åˆ†è¯..."):
            # æ‰§è¡Œåˆ†è¯ï¼ˆä½¿ç”¨å¸¦seedè¿½è¸ªçš„ç‰ˆæœ¬ï¼‰
            if st.session_state.phrases_cache:
                # ä½¿ç”¨å¸¦seedè¿½è¸ªçš„åˆ†è¯
                word_counter, word_to_seeds = segment_keywords_with_seed_tracking(
                    st.session_state.phrases_cache,
                    st.session_state.stopwords
                )
                st.session_state.word_to_seeds = word_to_seeds
            else:
                # é™çº§åˆ°æ™®é€šåˆ†è¯ï¼ˆå¦‚æœæ²¡æœ‰phrases_cacheï¼‰
                word_counter = segment_keywords(
                    keywords_cleaned,
                    st.session_state.stopwords
                )
                st.session_state.word_to_seeds = {}

            st.session_state.word_counter = word_counter

            # è¯æ€§æ ‡æ³¨
            if enable_pos_tagging and POS_TAGGING_AVAILABLE:
                with st.spinner("æ­£åœ¨è¿›è¡Œè¯æ€§æ ‡æ³¨..."):
                    words_list = list(word_counter.keys())
                    st.session_state.pos_tags = tag_words_batch(words_list)

            # è·å–ç»Ÿè®¡
            stats = get_statistics(word_counter)

            # æ˜¾ç¤ºç»Ÿè®¡
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("å”¯ä¸€è¯æ•°", stats['total_unique_words'])
            col2.metric("æ€»å‡ºç°æ¬¡æ•°", stats['total_occurrences'])
            col3.metric("å¹³å‡é¢‘æ¬¡", stats['avg_frequency'])

            # è¯æ€§ç»Ÿè®¡
            if st.session_state.pos_tags:
                pos_stats = get_pos_statistics(word_counter, st.session_state.pos_tags)
                noun_count = pos_stats.get('by_category', {}).get('Noun', 0)
                col4.metric("åè¯æ•°é‡", noun_count)

            st.success("âœ“ åˆ†è¯å®Œæˆï¼")

    # ========== 4. æ˜¾ç¤ºç»“æœ ==========
    if st.session_state.word_counter is not None:
        st.header("4ï¸âƒ£ åˆ†è¯ç»“æœ")

        # æ’åº
        sorted_words = get_sorted_words(
            st.session_state.word_counter,
            sort_by=sort_by,
            min_frequency=min_frequency
        )

        # åˆ›å»ºDataFrame
        df_words = pd.DataFrame(sorted_words, columns=['è¯æ±‡', 'é¢‘æ¬¡'])

        # æ·»åŠ è¯æ€§åˆ—
        if st.session_state.pos_tags:
            df_words['è¯æ€§'] = df_words['è¯æ±‡'].map(
                lambda w: st.session_state.pos_tags.get(w, ('UNKNOWN', 'Other', 'æœªçŸ¥'))[2]
            )
            df_words['è¯æ€§åˆ†ç±»'] = df_words['è¯æ±‡'].map(
                lambda w: st.session_state.pos_tags.get(w, ('UNKNOWN', 'Other', 'æœªçŸ¥'))[1]
            )

        # æ·»åŠ è¯æ ¹çŠ¶æ€åˆ—ï¼ˆè¯¥è¯æ˜¯å¦ä½œä¸ºseed_wordä½¿ç”¨ï¼‰
        with st.spinner("æ­£åœ¨æŸ¥è¯¢è¯æ ¹çŠ¶æ€..."):
            with PhraseRepository() as repo:
                words_list = df_words['è¯æ±‡'].tolist()
                seed_status = repo.get_words_seed_status(words_list)

        df_words['æ˜¯å¦ä¸ºè¯æ ¹'] = df_words['è¯æ±‡'].map(
            lambda w: 'æ˜¯' if seed_status.get(w, 0) > 0 else 'å¦'
        )
        df_words['ä½œä¸ºè¯æ ¹çš„æ‰©å±•æ•°'] = df_words['è¯æ±‡'].map(
            lambda w: seed_status.get(w, 0)
        )

        # æ·»åŠ åŸå§‹è¯æ ¹åˆ—ï¼ˆè¯¥è¯å‡ºç°åœ¨å“ªäº›seed_wordçš„çŸ­è¯­ä¸­ï¼‰
        if st.session_state.word_to_seeds:
            def format_seeds(word, max_show=5):
                """æ ¼å¼åŒ–è¯æ ¹æ˜¾ç¤ºï¼Œåªæ˜¾ç¤ºå‰å‡ ä¸ª"""
                seeds = sorted(st.session_state.word_to_seeds.get(word, ['unknown']))
                if len(seeds) <= max_show:
                    return ', '.join(seeds)
                else:
                    shown = ', '.join(seeds[:max_show])
                    return f"{shown}... (+{len(seeds)-max_show}ä¸ª)"

            df_words['æ¥æºè¯æ ¹'] = df_words['è¯æ±‡'].map(
                lambda w: format_seeds(w, max_show=5)
            )
            df_words['æ¥æºè¯æ ¹æ•°'] = df_words['è¯æ±‡'].map(
                lambda w: len(st.session_state.word_to_seeds.get(w, []))
            )

        # é«˜çº§ç­›é€‰åŒºåŸŸ
        st.subheader("ğŸ” é«˜çº§ç­›é€‰")

        col1, col2, col3 = st.columns(3)

        with col1:
            # é¢‘æ¬¡ç­›é€‰
            st.markdown("**é¢‘æ¬¡èŒƒå›´ç­›é€‰**")
            freq_min = df_words['é¢‘æ¬¡'].min()
            freq_max = df_words['é¢‘æ¬¡'].max()

            freq_range = st.slider(
                "é€‰æ‹©é¢‘æ¬¡èŒƒå›´",
                min_value=int(freq_min),
                max_value=int(freq_max),
                value=(int(freq_min), int(freq_max)),
                help="æ‹–åŠ¨æ»‘å—ç­›é€‰é¢‘æ¬¡èŒƒå›´"
            )

            # åº”ç”¨é¢‘æ¬¡ç­›é€‰
            df_words = df_words[
                (df_words['é¢‘æ¬¡'] >= freq_range[0]) &
                (df_words['é¢‘æ¬¡'] <= freq_range[1])
            ]

        with col2:
            # è¯æ€§ç­›é€‰
            if st.session_state.pos_tags:
                st.markdown("**è¯æ€§ç­›é€‰**")
                # è·å–å¯ç”¨çš„è¯æ€§åˆ†ç±»
                available_categories = get_available_categories()
                category_names = [cn for _, cn in available_categories]

                selected_pos = st.multiselect(
                    "é€‰æ‹©è¦æ˜¾ç¤ºçš„è¯æ€§ï¼ˆä¸é€‰åˆ™æ˜¾ç¤ºå…¨éƒ¨ï¼‰",
                    options=category_names,
                    help="å¯ä»¥é€‰æ‹©å¤šä¸ªè¯æ€§ç±»åˆ«è¿›è¡Œç­›é€‰"
                )

                # åº”ç”¨è¯æ€§ç­›é€‰
                if selected_pos:
                    # å»ºç«‹ä¸­æ–‡åˆ°è‹±æ–‡çš„æ˜ å°„
                    cn_to_en = {cn: en for en, cn in available_categories}
                    selected_en = [cn_to_en[cn] for cn in selected_pos]
                    df_words = df_words[df_words['è¯æ€§åˆ†ç±»'].isin(selected_en)]

        with col3:
            # è¯æ ¹ç­›é€‰
            if 'æ˜¯å¦ä¸ºè¯æ ¹' in df_words.columns:
                st.markdown("**è¯æ ¹ç­›é€‰**")
                exclude_seeds = st.checkbox(
                    "ä»…æ˜¾ç¤ºéè¯æ ¹è¯æ±‡",
                    value=False,
                    help="å‹¾é€‰åï¼Œå°†éšè—é‚£äº›æœ¬èº«ä½œä¸ºseed_wordä½¿ç”¨çš„è¯ï¼Œåªæ˜¾ç¤ºåˆ†è¯åçš„æ™®é€šè¯æ±‡"
                )

                if exclude_seeds:
                    # è¿‡æ»¤æ‰æ˜¯è¯æ ¹çš„è¯ï¼ˆæ˜¯å¦ä¸ºè¯æ ¹='æ˜¯'ï¼‰
                    df_words = df_words[df_words['æ˜¯å¦ä¸ºè¯æ ¹'] == 'å¦']

        # æ˜¾ç¤ºç­›é€‰ç»“æœ
        if len(df_words) < len(sorted_words):
            st.info(f"âœ“ ç­›é€‰åå‰©ä½™ {len(df_words)} ä¸ªè¯ï¼ˆåŸå§‹ {len(sorted_words)} ä¸ªï¼‰")

        # ç¿»è¯‘é€‰é¡¹
        col1, col2 = st.columns([3, 1])
        with col1:
            translate_enabled = st.checkbox(
                "æ˜¾ç¤ºä¸­æ–‡ç¿»è¯‘",
                value=False,
                disabled=not TRANSLATION_AVAILABLE,
                help="ä½¿ç”¨Google Translateè¿›è¡Œè‹±è¯‘ä¸­ï¼ˆåŸºäºdeep-translatoråº“ï¼‰"
            )
            if not TRANSLATION_AVAILABLE:
                st.info("â„¹ï¸ ç¿»è¯‘åŠŸèƒ½ä¸å¯ç”¨ï¼šè¯·è¿è¡Œ `pip install deep-translator` å®‰è£…ç¿»è¯‘åº“")

        with col2:
            if translate_enabled and TRANSLATION_AVAILABLE:
                # å…ˆä»æ•°æ®åº“åŠ è½½å·²æœ‰ç¿»è¯‘
                if st.button("ğŸŒ æ‰§è¡Œç¿»è¯‘"):
                    with st.spinner("æ­£åœ¨ä»æ•°æ®åº“åŠ è½½å·²æœ‰ç¿»è¯‘..."):
                        words_to_translate = df_words['è¯æ±‡'].tolist()

                        # ä»word_segmentsè¡¨åŠ è½½å·²æœ‰ç¿»è¯‘
                        with WordSegmentRepository() as ws_repo:
                            existing_translations = {}
                            for word in words_to_translate:
                                ws = ws_repo.get_word_segment(word)
                                if ws and ws.translation:
                                    existing_translations[word] = ws.translation

                        # æ‰¾å‡ºéœ€è¦ç¿»è¯‘çš„æ–°è¯
                        words_need_translation = [
                            w for w in words_to_translate
                            if w not in existing_translations
                        ]

                        if existing_translations:
                            st.info(f"âœ“ ä»æ•°æ®åº“åŠ è½½äº† {len(existing_translations)} ä¸ªå·²æœ‰ç¿»è¯‘")

                        # ç¿»è¯‘æ–°è¯
                        new_translations = {}
                        if words_need_translation:
                            with st.spinner(f"æ­£åœ¨ç¿»è¯‘ {len(words_need_translation)} ä¸ªæ–°è¯..."):
                                new_translations = translate_words_batch(
                                    words_need_translation,
                                    batch_size=100
                                )

                            # ä¿å­˜æ–°ç¿»è¯‘åˆ°æ•°æ®åº“
                            if new_translations:
                                with st.spinner("æ­£åœ¨ä¿å­˜ç¿»è¯‘åˆ°æ•°æ®åº“..."):
                                    with WordSegmentRepository() as ws_repo:
                                        for word, trans in new_translations.items():
                                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                                            existing = ws_repo.get_word_segment(word)
                                            if existing:
                                                # æ›´æ–°ç¿»è¯‘
                                                existing.translation = trans
                                            else:
                                                # åˆ›å»ºæ–°è®°å½•ï¼ˆåªä¿å­˜wordå’Œtranslationï¼‰
                                                from storage.models import WordSegment
                                                from datetime import datetime
                                                new_ws = WordSegment(
                                                    word=word,
                                                    frequency=0,  # ç¿»è¯‘åŠŸèƒ½ä¸è®°å½•é¢‘æ¬¡
                                                    translation=trans,
                                                    created_at=datetime.utcnow()
                                                )
                                                ws_repo.session.add(new_ws)
                                        ws_repo.session.commit()
                                st.success(f"âœ“ ç¿»è¯‘äº† {len(new_translations)} ä¸ªæ–°è¯å¹¶å·²ä¿å­˜")
                        else:
                            st.success("âœ“ æ‰€æœ‰è¯æ±‡éƒ½å·²æœ‰ç¿»è¯‘ï¼")

                        # åˆå¹¶ç¿»è¯‘ç»“æœ
                        st.session_state.translations = {**existing_translations, **new_translations}

        # æ·»åŠ ç¿»è¯‘åˆ—
        if translate_enabled and st.session_state.translations:
            df_words['ä¸­æ–‡'] = df_words['è¯æ±‡'].map(st.session_state.translations)

        # æ·»åŠ é€‰æ‹©åˆ—
        df_words.insert(0, 'é€‰æ‹©', False)

        # æ‰¹é‡é€‰æ‹©æ“ä½œ
        st.subheader("ğŸ¯ è¯æ±‡é€‰æ‹©")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            if st.button("âœ… å…¨é€‰", key="select_all_btn"):
                st.session_state.selected_words = set(df_words['è¯æ±‡'].tolist())
                # ä¸ç«‹å³rerunï¼Œè®©data_editoræ›´æ–°åè‡ªåŠ¨å¤„ç†
        with col2:
            if st.button("âŒ å…¨ä¸é€‰", key="deselect_all_btn"):
                st.session_state.selected_words = set()
        with col3:
            if st.button("ğŸ”„ åé€‰", key="inverse_select_btn"):
                all_words = set(df_words['è¯æ±‡'].tolist())
                st.session_state.selected_words = all_words - st.session_state.selected_words
        with col4:
            st.metric("å·²é€‰æ‹©", len(st.session_state.selected_words))

        # æ›´æ–°é€‰æ‹©åˆ—çš„å€¼
        df_words['é€‰æ‹©'] = df_words['è¯æ±‡'].apply(lambda w: w in st.session_state.selected_words)

        # æ˜¾ç¤ºå¯ç¼–è¾‘çš„è¡¨æ ¼ - ä½¿ç”¨keyå‚æ•°é¿å…ä¸å¿…è¦çš„åˆ·æ–°
        # æ„å»ºç¦ç”¨åˆ—åˆ—è¡¨
        disabled_cols = ['è¯æ±‡', 'é¢‘æ¬¡']
        if 'è¯æ€§' in df_words.columns:
            disabled_cols.extend(['è¯æ€§', 'è¯æ€§åˆ†ç±»'])
        if 'ä¸­æ–‡' in df_words.columns:
            disabled_cols.append('ä¸­æ–‡')
        if 'æ˜¯å¦ä¸ºè¯æ ¹' in df_words.columns:
            disabled_cols.extend(['æ˜¯å¦ä¸ºè¯æ ¹', 'ä½œä¸ºè¯æ ¹çš„æ‰©å±•æ•°'])
        if 'æ¥æºè¯æ ¹' in df_words.columns:
            disabled_cols.extend(['æ¥æºè¯æ ¹', 'æ¥æºè¯æ ¹æ•°'])

        edited_df = st.data_editor(
            df_words,
            width='stretch',
            height=400,
            disabled=disabled_cols,
            hide_index=True,
            key="words_editor",  # æ·»åŠ å›ºå®škey
            column_config={
                "é€‰æ‹©": st.column_config.CheckboxColumn(
                    "é€‰æ‹©",
                    help="å‹¾é€‰è¦å¯¼å‡ºçš„è¯æ±‡",
                    default=False,
                )
            }
        )

        # æ›´æ–°session_stateä¸­çš„é€‰æ‹©ï¼ˆä¸è§¦å‘rerunï¼‰
        st.session_state.selected_words = set(edited_df[edited_df['é€‰æ‹©']]['è¯æ±‡'].tolist())

        # ========== 5. å¯¼å‡ºåŠŸèƒ½ ==========
        st.header("5ï¸âƒ£ å¯¼å‡ºç»“æœ")

        # å¯¼å‡ºé€‰é¡¹
        export_selected_only = st.checkbox(
            "ä»…å¯¼å‡ºé€‰ä¸­çš„è¯æ±‡",
            value=False,
            help=f"å½“å‰å·²é€‰æ‹© {len(st.session_state.selected_words)} ä¸ªè¯"
        )

        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        if export_selected_only and st.session_state.selected_words:
            df_export = edited_df[edited_df['é€‰æ‹©']].copy()
            df_export = df_export.drop(columns=['é€‰æ‹©'])
            st.info(f"âœ“ å°†å¯¼å‡º {len(df_export)} ä¸ªé€‰ä¸­çš„è¯")
        else:
            df_export = edited_df.drop(columns=['é€‰æ‹©']).copy()

        col1, col2, col3 = st.columns(3)

        with col1:
            # å¯¼å‡ºCSV
            csv = df_export.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“„ ä¸‹è½½CSV",
                data=csv,
                file_name="keywords_segmented.csv",
                mime="text/csv"
            )

        with col2:
            # å¯¼å‡ºHTMLï¼ˆå¸¦ç­›é€‰åŠŸèƒ½ï¼‰
            html = df_export.to_html(index=False, escape=False, table_id='dataTable')

            # æ„å»ºè¯æ€§ç­›é€‰é€‰é¡¹ï¼ˆå¦‚æœæœ‰è¯æ€§åˆ—ï¼‰
            pos_filter_html = ""
            pos_filter_js = ""
            if 'è¯æ€§' in df_export.columns:
                # è·å–æ‰€æœ‰å”¯ä¸€çš„è¯æ€§
                unique_pos = df_export['è¯æ€§'].unique().tolist()
                pos_options = ''.join([f'<option value="{pos}">{pos}</option>' for pos in sorted(unique_pos)])

                pos_filter_html = f"""
                        <div class="filter-row">
                            <span class="filter-label">è¯æ€§:</span>
                            <select id="posFilter" class="filter-input" onchange="filterTable()" style="max-width: 200px;">
                                <option value="">å…¨éƒ¨è¯æ€§</option>
                                {pos_options}
                            </select>
                        </div>
                """

                # è¯æ€§åˆ—çš„ç´¢å¼•ï¼ˆå‡è®¾è¯æ€§åˆ—åœ¨ç¬¬3åˆ—ï¼Œç´¢å¼•ä¸º2ï¼‰
                pos_col_index = df_export.columns.tolist().index('è¯æ€§')

                pos_filter_js = f"""
                            // æ£€æŸ¥è¯æ€§ç­›é€‰
                            var posFilter = document.getElementById('posFilter').value;
                            var posMatch = true;
                            if (posFilter && cells.length > {pos_col_index}) {{
                                var pos = cells[{pos_col_index}].textContent;
                                if (pos !== posFilter) {{
                                    posMatch = false;
                                }}
                            }}
                """

                # ä¿®æ”¹æ˜¾ç¤ºé€»è¾‘
                pos_filter_js += """
                            // æ˜¾ç¤ºæˆ–éšè—è¡Œ
                            if (wordMatch && freqMatch && posMatch) {
                                rows[i].style.display = '';
                                visibleCount++;
                            } else {
                                rows[i].style.display = 'none';
                            }
                """
            else:
                pos_filter_js = """
                            // æ˜¾ç¤ºæˆ–éšè—è¡Œ
                            if (wordMatch && freqMatch) {
                                rows[i].style.display = '';
                                visibleCount++;
                            } else {
                                rows[i].style.display = 'none';
                            }
                """

            html_full = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <title>å…³é”®è¯åˆ†è¯ç»“æœ</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
                    .container {{ max-width: 1400px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                    h1 {{ color: #333; text-align: center; margin-bottom: 30px; }}
                    .filter-container {{ margin: 20px 0; padding: 20px; background-color: #f9f9f9; border-radius: 5px; border: 1px solid #ddd; }}
                    .filter-row {{ display: flex; gap: 15px; align-items: center; flex-wrap: wrap; margin-bottom: 10px; }}
                    .filter-input {{ padding: 10px; font-size: 14px; border: 1px solid #ccc; border-radius: 4px; flex: 1; min-width: 200px; }}
                    .filter-input:focus {{ outline: none; border-color: #4CAF50; }}
                    .filter-label {{ font-weight: bold; color: #555; min-width: 80px; }}
                    #resultCount {{ color: #4CAF50; font-weight: bold; font-size: 14px; }}
                    .reset-btn {{ padding: 10px 20px; background-color: #f44336; color: white; border: none; border-radius: 4px; cursor: pointer; font-size: 14px; }}
                    .reset-btn:hover {{ background-color: #da190b; }}
                    table {{ border-collapse: collapse; width: 100%; margin-top: 20px; }}
                    th, td {{ border: 1px solid #ddd; padding: 12px 8px; text-align: left; }}
                    th {{ background-color: #4CAF50; color: white; position: sticky; top: 0; z-index: 10; }}
                    tr:nth-child(even) {{ background-color: #f2f2f2; }}
                    tr:hover {{ background-color: #e8f5e9; }}
                    .table-wrapper {{ max-height: 600px; overflow-y: auto; border: 1px solid #ddd; border-radius: 5px; }}
                </style>
            </head>
            <body>
                <div class="container">
                    <h1>ğŸ“Š å…³é”®è¯åˆ†è¯ç»“æœ</h1>

                    <div class="filter-container">
                        <h3 style="margin-top: 0; color: #333;">ğŸ” ç­›é€‰å·¥å…·</h3>
                        <div class="filter-row">
                            <span class="filter-label">å…³é”®è¯:</span>
                            <input type="text" id="wordFilter" class="filter-input"
                                   placeholder="è¾“å…¥å…³é”®è¯è¿›è¡Œç­›é€‰..." onkeyup="filterTable()">
                        </div>
                        <div class="filter-row">
                            <span class="filter-label">æœ€å°é¢‘æ¬¡:</span>
                            <input type="number" id="minFreq" class="filter-input"
                                   placeholder="æœ€å°é¢‘æ¬¡" onkeyup="filterTable()" style="max-width: 150px;">
                            <span class="filter-label">æœ€å¤§é¢‘æ¬¡:</span>
                            <input type="number" id="maxFreq" class="filter-input"
                                   placeholder="æœ€å¤§é¢‘æ¬¡" onkeyup="filterTable()" style="max-width: 150px;">
                            <button class="reset-btn" onclick="resetFilters()">ğŸ”„ é‡ç½®ç­›é€‰</button>
                        </div>
                        {pos_filter_html}
                        <div style="margin-top: 15px;">
                            <span id="resultCount"></span>
                        </div>
                    </div>

                    <div class="table-wrapper">
                        {html}
                    </div>
                </div>

                <script>
                    // ç­›é€‰è¡¨æ ¼å‡½æ•°
                    function filterTable() {{
                        var wordFilter = document.getElementById('wordFilter').value.toLowerCase();
                        var minFreq = document.getElementById('minFreq').value;
                        var maxFreq = document.getElementById('maxFreq').value;

                        var table = document.getElementById('dataTable');
                        var rows = table.getElementsByTagName('tr');
                        var visibleCount = 0;

                        // ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
                        for (var i = 1; i < rows.length; i++) {{
                            var cells = rows[i].getElementsByTagName('td');
                            if (cells.length === 0) continue;

                            var word = cells[0].textContent.toLowerCase();
                            var frequency = parseInt(cells[1].textContent);

                            // æ£€æŸ¥å…³é”®è¯ç­›é€‰
                            var wordMatch = true;
                            if (wordFilter) {{
                                // æ£€æŸ¥æ‰€æœ‰åˆ—ï¼ˆåŒ…æ‹¬å¯èƒ½çš„ä¸­æ–‡ç¿»è¯‘åˆ—ï¼‰
                                wordMatch = false;
                                for (var j = 0; j < cells.length; j++) {{
                                    if (cells[j].textContent.toLowerCase().indexOf(wordFilter) > -1) {{
                                        wordMatch = true;
                                        break;
                                    }}
                                }}
                            }}

                            // æ£€æŸ¥é¢‘æ¬¡ç­›é€‰
                            var freqMatch = true;
                            if (minFreq && frequency < parseInt(minFreq)) {{
                                freqMatch = false;
                            }}
                            if (maxFreq && frequency > parseInt(maxFreq)) {{
                                freqMatch = false;
                            }}

                            {pos_filter_js}
                        }}

                        // æ›´æ–°ç»“æœè®¡æ•°
                        var totalRows = rows.length - 1;
                        document.getElementById('resultCount').textContent =
                            'âœ“ æ˜¾ç¤º ' + visibleCount + ' / ' + totalRows + ' æ¡ç»“æœ';
                    }}

                    // é‡ç½®ç­›é€‰
                    function resetFilters() {{
                        document.getElementById('wordFilter').value = '';
                        document.getElementById('minFreq').value = '';
                        document.getElementById('maxFreq').value = '';
                        {'document.getElementById("posFilter").value = "";' if pos_filter_html else ''}
                        filterTable();
                    }}

                    // é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–
                    window.onload = function() {{
                        var table = document.getElementById('dataTable');
                        if (table) {{
                            var totalRows = table.getElementsByTagName('tr').length - 1;
                            document.getElementById('resultCount').textContent =
                                'âœ“ æ˜¾ç¤º ' + totalRows + ' / ' + totalRows + ' æ¡ç»“æœ';
                        }}
                    }};
                </script>
            </body>
            </html>
            """
            st.download_button(
                label="ğŸŒ ä¸‹è½½HTML",
                data=html_full,
                file_name="keywords_segmented.html",
                mime="text/html"
            )

        with col3:
            # å¤åˆ¶åˆ°å‰ªè´´æ¿
            text_for_copy = df_export.to_string(index=False)
            st.text_area(
                "å¤åˆ¶å†…å®¹",
                value=text_for_copy,
                height=100,
                help="å…¨é€‰å¹¶å¤åˆ¶æ–‡æœ¬"
            )

        # æ·»åŠ åˆ°è¯æ ¹ç®¡ç†
        st.markdown("---")
        st.subheader("ğŸŒ± æ·»åŠ åˆ°è¯æ ¹ç®¡ç†")

        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown("""
            **å°†é€‰ä¸­çš„è¯æ±‡æ·»åŠ ä¸ºè¯æ ¹ï¼ˆseed_wordï¼‰**

            é€‰ä¸­çš„è¯æ±‡å°†è¢«æ·»åŠ åˆ°è¯æ ¹ç®¡ç†ç³»ç»Ÿä¸­ï¼Œåç»­å¯ä»¥ï¼š
            - ä½¿ç”¨ ğŸ¤– æ‰¹é‡è‡ªåŠ¨åˆ†ç±» åŠŸèƒ½è‡ªåŠ¨åˆ†é…Tokenç±»åˆ«
            - æ‰‹åŠ¨ç¼–è¾‘è¯æ ¹çš„å®šä¹‰ã€å•†ä¸šä»·å€¼ç­‰ä¿¡æ¯
            - å…³è”è¯æ ¹åˆ°éœ€æ±‚å¡ç‰‡
            """)

        with col2:
            add_to_seeds_btn = st.button(
                "â• æ·»åŠ é€‰ä¸­è¯æ±‡åˆ°è¯æ ¹",
                type="primary",
                disabled=len(st.session_state.selected_words) == 0,
                help=f"å°† {len(st.session_state.selected_words)} ä¸ªé€‰ä¸­çš„è¯æ±‡æ·»åŠ ä¸ºè¯æ ¹"
            )

        if add_to_seeds_btn:
            add_selected_words_to_seeds()


def add_selected_words_to_seeds():
    """å°†é€‰ä¸­çš„è¯æ±‡æ·»åŠ åˆ°seed_wordsè¡¨"""
    try:
        selected_words = st.session_state.selected_words

        if not selected_words:
            st.warning("âš ï¸ æ²¡æœ‰é€‰ä¸­ä»»ä½•è¯æ±‡")
            return

        with st.spinner(f"æ­£åœ¨æ·»åŠ  {len(selected_words)} ä¸ªè¯æ±‡åˆ°è¯æ ¹ç®¡ç†..."):
            imported_count = 0
            updated_count = 0
            skipped_count = 0

            with SeedWordRepository() as seed_repo:
                for word in selected_words:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = seed_repo.get_seed_word(word)

                    if existing:
                        # å·²å­˜åœ¨ï¼Œåªæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        seed_repo.update_expansion_stats(word)
                        updated_count += 1
                    else:
                        # åˆ›å»ºæ–°è¯æ ¹ï¼ˆæœªåˆ†ç±»çŠ¶æ€ï¼Œæ¥æºæ ‡è®°ä¸ºphase0_selectionï¼‰
                        seed_repo.create_or_update_seed_word(
                            seed_word=word,
                            token_types=None,  # å¾…åˆ†ç±»
                            primary_token_type=None,  # å¾…åˆ†ç±»
                            source='phase0_selection',
                            status='active'
                        )

                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        seed_repo.update_expansion_stats(word)
                        imported_count += 1

            # æ˜¾ç¤ºç»“æœ
            st.success(f"âœ“ æ·»åŠ å®Œæˆï¼")

            col1, col2, col3 = st.columns(3)
            col1.metric("æ–°å¢è¯æ ¹", imported_count)
            col2.metric("æ›´æ–°ç»Ÿè®¡", updated_count)
            col3.metric("æ€»å¤„ç†", imported_count + updated_count)

            # æç¤ºåç»­æ“ä½œ
            if imported_count > 0:
                st.info("""
                ğŸ’¡ **åç»­æ“ä½œå»ºè®®**ï¼š
                1. è¿›å…¥ **ğŸŒ± è¯æ ¹ç®¡ç†** é¡µé¢
                2. ç‚¹å‡» **ğŸ¤– æ‰¹é‡è‡ªåŠ¨åˆ†ç±»** æŒ‰é’®ï¼Œä¸ºæ–°è¯æ ¹è‡ªåŠ¨åˆ†é…Tokenç±»åˆ«
                3. äººå·¥å¤æŸ¥å¹¶è°ƒæ•´åˆ†ç±»ç»“æœ
                4. ä¸ºé‡è¦è¯æ ¹æ·»åŠ å®šä¹‰å’Œå•†ä¸šä»·å€¼
                """)

                # æ¸…ç©ºé€‰æ‹©
                if st.button("ğŸ”„ æ¸…ç©ºé€‰æ‹©å¹¶ç»§ç»­"):
                    st.session_state.selected_words = set()
                    st.rerun()

    except Exception as e:
        st.error(f"âŒ æ·»åŠ å¤±è´¥: {str(e)}")
        import traceback
        st.error(traceback.format_exc())


if __name__ == "__main__":
    main()
