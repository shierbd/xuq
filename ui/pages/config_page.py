"""
é…ç½®ç®¡ç†é¡µé¢
"""
import streamlit as st
import sys
from pathlib import Path
import json

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from config.settings import (
    DATABASE_CONFIG, LLM_PROVIDER, LLM_CONFIG,
    EMBEDDING_MODEL, EMBEDDING_MODEL_VERSION, EMBEDDING_DIM,
    LARGE_CLUSTER_CONFIG, SMALL_CLUSTER_CONFIG
)


def load_env_config():
    """ä».envæ–‡ä»¶åŠ è½½å½“å‰é…ç½®"""
    import os
    from dotenv import load_dotenv

    # é‡æ–°åŠ è½½.envæ–‡ä»¶
    env_file = project_root / ".env"
    if env_file.exists():
        load_dotenv(env_file, override=True)

    # è¯»å–é…ç½®
    current_provider = os.getenv('LLM_PROVIDER', 'deepseek')
    current_api_key = os.getenv(f'{current_provider.upper()}_API_KEY', '')
    current_model = os.getenv(f'{current_provider.upper()}_MODEL', '')

    # æ ¹æ®providerè®¾ç½®é»˜è®¤æ¨¡å‹
    if not current_model:
        if current_provider == 'deepseek':
            current_model = 'deepseek-chat'
        elif current_provider == 'openai':
            current_model = 'gpt-4o-mini'
        elif current_provider == 'anthropic':
            current_model = 'claude-3-5-sonnet-20241022'

    return {
        'provider': current_provider,
        'api_key': current_api_key,
        'model': current_model
    }


def save_env_config(provider, api_key, model):
    """ä¿å­˜é…ç½®åˆ°.envæ–‡ä»¶"""
    env_file = project_root / ".env"

    # è¯»å–ç°æœ‰.envå†…å®¹
    env_lines = []
    if env_file.exists():
        with open(env_file, 'r', encoding='utf-8') as f:
            env_lines = f.readlines()

    # æ›´æ–°é…ç½®
    updated = {
        'LLM_PROVIDER': False,
        f'{provider.upper()}_API_KEY': False,
        f'{provider.upper()}_MODEL': False
    }

    new_lines = []
    for line in env_lines:
        line_stripped = line.strip()
        if line_stripped.startswith('LLM_PROVIDER='):
            new_lines.append(f'LLM_PROVIDER={provider}\n')
            updated['LLM_PROVIDER'] = True
        elif line_stripped.startswith(f'{provider.upper()}_API_KEY='):
            new_lines.append(f'{provider.upper()}_API_KEY={api_key}\n')
            updated[f'{provider.upper()}_API_KEY'] = True
        elif line_stripped.startswith(f'{provider.upper()}_MODEL='):
            new_lines.append(f'{provider.upper()}_MODEL={model}\n')
            updated[f'{provider.upper()}_MODEL'] = True
        else:
            new_lines.append(line)

    # æ·»åŠ æœªæ›´æ–°çš„é…ç½®
    if not updated['LLM_PROVIDER']:
        new_lines.append(f'LLM_PROVIDER={provider}\n')
    if not updated[f'{provider.upper()}_API_KEY']:
        new_lines.append(f'{provider.upper()}_API_KEY={api_key}\n')
    if not updated[f'{provider.upper()}_MODEL']:
        new_lines.append(f'{provider.upper()}_MODEL={model}\n')

    # ä¿å­˜
    with open(env_file, 'w', encoding='utf-8') as f:
        f.writelines(new_lines)


def render():
    st.markdown('<div class="main-header">âš™ï¸ é…ç½®ç®¡ç†</div>', unsafe_allow_html=True)

    st.markdown("""
    ### ç³»ç»Ÿé…ç½®

    å¿«é€Ÿé…ç½®LLMæä¾›å•†å’ŒAPIå¯†é’¥ï¼Œæˆ–ç¼–è¾‘è¯¦ç»†é…ç½®æ–‡ä»¶ã€‚
    """)

    st.markdown("---")

    # ============ æ–°å¢ï¼šLLMé…ç½®è¡¨å• ============
    st.markdown("## ğŸš€ å¿«é€Ÿé…ç½®LLM")

    # åŠ è½½å½“å‰é…ç½®
    current_config = load_env_config()

    # æ˜¾ç¤ºå½“å‰é…ç½®çŠ¶æ€
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å½“å‰æä¾›å•†", current_config['provider'].upper())
    with col2:
        st.metric("å½“å‰æ¨¡å‹", current_config['model'])
    with col3:
        api_key_display = current_config['api_key']
        if api_key_display:
            api_key_display = f"{api_key_display[:8]}...{api_key_display[-4:]}"
        else:
            api_key_display = "æœªé…ç½®"
        st.metric("APIå¯†é’¥", api_key_display)

    st.info("ğŸ’¡ ä¿®æ”¹ä¸‹æ–¹é…ç½®åç‚¹å‡»ä¿å­˜ï¼Œé…ç½®ä¼šç«‹å³ä¿å­˜åˆ° `.env` æ–‡ä»¶ã€‚åˆ·æ–°é¡µé¢åä¼šæ˜¾ç¤ºæœ€æ–°é…ç½®ã€‚")

    with st.form("llm_config_form"):
        col1, col2 = st.columns(2)

        with col1:
            # æä¾›å•†é€‰æ‹© - ä½¿ç”¨å½“å‰é…ç½®ä½œä¸ºé»˜è®¤å€¼
            provider_options = ["deepseek", "openai", "anthropic"]
            default_provider_index = provider_options.index(current_config['provider']) if current_config['provider'] in provider_options else 0

            provider = st.selectbox(
                "é€‰æ‹©LLMæä¾›å•†",
                options=provider_options,
                index=default_provider_index,
                help="æ¨èä½¿ç”¨DeepSeekï¼ˆæˆæœ¬æœ€ä½ï¼‰æˆ–OpenAIï¼ˆæ€§ä»·æ¯”é«˜ï¼‰"
            )

            # æ ¹æ®é€‰æ‹©çš„æä¾›å•†æ˜¾ç¤ºä¸åŒçš„æ¨¡å‹é€‰é¡¹
            if provider == "deepseek":
                model_options = ["deepseek-chat", "deepseek-coder"]
                default_model_index = model_options.index(current_config['model']) if current_config['model'] in model_options else 0

                model = st.selectbox(
                    "é€‰æ‹©æ¨¡å‹",
                    options=model_options,
                    index=default_model_index,
                    help="deepseek-chat: é€šç”¨æ¨¡å‹\ndeeseek-coder: ä»£ç ä¸“ç”¨"
                )
                api_url = st.text_input(
                    "API Base URL",
                    value="https://api.deepseek.com/v1",
                    help="é€šå¸¸ä½¿ç”¨é»˜è®¤å€¼å³å¯"
                )
            elif provider == "openai":
                model_options = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
                default_model_index = model_options.index(current_config['model']) if current_config['model'] in model_options else 0

                model = st.selectbox(
                    "é€‰æ‹©æ¨¡å‹",
                    options=model_options,
                    index=default_model_index,
                    help="æ¨èä½¿ç”¨gpt-4o-miniï¼ˆæ€§ä»·æ¯”æœ€é«˜ï¼‰"
                )
                api_url = st.text_input(
                    "API Base URL",
                    value="https://api.openai.com/v1",
                    help="å¦‚æœä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼Œå¯ä¿®æ”¹æ­¤åœ°å€"
                )
            else:  # anthropic
                model_options = ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229"]
                default_model_index = model_options.index(current_config['model']) if current_config['model'] in model_options else 0

                model = st.selectbox(
                    "é€‰æ‹©æ¨¡å‹",
                    options=model_options,
                    index=default_model_index,
                    help="Claude Sonnet: å¹³è¡¡æ€§èƒ½\nClaude Opus: æœ€é«˜æ€§èƒ½"
                )
                api_url = None

        with col2:
            # APIå¯†é’¥è¾“å…¥ - æ˜¾ç¤ºå ä½ç¬¦æç¤ºå½“å‰æœ‰é…ç½®
            api_key_placeholder = f"å½“å‰å·²é…ç½® {current_config['provider'].upper()} API Key" if current_config['api_key'] else f"è¯·è¾“å…¥æ‚¨çš„{provider.upper()} API Key"

            api_key = st.text_input(
                "APIå¯†é’¥",
                type="password",
                placeholder=api_key_placeholder,
                help="ç•™ç©ºåˆ™ä¿æŒå½“å‰å¯†é’¥ä¸å˜ï¼›è¾“å…¥æ–°å¯†é’¥åˆ™ä¼šè¦†ç›–"
            )

            # å‚æ•°é…ç½®
            temperature = st.slider(
                "Temperatureï¼ˆåˆ›é€ æ€§ï¼‰",
                min_value=0.0,
                max_value=1.0,
                value=0.3,
                step=0.1,
                help="0.0=ç¡®å®šæ€§å¼ºï¼Œ1.0=åˆ›é€ æ€§å¼ºã€‚æ¨è0.3"
            )

            max_tokens = st.number_input(
                "æœ€å¤§Tokenæ•°",
                min_value=500,
                max_value=8000,
                value=2000,
                step=500,
                help="å•æ¬¡è¯·æ±‚æœ€å¤šç”Ÿæˆçš„tokenæ•°"
            )

        # æäº¤æŒ‰é’®
        col1, col2, col3 = st.columns([1, 1, 2])

        with col1:
            submit_button = st.form_submit_button(
                "ğŸ’¾ ä¿å­˜é…ç½®",
                type="primary",
                use_container_width=True
            )

        with col2:
            test_button = st.form_submit_button(
                "ğŸ§ª æµ‹è¯•è¿æ¥",
                use_container_width=True
            )

    # å¤„ç†è¡¨å•æäº¤
    if submit_button:
        # å¦‚æœAPIå¯†é’¥ä¸ºç©ºï¼Œä½¿ç”¨å½“å‰é…ç½®çš„å¯†é’¥
        final_api_key = api_key if api_key else current_config['api_key']

        if not final_api_key:
            st.error("âŒ è¯·è¾“å…¥APIå¯†é’¥")
        else:
            try:
                # ä¿å­˜åˆ°.env
                save_env_config(provider, final_api_key, model)

                st.success(f"""
                âœ… é…ç½®å·²ä¿å­˜ï¼

                - **æä¾›å•†**: {provider}
                - **æ¨¡å‹**: {model}
                - **APIå¯†é’¥**: {final_api_key[:8]}...{final_api_key[-4:]}

                ğŸ’¡ **é…ç½®å·²ç«‹å³ç”Ÿæ•ˆ**ï¼Œåˆ·æ–°é¡µé¢å³å¯çœ‹åˆ°æœ€æ–°é…ç½®
                """)

                st.info("ğŸ”„ å¦‚æœéœ€è¦åœ¨Phase 3/4/5ä¸­ä½¿ç”¨æ–°é…ç½®ï¼Œè¯·é‡å¯Web UI")

                # æç¤ºç”¨æˆ·åˆ·æ–°é¡µé¢
                st.warning("âš ï¸ ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®åˆ·æ–°é¡µé¢æŸ¥çœ‹æœ€æ–°é…ç½®")
                if st.button("ğŸ”„ åˆ·æ–°é¡µé¢", type="secondary"):
                    st.rerun()

            except Exception as e:
                st.error(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")

    if test_button:
        # å¦‚æœAPIå¯†é’¥ä¸ºç©ºï¼Œä½¿ç”¨å½“å‰é…ç½®çš„å¯†é’¥
        test_api_key = api_key if api_key else current_config['api_key']

        if not test_api_key:
            st.error("âŒ è¯·å…ˆè¾“å…¥APIå¯†é’¥ï¼Œæˆ–ç¡®ä¿å·²ä¿å­˜è¿‡APIå¯†é’¥")
        else:
            with st.spinner(f"æ­£åœ¨æµ‹è¯• {provider} è¿æ¥..."):
                try:
                    # ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡è¿›è¡Œæµ‹è¯•
                    import os
                    os.environ['LLM_PROVIDER'] = provider
                    os.environ[f'{provider.upper()}_API_KEY'] = test_api_key
                    os.environ[f'{provider.upper()}_MODEL'] = model
                    if api_url:
                        os.environ[f'{provider.upper()}_BASE_URL'] = api_url

                    # é‡æ–°åŠ è½½é…ç½®æ¨¡å—
                    import importlib
                    import config.settings
                    importlib.reload(config.settings)

                    # ç°åœ¨å¯¼å…¥LLMClientï¼Œè¿™æ ·å®ƒä¼šè¯»å–æ–°çš„é…ç½®
                    from ai.client import LLMClient

                    # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆä¼šä½¿ç”¨åˆšåˆšreloadçš„é…ç½®ï¼‰
                    client = LLMClient()

                    # å‘é€æµ‹è¯•æ¶ˆæ¯
                    response = client._call_llm([{
                        "role": "user",
                        "content": "è¯·ç”¨ä¸­æ–‡å›å¤ï¼šä½ å¥½ï¼"
                    }])

                    st.success(f"âœ… {provider.upper()} è¿æ¥æˆåŠŸï¼")
                    st.info(f"**æ¨¡å‹å›å¤**: {response}")

                except Exception as e:
                    st.error(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")
                    st.warning("è¯·æ£€æŸ¥ï¼š\n1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®\n2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n3. APIé¢åº¦æ˜¯å¦å……è¶³")

                    # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
                    with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
                        import traceback
                        st.code(traceback.format_exc())

    st.markdown("---")

    # æ•°æ®åº“é…ç½®
    st.markdown("## ğŸ—„ï¸ æ•°æ®åº“é…ç½®")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### å½“å‰é…ç½®")
        st.json(DATABASE_CONFIG)

    with col2:
        st.markdown("### æµ‹è¯•è¿æ¥")

        if st.button("ğŸ”Œ æµ‹è¯•æ•°æ®åº“è¿æ¥", use_container_width=True):
            try:
                from storage.repository import PhraseRepository

                with PhraseRepository() as repo:
                    count = repo.get_phrase_count()

                st.success(f"âœ… è¿æ¥æˆåŠŸï¼æ•°æ®åº“æœ‰ {count:,} æ¡çŸ­è¯­")

            except Exception as e:
                st.error(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")

        st.markdown("### ä¿®æ”¹æ–¹æ³•")
        st.info("""
        ç¼–è¾‘ `config/settings.py` æ–‡ä»¶ï¼š

        ```python
        DATABASE_CONFIG = {
            'host': 'localhost',
            'port': 3306,
            'user': 'your_user',
            'password': 'your_password',
            'database': 'search_demand_mining',
        }
        ```
        """)

    st.markdown("---")

    # LLMé…ç½®
    st.markdown("## ğŸ¤– LLMé…ç½®")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### å½“å‰æä¾›å•†")
        st.info(f"**Provider**: {LLM_PROVIDER}")

        st.markdown("### é…ç½®è¯¦æƒ…")
        if LLM_PROVIDER in LLM_CONFIG:
            config = LLM_CONFIG[LLM_PROVIDER].copy()
            # éšè—APIå¯†é’¥
            if 'api_key' in config:
                config['api_key'] = "***" + config['api_key'][-4:] if len(config['api_key']) > 4 else "****"
            st.json(config)
        else:
            st.warning(f"âš ï¸ æœªæ‰¾åˆ° {LLM_PROVIDER} çš„é…ç½®")

    with col2:
        st.markdown("### æµ‹è¯•LLM")

        if st.button("ğŸ§ª æµ‹è¯•LLMè¿æ¥", use_container_width=True):
            try:
                from ai.client import LLMClient

                client = LLMClient()
                response = client._call_llm([{
                    "role": "user",
                    "content": "è¯·ç”¨ä¸­æ–‡å›å¤ï¼šä½ å¥½ï¼Œæµ‹è¯•è¿æ¥ï¼"
                }])

                st.success(f"âœ… LLMå“åº”: {response}")

            except Exception as e:
                st.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

        st.markdown("### å¯ç”¨æä¾›å•†")
        st.markdown("""
        - **openai**: GPT-4o-miniï¼ˆæ¨èï¼Œæ€§ä»·æ¯”é«˜ï¼‰
        - **anthropic**: Claude Sonnetï¼ˆå‡†ç¡®ç‡é«˜ï¼Œæˆæœ¬è¾ƒé«˜ï¼‰
        - **deepseek**: DeepSeekï¼ˆæœ€ä¾¿å®œï¼‰

        ä¿®æ”¹ `config/settings.py`:
        ```python
        LLM_PROVIDER = "openai"  # æˆ– anthropic, deepseek
        ```
        """)

    st.markdown("---")

    # Embeddingé…ç½®
    st.markdown("## ğŸ§® Embeddingé…ç½®")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### å½“å‰é…ç½®")
        embedding_config = {
            "model": EMBEDDING_MODEL,
            "version": EMBEDDING_MODEL_VERSION,
            "dimension": EMBEDDING_DIM
        }
        st.json(embedding_config)

    with col2:
        st.markdown("### è¯´æ˜")
        st.info(f"""
        **Model**: {EMBEDDING_MODEL}
        **Version**: {EMBEDDING_MODEL_VERSION}
        **Dimension**: {EMBEDDING_DIM}

        ä½¿ç”¨æœ¬åœ°Sentence Transformeræ¨¡å‹è¿›è¡Œembeddingè®¡ç®—ã€‚
        æˆæœ¬: å…è´¹ï¼ˆæœ¬åœ°è®¡ç®—ï¼‰
        """)

        if st.button("ğŸ§ª æµ‹è¯•Embedding", use_container_width=True):
            try:
                from core.embedding import EmbeddingService

                service = EmbeddingService(use_cache=False)
                embeddings = service.embed_texts(["test phrase"], show_progress=False)

                st.success(f"âœ… Embeddingç”ŸæˆæˆåŠŸï¼ç»´åº¦: {embeddings.shape[1]}")

            except Exception as e:
                st.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

    st.markdown("---")

    # èšç±»é…ç½®
    st.markdown("## ğŸ”„ èšç±»é…ç½®")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### å¤§ç»„èšç±» (Level A)")
        st.json(LARGE_CLUSTER_CONFIG)

        st.markdown("**å‚æ•°è¯´æ˜**:")
        st.markdown("""
        - `min_cluster_size`: æœ€å°èšç±»å¤§å°ï¼ˆé»˜è®¤30ï¼‰
          - å¢å¤§ â†’ æ›´å°‘ã€æ›´å¤§çš„ç°‡
          - å‡å° â†’ æ›´å¤šã€æ›´å°çš„ç°‡

        - `min_samples`: æœ€å°æ ·æœ¬æ•°ï¼ˆé»˜è®¤3ï¼‰
          - å¢å¤§ â†’ æ›´ç´§å¯†çš„ç°‡ï¼ˆå™ªéŸ³ç‚¹æ›´å¤šï¼‰
          - å‡å° â†’ æ›´æ¾æ•£çš„ç°‡ï¼ˆå™ªéŸ³ç‚¹æ›´å°‘ï¼‰

        - `metric`: è·ç¦»åº¦é‡ï¼ˆcosineæ¨èï¼‰
        """)

    with col2:
        st.markdown("### å°ç»„èšç±» (Level B)")
        st.json(SMALL_CLUSTER_CONFIG)

        st.markdown("**è°ƒæ•´å»ºè®®**:")
        st.markdown("""
        **å¤§ç»„èšç±»ç»“æœä¸ç†æƒ³**:
        - ç°‡å¤ªå¤šï¼ˆ>100ä¸ªï¼‰â†’ å¢å¤§ min_cluster_size åˆ° 40-50
        - ç°‡å¤ªå°‘ï¼ˆ<40ä¸ªï¼‰â†’ å‡å° min_cluster_size åˆ° 20-25
        - å™ªéŸ³ç‚¹å¤ªå¤šï¼ˆ>50%ï¼‰â†’ å‡å° min_samples åˆ° 2

        **å°ç»„èšç±»ç»“æœä¸ç†æƒ³**:
        - å°ç»„å¤ªå¤šï¼ˆ>15ä¸ª/å¤§ç»„ï¼‰â†’ å¢å¤§ min_cluster_size åˆ° 8-10
        - å°ç»„å¤ªå°‘ï¼ˆ<3ä¸ª/å¤§ç»„ï¼‰â†’ å‡å° min_cluster_size åˆ° 3-4
        """)

    st.markdown("---")

    # æ–‡ä»¶è·¯å¾„é…ç½®
    st.markdown("## ğŸ“ æ–‡ä»¶è·¯å¾„")

    paths_info = {
        "é¡¹ç›®æ ¹ç›®å½•": str(project_root),
        "æ•°æ®ç›®å½•": str(project_root / "data"),
        "åŸå§‹æ•°æ®": str(project_root / "data" / "raw"),
        "è¾“å‡ºç›®å½•": str(project_root / "data" / "output"),
        "ç¼“å­˜ç›®å½•": str(project_root / "data" / "cache"),
        "è„šæœ¬ç›®å½•": str(project_root / "scripts"),
        "é…ç½®æ–‡ä»¶": str(project_root / "config" / "settings.py")
    }

    for name, path in paths_info.items():
        col1, col2 = st.columns([1, 3])
        with col1:
            st.markdown(f"**{name}**")
        with col2:
            st.code(path, language="text")

    st.markdown("---")

    # APIæˆæœ¬ä¼°ç®—
    st.markdown("## ğŸ’° APIæˆæœ¬ä¼°ç®—")

    st.markdown("### å…¸å‹é¡¹ç›®ï¼ˆ55,275æ¡çŸ­è¯­ï¼Œ28ä¸ªé€‰ä¸­å¤§ç»„ï¼‰")

    cost_data = {
        "é˜¶æ®µ": ["Phase 2 Embedding", "Phase 4 éœ€æ±‚å¡ç‰‡", "Phase 5 Tokenåˆ†ç±»", "æ€»è®¡"],
        "OpenAI": ["$0.03", "$0.50", "$0.05", "$0.58"],
        "Anthropic": ["N/A", "$10.00", "$1.00", "$11.00"],
        "DeepSeek": ["N/A", "$0.07", "$0.01", "$0.08"]
    }

    import pandas as pd
    df = pd.DataFrame(cost_data)

    st.dataframe(df, use_container_width=True)

    st.markdown("### æˆæœ¬ä¼˜åŒ–å»ºè®®")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**æµ‹è¯•é˜¶æ®µ**:")
        st.markdown("""
        - ä½¿ç”¨ `--skip-llm` è·³è¿‡LLMè°ƒç”¨
        - ä½¿ç”¨ `--test-limit` é™åˆ¶å¤„ç†æ•°é‡
        - ä½¿ç”¨å°æ ·æœ¬æ•°æ®éªŒè¯æµç¨‹
        - Phase 2 ä½¿ç”¨æœ¬åœ°embeddingï¼ˆå…è´¹ï¼‰
        """)

    with col2:
        st.markdown("**ç”Ÿäº§é˜¶æ®µ**:")
        st.markdown("""
        - æ¨èä½¿ç”¨ OpenAI GPT-4o-miniï¼ˆæ€§ä»·æ¯”æœ€é«˜ï¼‰
        - DeepSeekæœ€ä¾¿å®œä½†è´¨é‡ç•¥ä½
        - æ‰¹é‡APIè°ƒç”¨èŠ‚çœæˆæœ¬
        - ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—
        """)

    st.markdown("---")

    # ç¯å¢ƒä¿¡æ¯
    st.markdown("## ğŸ“Š ç¯å¢ƒä¿¡æ¯")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("### Pythonç¯å¢ƒ")
        st.text(f"ç‰ˆæœ¬: {sys.version.split()[0]}")
        st.text(f"è·¯å¾„: {sys.executable}")

    with col2:
        st.markdown("### å·²å®‰è£…åŒ…")
        try:
            import streamlit
            import pandas
            import sqlalchemy
            st.text(f"streamlit: {streamlit.__version__}")
            st.text(f"pandas: {pandas.__version__}")
            st.text(f"sqlalchemy: {sqlalchemy.__version__}")
        except Exception as e:
            st.error(f"æ£€æŸ¥å¤±è´¥: {str(e)}")

    with col3:
        st.markdown("### ç³»ç»Ÿä¿¡æ¯")
        import platform
        st.text(f"ç³»ç»Ÿ: {platform.system()}")
        st.text(f"ç‰ˆæœ¬: {platform.release()}")

    st.markdown("---")

    # é…ç½®æ–‡ä»¶ç¼–è¾‘å™¨
    st.markdown("## ğŸ“ é…ç½®æ–‡ä»¶ç¼–è¾‘å™¨")

    st.warning("âš ï¸ ä¿®æ”¹é…ç½®åéœ€è¦é‡å¯åº”ç”¨æ‰èƒ½ç”Ÿæ•ˆ")

    settings_file = project_root / "config" / "settings.py"

    if settings_file.exists():
        try:
            with open(settings_file, 'r', encoding='utf-8') as f:
                content = f.read()

            edited_content = st.text_area(
                "ç¼–è¾‘ config/settings.py",
                value=content,
                height=400,
                help="ä¿®æ”¹åç‚¹å‡»ä¸‹æ–¹çš„ä¿å­˜æŒ‰é’®"
            )

            col1, col2, col3 = st.columns([1, 1, 2])

            with col1:
                if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary", use_container_width=True):
                    try:
                        with open(settings_file, 'w', encoding='utf-8') as f:
                            f.write(edited_content)
                        st.success("âœ… é…ç½®å·²ä¿å­˜ï¼è¯·é‡å¯åº”ç”¨ä½¿é…ç½®ç”Ÿæ•ˆã€‚")
                    except Exception as e:
                        st.error(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")

            with col2:
                if st.button("ğŸ”„ é‡ç½®", use_container_width=True):
                    st.rerun()

        except Exception as e:
            st.error(f"âŒ æ— æ³•è¯»å–é…ç½®æ–‡ä»¶: {str(e)}")
    else:
        st.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {settings_file}")

    st.markdown("---")

    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### é…ç½®ç®¡ç†

        æœ¬é¡µé¢æä¾›ç³»ç»Ÿé…ç½®çš„æŸ¥çœ‹å’Œæµ‹è¯•åŠŸèƒ½ã€‚

        ### ä¿®æ”¹é…ç½®

        1. **æ–¹æ³•1: åœ¨çº¿ç¼–è¾‘**
           - åœ¨é¡µé¢åº•éƒ¨çš„"é…ç½®æ–‡ä»¶ç¼–è¾‘å™¨"ä¸­ä¿®æ”¹
           - ç‚¹å‡»"ä¿å­˜é…ç½®"
           - é‡å¯åº”ç”¨

        2. **æ–¹æ³•2: ç›´æ¥ç¼–è¾‘**
           - ä½¿ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€ `config/settings.py`
           - ä¿®æ”¹ç›¸åº”é…ç½®
           - ä¿å­˜æ–‡ä»¶
           - é‡å¯åº”ç”¨

        ### æµ‹è¯•åŠŸèƒ½

        ä½¿ç”¨å„ä¸ª"æµ‹è¯•"æŒ‰é’®éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ï¼š
        - ğŸ”Œ æµ‹è¯•æ•°æ®åº“è¿æ¥
        - ğŸ§ª æµ‹è¯•LLMè¿æ¥
        - ğŸ§® æµ‹è¯•Embedding

        ### é‡è¦æç¤º

        - ä¿®æ”¹é…ç½®åå¿…é¡»é‡å¯Streamlitåº”ç”¨
        - å»ºè®®å…ˆå¤‡ä»½é…ç½®æ–‡ä»¶
        - APIå¯†é’¥è¯·å¦¥å–„ä¿ç®¡ï¼Œä¸è¦æ³„éœ²
        """)
