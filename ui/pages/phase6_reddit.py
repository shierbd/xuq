"""
Phase 6: Redditæ¿å—åˆ†æä¸æ ‡æ³¨ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. æ•°æ®å¯¼å…¥ï¼ˆCSV/Excelï¼‰
2. AIé…ç½®ç®¡ç†
3. æ¿å—åˆ—è¡¨æŸ¥çœ‹ä¸ç¼–è¾‘
4. æ ‡ç­¾ç®¡ç†ä¸ç»Ÿè®¡
5. æ•°æ®å¯¼å‡º
"""
import streamlit as st
import pandas as pd
from datetime import datetime
from pathlib import Path
import tempfile

from core.reddit_analyzer import RedditAnalyzer


def render():
    """æ¸²æŸ“Redditæ¿å—åˆ†æé¡µé¢"""
    st.title("ğŸ” Redditæ¿å—åˆ†æä¸æ ‡æ³¨ç³»ç»Ÿ")

    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“¥ æ•°æ®å¯¼å…¥",
        "âš™ï¸ AIé…ç½®",
        "ğŸ“Š æ¿å—åˆ—è¡¨",
        "ğŸ·ï¸ æ ‡ç­¾ç®¡ç†",
        "ğŸ“¤ æ•°æ®å¯¼å‡º"
    ])

    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = RedditAnalyzer()

    # Tab 1: æ•°æ®å¯¼å…¥
    with tab1:
        render_import_tab(analyzer)

    # Tab 2: AIé…ç½®
    with tab2:
        render_config_tab(analyzer)

    # Tab 3: æ¿å—åˆ—è¡¨
    with tab3:
        render_list_tab(analyzer)

    # Tab 4: æ ‡ç­¾ç®¡ç†
    with tab4:
        render_tags_tab(analyzer)

    # Tab 5: æ•°æ®å¯¼å‡º
    with tab5:
        render_export_tab(analyzer)


def render_import_tab(analyzer: RedditAnalyzer):
    """æ¸²æŸ“æ•°æ®å¯¼å…¥é€‰é¡¹å¡"""
    st.header("æ•°æ®å¯¼å…¥")

    st.markdown("""
    **æ–‡ä»¶æ ¼å¼è¦æ±‚**:
    - æ”¯æŒCSVæˆ–Excelæ–‡ä»¶
    - æ— åˆ—åï¼ŒæŒ‰åˆ—é¡ºåºè¯†åˆ«ï¼š
      1. ç¬¬1åˆ—ï¼šæ¿å—åç§°ï¼ˆå¦‚ r/Pythonï¼‰
      2. ç¬¬2åˆ—ï¼šæ¿å—æè¿°
      3. ç¬¬3åˆ—ï¼šè®¢é˜…äººæ•°
    - æè¿°ä¸ºç©ºçš„æ¿å—å°†è¢«è·³è¿‡AIåˆ†æ
    """)

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶",
        type=['csv', 'xlsx', 'xls'],
        help="é€‰æ‹©åŒ…å«Redditæ¿å—æ•°æ®çš„æ–‡ä»¶"
    )

    # æ‰¹æ¬¡ID
    batch_id = st.text_input(
        "å¯¼å…¥æ‰¹æ¬¡IDï¼ˆå¯é€‰ï¼‰",
        placeholder="ç•™ç©ºè‡ªåŠ¨ç”Ÿæˆ",
        help="ç”¨äºæ ‡è¯†æœ¬æ¬¡å¯¼å…¥çš„æ•°æ®æ‰¹æ¬¡"
    )

    # å»é‡é€‰é¡¹
    skip_duplicates = st.checkbox(
        "è·³è¿‡é‡å¤è®°å½•ï¼ˆæŒ‰æ¿å—åç§°å»é‡ï¼‰",
        value=True,
        help="å¦‚æœæ¿å—åç§°å·²å­˜åœ¨ï¼Œä¿ç•™è®¢é˜…æ•°æœ€å¤šçš„è®°å½•"
    )

    # å¯¼å…¥æŒ‰é’®
    if st.button("å¼€å§‹å¯¼å…¥", type="primary", disabled=not uploaded_file):
        if uploaded_file:
            with st.spinner("æ­£åœ¨å¯¼å…¥..."):
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                    tmp_file.write(uploaded_file.getbuffer())
                    temp_path = tmp_file.name

                # å¯¼å…¥æ•°æ®
                file_type = 'csv' if uploaded_file.name.endswith('.csv') else 'excel'

                if file_type == 'csv':
                    result = analyzer.import_from_csv(
                        temp_path,
                        batch_id=batch_id if batch_id else None,
                        skip_duplicates=skip_duplicates
                    )
                else:
                    result = analyzer.import_from_excel(
                        temp_path,
                        batch_id=batch_id if batch_id else None,
                        skip_duplicates=skip_duplicates
                    )

                # æ˜¾ç¤ºç»“æœ
                if result['success']:
                    st.success(result['message'])

                    col1, col2, col3 = st.columns(3)
                    col1.metric("å¯¼å…¥æˆåŠŸ", result['data']['imported_count'])
                    col2.metric("è·³è¿‡ï¼ˆæè¿°ä¸ºç©ºï¼‰", result['data']['skipped_count'])
                    col3.metric("é”™è¯¯", result['data']['error_count'])

                    st.info(f"æ‰¹æ¬¡ID: {result['data']['batch_id']}")
                else:
                    st.error(result['message'])
                    if result['errors']:
                        for error in result['errors']:
                            st.error(f"- {error}")


def render_config_tab(analyzer: RedditAnalyzer):
    """æ¸²æŸ“AIé…ç½®é€‰é¡¹å¡"""
    st.header("AIé…ç½®ç®¡ç†")

    # è·å–é…ç½®åˆ—è¡¨
    configs_result = analyzer.get_prompt_configs(active_only=False)

    if not configs_result['success']:
        st.error(configs_result['message'])
        return

    configs = configs_result['data']

    if not configs:
        st.warning("æ²¡æœ‰å¯ç”¨çš„é…ç½®")
        return

    # é…ç½®é€‰æ‹©
    config_names = [c['config_name'] for c in configs]
    selected_config_name = st.selectbox("é€‰æ‹©é…ç½®", config_names)

    # è·å–é€‰ä¸­çš„é…ç½®
    selected_config = next(c for c in configs if c['config_name'] == selected_config_name)

    # é…ç½®ç¼–è¾‘
    st.subheader("é…ç½®è¯¦æƒ…")

    config_name = st.text_input("é…ç½®åç§°", value=selected_config['config_name'])

    prompt_template = st.text_area(
        "æç¤ºè¯æ¨¡æ¿",
        value=selected_config['prompt_template'],
        height=300,
        help="ä½¿ç”¨ {name}, {description}, {subscribers} ä½œä¸ºå˜é‡å ä½ç¬¦"
    )

    system_message = st.text_area(
        "ç³»ç»Ÿæ¶ˆæ¯",
        value=selected_config['system_message'] or '',
        height=100,
        help="å®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸º"
    )

    col1, col2 = st.columns(2)
    temperature = col1.slider(
        "æ¸©åº¦å‚æ•°",
        0.0, 2.0,
        float(selected_config['temperature']),
        0.1,
        help="æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œè¶Šé«˜è¶Šéšæœº"
    )
    max_tokens = col2.number_input(
        "æœ€å¤§Tokenæ•°",
        100, 10000,
        selected_config['max_tokens'],
        help="é™åˆ¶AIå“åº”çš„é•¿åº¦"
    )

    col3, col4 = st.columns(2)
    is_active = col3.checkbox("å¯ç”¨", value=selected_config['is_active'])
    is_default = col4.checkbox("è®¾ä¸ºé»˜è®¤", value=selected_config['is_default'])

    description = st.text_area(
        "é…ç½®è¯´æ˜",
        value=selected_config['description'] or '',
        height=100
    )

    # ä¿å­˜æŒ‰é’®
    if st.button("ä¿å­˜é…ç½®"):
        config_data = {
            'config_name': config_name,
            'prompt_template': prompt_template,
            'system_message': system_message,
            'temperature': temperature,
            'max_tokens': max_tokens,
            'is_active': is_active,
            'is_default': is_default,
            'description': description
        }

        result = analyzer.save_prompt_config(
            config_data,
            config_id=selected_config['config_id']
        )

        if result['success']:
            st.success(result['message'])
            st.rerun()
        else:
            st.error(result['message'])


def render_list_tab(analyzer: RedditAnalyzer):
    """æ¸²æŸ“æ¿å—åˆ—è¡¨é€‰é¡¹å¡"""
    st.header("æ¿å—åˆ—è¡¨")

    # ç­›é€‰å™¨
    col1, col2, col3 = st.columns(3)

    with col1:
        status_filter = st.multiselect(
            "åˆ†æçŠ¶æ€",
            ['pending', 'processing', 'completed', 'failed', 'skipped'],
            default=['completed']
        )

    with col2:
        # è·å–æ‰€æœ‰æ ‡ç­¾
        all_tags = analyzer.get_all_tags()
        tag_filter = st.multiselect("æ ‡ç­¾ç­›é€‰", all_tags)

    with col3:
        score_range = st.slider("é‡è¦æ€§è¯„åˆ†", 1, 5, (1, 5))

    # æ’åº
    sort_by = st.selectbox(
        "æ’åºæ–¹å¼",
        ['created_at', 'subscribers', 'importance_score'],
        format_func=lambda x: {
            'created_at': 'åˆ›å»ºæ—¶é—´',
            'subscribers': 'è®¢é˜…äººæ•°',
            'importance_score': 'é‡è¦æ€§è¯„åˆ†'
        }[x]
    )

    # æŸ¥è¯¢æ•°æ®
    filters = {
        'status': status_filter,
        'tags': tag_filter,
        'importance_score_min': score_range[0],
        'importance_score_max': score_range[1]
    }

    result = analyzer.query_subreddits(
        filters=filters,
        sort_by=sort_by,
        sort_order='desc',
        limit=100
    )

    if not result['success']:
        st.error(result['message'])
        return

    total = result['data']['total']
    data = result['data']['data']

    st.info(f"å…±æ‰¾åˆ° {total} æ¡è®°å½•ï¼Œæ˜¾ç¤ºå‰ {len(data)} æ¡")

    if not data:
        st.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
        return

    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(data)

    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
    display_columns = [
        'subreddit_id', 'name', 'subscribers',
        'tag1', 'tag2', 'tag3',
        'importance_score', 'ai_analysis_status'
    ]

    df_display = df[display_columns].copy()

    # æ•°æ®è¡¨æ ¼ï¼ˆå¯ç¼–è¾‘ï¼‰
    edited_df = st.data_editor(
        df_display,
        column_config={
            "subreddit_id": st.column_config.NumberColumn("ID", disabled=True),
            "name": st.column_config.TextColumn("æ¿å—åç§°", disabled=True),
            "subscribers": st.column_config.NumberColumn("è®¢é˜…æ•°", disabled=True),
            "tag1": st.column_config.TextColumn("æ ‡ç­¾1"),
            "tag2": st.column_config.TextColumn("æ ‡ç­¾2"),
            "tag3": st.column_config.TextColumn("æ ‡ç­¾3"),
            "importance_score": st.column_config.NumberColumn(
                "è¯„åˆ†",
                min_value=1,
                max_value=5
            ),
            "ai_analysis_status": st.column_config.SelectboxColumn(
                "çŠ¶æ€",
                options=['pending', 'completed', 'failed', 'skipped']
            )
        },
        hide_index=True,
        use_container_width=True,
        num_rows="fixed"
    )

    # æ“ä½œæŒ‰é’®
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("æ‰¹é‡åˆ†æ"):
            # è·å–pendingçŠ¶æ€çš„æ¿å—
            pending_ids = df[df['ai_analysis_status'] == 'pending']['subreddit_id'].tolist()

            if not pending_ids:
                st.warning("æ²¡æœ‰å¾…åˆ†æçš„æ¿å—")
            else:
                with st.spinner(f"æ­£åœ¨åˆ†æ {len(pending_ids)} ä¸ªæ¿å—..."):
                    result = analyzer.analyze_subreddits(
                        subreddit_ids=pending_ids,
                        batch_size=10
                    )

                    if result['success']:
                        st.success(result['message'])
                        st.rerun()
                    else:
                        st.error(result['message'])

    with col2:
        if st.button("ä¿å­˜ä¿®æ”¹"):
            st.info("ä¿å­˜åŠŸèƒ½å¼€å‘ä¸­...")

    with col3:
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            "å¯¼å‡ºCSV",
            data=csv,
            file_name=f"reddit_subreddits_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )


def render_tags_tab(analyzer: RedditAnalyzer):
    """æ¸²æŸ“æ ‡ç­¾ç®¡ç†é€‰é¡¹å¡"""
    st.header("æ ‡ç­¾ç®¡ç†")

    # æ ‡ç­¾ç»Ÿè®¡
    tag_stats_result = analyzer.get_tag_statistics()

    if not tag_stats_result['success']:
        st.error(tag_stats_result['message'])
        return

    tag_counts = tag_stats_result['data']['tag_counts']

    if not tag_counts:
        st.warning("è¿˜æ²¡æœ‰æ ‡ç­¾æ•°æ®")
        return

    st.subheader("æ ‡ç­¾ç»Ÿè®¡")

    # æ ‡ç­¾äº‘ï¼ˆä½¿ç”¨columnsæ˜¾ç¤ºï¼‰
    sorted_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)

    # æ˜¾ç¤ºå‰20ä¸ªæ ‡ç­¾
    for i in range(0, min(20, len(sorted_tags)), 4):
        cols = st.columns(4)
        for j, (tag, count) in enumerate(sorted_tags[i:i+4]):
            cols[j].metric(tag, count)

    # æŒ‰æ ‡ç­¾æŸ¥çœ‹æ¿å—
    st.subheader("æŒ‰æ ‡ç­¾æŸ¥çœ‹æ¿å—")

    selected_tag = st.selectbox(
        "é€‰æ‹©æ ‡ç­¾",
        [t[0] for t in sorted_tags]
    )

    if selected_tag:
        result = analyzer.query_subreddits(
            filters={'tags': [selected_tag]},
            limit=100
        )

        if result['success']:
            data = result['data']['data']
            if data:
                df = pd.DataFrame(data)
                st.dataframe(
                    df[['name', 'subscribers', 'tag1', 'tag2', 'tag3', 'importance_score']],
                    use_container_width=True
                )
            else:
                st.info("è¯¥æ ‡ç­¾ä¸‹æ²¡æœ‰æ¿å—")


def render_export_tab(analyzer: RedditAnalyzer):
    """æ¸²æŸ“æ•°æ®å¯¼å‡ºé€‰é¡¹å¡"""
    st.header("æ•°æ®å¯¼å‡º")

    # å¯¼å‡ºæ ¼å¼
    export_format = st.radio("å¯¼å‡ºæ ¼å¼", ['CSV', 'Excel'])

    # ç­›é€‰æ¡ä»¶
    st.subheader("ç­›é€‰æ¡ä»¶")

    export_status = st.multiselect(
        "çŠ¶æ€",
        ['pending', 'completed', 'failed', 'skipped'],
        default=['completed']
    )

    all_tags = analyzer.get_all_tags()
    export_tags = st.multiselect("æ ‡ç­¾", all_tags)

    # å¯¼å‡ºæŒ‰é’®
    if st.button("ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶", type="primary"):
        filters = {
            'status': export_status,
            'tags': export_tags
        }

        with st.spinner("æ­£åœ¨ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶..."):
            result = analyzer.export_to_csv(
                filters=filters
            )

            if result['success']:
                st.success(result['message'])

                # è¯»å–æ–‡ä»¶å¹¶æä¾›ä¸‹è½½
                file_path = result['data']['file_path']
                with open(file_path, 'rb') as f:
                    file_data = f.read()

                st.download_button(
                    "ä¸‹è½½CSVæ–‡ä»¶",
                    data=file_data,
                    file_name=f"reddit_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.error(result['message'])


# ==================== ä¾¿æ·å¯¼å…¥ ====================
__all__ = ['render']
