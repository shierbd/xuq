"""
æ•°æ®åº“æ“ä½œå°è£…ï¼ˆRepositoryå±‚ï¼‰
æä¾›CRUDæ“ä½œæ¥å£ï¼Œéš”ç¦»ä¸šåŠ¡é€»è¾‘å’Œæ•°æ®åº“ç»†èŠ‚
"""
from typing import List, Dict, Optional, Tuple
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, or_
from tqdm import tqdm

from storage.models import Phrase, Demand, Token, ClusterMeta, SeedWord, get_session


class PhraseRepository:
    """çŸ­è¯­è¡¨æ“ä½œå°è£…"""

    def __init__(self, session: Session = None):
        """
        åˆå§‹åŒ–Repository

        Args:
            session: SQLAlchemyä¼šè¯ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
        """
        self.session = session or get_session()
        self._should_close = session is None  # è®°å½•æ˜¯å¦éœ€è¦å…³é—­ä¼šè¯

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self._should_close:
            self.session.close()

    def bulk_insert_phrases(self, records: List[Dict], batch_size: int = 1000) -> int:
        """
        æ‰¹é‡æ’å…¥çŸ­è¯­è®°å½•ï¼ˆä½¿ç”¨bulk_insert_mappingsæé«˜æ€§èƒ½ï¼‰

        Args:
            records: å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«phraseçš„æ‰€æœ‰å­—æ®µ
            batch_size: æ‰¹æ¬¡å¤§å°

        Returns:
            æˆåŠŸæ’å…¥çš„è®°å½•æ•°
        """
        print(f"\nğŸ“¥ æ‰¹é‡æ’å…¥çŸ­è¯­æ•°æ®ï¼ˆbatch_size={batch_size}ï¼‰...")

        total_inserted = 0
        failed_records = []

        # åˆ†æ‰¹æ’å…¥
        for i in tqdm(range(0, len(records), batch_size), desc="æ’å…¥è¿›åº¦"):
            batch = records[i:i + batch_size]
            try:
                self.session.bulk_insert_mappings(Phrase, batch)
                self.session.commit()
                total_inserted += len(batch)
            except Exception as e:
                self.session.rollback()
                print(f"\nâš ï¸  æ‰¹æ¬¡ {i//batch_size + 1} æ’å…¥å¤±è´¥: {str(e)}")
                failed_records.extend(batch)

        # å¦‚æœæœ‰å¤±è´¥è®°å½•ï¼Œå°è¯•é€æ¡æ’å…¥
        if failed_records:
            print(f"\nğŸ”„ å°è¯•é€æ¡æ’å…¥ {len(failed_records)} æ¡å¤±è´¥è®°å½•...")
            for record in tqdm(failed_records, desc="é€æ¡æ’å…¥"):
                try:
                    phrase_obj = Phrase(**record)
                    self.session.add(phrase_obj)
                    self.session.commit()
                    total_inserted += 1
                except Exception as e:
                    self.session.rollback()
                    # å¿½ç•¥é‡å¤è®°å½•é”™è¯¯
                    if 'Duplicate entry' in str(e) or 'UNIQUE constraint' in str(e):
                        continue
                    else:
                        print(f"âš ï¸  è®°å½•æ’å…¥å¤±è´¥: {record.get('phrase', 'unknown')} - {str(e)}")

        print(f"âœ“ æˆåŠŸæ’å…¥ {total_inserted} æ¡è®°å½•")
        return total_inserted

    def get_phrase_count(self) -> int:
        """è·å–çŸ­è¯­æ€»æ•°"""
        return self.session.query(func.count(Phrase.phrase_id)).scalar()

    def get_phrase_by_text(self, phrase_text: str) -> Optional[Phrase]:
        """æ ¹æ®çŸ­è¯­æ–‡æœ¬æŸ¥è¯¢è®°å½•"""
        return self.session.query(Phrase).filter(Phrase.phrase == phrase_text).first()

    def get_phrases_by_cluster(self, cluster_id: int, cluster_level: str = 'A') -> List[Phrase]:
        """
        è·å–æŒ‡å®šèšç±»çš„æ‰€æœ‰çŸ­è¯­

        Args:
            cluster_id: èšç±»ID
            cluster_level: èšç±»çº§åˆ«ï¼ˆ'A'æˆ–'B'ï¼‰

        Returns:
            çŸ­è¯­åˆ—è¡¨
        """
        if cluster_level == 'A':
            return self.session.query(Phrase).filter(Phrase.cluster_id_A == cluster_id).all()
        else:
            return self.session.query(Phrase).filter(Phrase.cluster_id_B == cluster_id).all()

    def get_phrases_by_round(self, round_id: int) -> List[Phrase]:
        """è·å–æŒ‡å®šè½®æ¬¡çš„çŸ­è¯­"""
        return self.session.query(Phrase).filter(Phrase.first_seen_round == round_id).all()

    def get_phrases_paginated(self, page: int = 1, page_size: int = 1000,
                              filters: Dict = None) -> Tuple[List[Phrase], int]:
        """
        åˆ†é¡µè·å–çŸ­è¯­

        Args:
            page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
            page_size: æ¯é¡µå¤§å°
            filters: è¿‡æ»¤æ¡ä»¶å­—å…¸
                - cluster_id_A: å¤§ç»„ID
                - cluster_id_B: å°ç»„ID
                - source_type: æ•°æ®æºç±»å‹
                - processed_status: å¤„ç†çŠ¶æ€
                - first_seen_round: é¦–æ¬¡å‡ºç°è½®æ¬¡

        Returns:
            (phrases_list, total_count)
        """
        query = self.session.query(Phrase)

        # åº”ç”¨è¿‡æ»¤å™¨
        if filters:
            if 'cluster_id_A' in filters:
                query = query.filter(Phrase.cluster_id_A == filters['cluster_id_A'])
            if 'cluster_id_B' in filters:
                query = query.filter(Phrase.cluster_id_B == filters['cluster_id_B'])
            if 'source_type' in filters:
                query = query.filter(Phrase.source_type == filters['source_type'])
            if 'processed_status' in filters:
                query = query.filter(Phrase.processed_status == filters['processed_status'])
            if 'first_seen_round' in filters:
                query = query.filter(Phrase.first_seen_round == filters['first_seen_round'])

        # è·å–æ€»æ•°
        total = query.count()

        # åˆ†é¡µ
        offset = (page - 1) * page_size
        phrases = query.offset(offset).limit(page_size).all()

        return phrases, total

    def get_unseen_phrases(self, limit: Optional[int] = None) -> List[Phrase]:
        """
        è·å–æœªå¤„ç†çš„çŸ­è¯­ï¼ˆprocessed_status='unseen'ï¼‰

        Args:
            limit: é™åˆ¶è¿”å›æ•°é‡

        Returns:
            çŸ­è¯­åˆ—è¡¨
        """
        query = self.session.query(Phrase).filter(Phrase.processed_status == 'unseen')
        if limit:
            query = query.limit(limit)
        return query.all()

    def update_cluster_assignment(self, phrase_id: int, cluster_id_A: Optional[int] = None,
                                   cluster_id_B: Optional[int] = None) -> bool:
        """
        æ›´æ–°çŸ­è¯­çš„èšç±»åˆ†é…

        Args:
            phrase_id: çŸ­è¯­ID
            cluster_id_A: å¤§ç»„ID
            cluster_id_B: å°ç»„ID

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            phrase = self.session.query(Phrase).filter(Phrase.phrase_id == phrase_id).first()
            if phrase:
                if cluster_id_A is not None:
                    phrase.cluster_id_A = cluster_id_A
                if cluster_id_B is not None:
                    phrase.cluster_id_B = cluster_id_B
                phrase.processed_status = 'assigned'
                self.session.commit()
                return True
            return False
        except Exception as e:
            self.session.rollback()
            print(f"âš ï¸  æ›´æ–°å¤±è´¥: {str(e)}")
            return False

    def get_statistics(self) -> Dict:
        """
        è·å–çŸ­è¯­è¡¨ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            'total_count': self.get_phrase_count(),
            'by_source': {},
            'by_status': {},
            'by_round': {},
            'clustered_A': 0,
            'clustered_B': 0,
            'mapped_to_demand': 0,
        }

        # æŒ‰source_typeç»Ÿè®¡
        source_counts = self.session.query(
            Phrase.source_type, func.count(Phrase.phrase_id)
        ).group_by(Phrase.source_type).all()
        stats['by_source'] = {src: cnt for src, cnt in source_counts}

        # æŒ‰processed_statusç»Ÿè®¡
        status_counts = self.session.query(
            Phrase.processed_status, func.count(Phrase.phrase_id)
        ).group_by(Phrase.processed_status).all()
        stats['by_status'] = {status: cnt for status, cnt in status_counts}

        # æŒ‰first_seen_roundç»Ÿè®¡
        round_counts = self.session.query(
            Phrase.first_seen_round, func.count(Phrase.phrase_id)
        ).group_by(Phrase.first_seen_round).all()
        stats['by_round'] = {rnd: cnt for rnd, cnt in round_counts}

        # èšç±»ç»Ÿè®¡
        stats['clustered_A'] = self.session.query(func.count(Phrase.phrase_id)).filter(
            Phrase.cluster_id_A.isnot(None)
        ).scalar()
        stats['clustered_B'] = self.session.query(func.count(Phrase.phrase_id)).filter(
            Phrase.cluster_id_B.isnot(None)
        ).scalar()

        # éœ€æ±‚å…³è”ç»Ÿè®¡
        stats['mapped_to_demand'] = self.session.query(func.count(Phrase.phrase_id)).filter(
            Phrase.mapped_demand_id.isnot(None)
        ).scalar()

        return stats

    def get_seed_word_expansion(self) -> Dict[str, Dict]:
        """
        è·å–è¯æ ¹æ‰©å±•ç»Ÿè®¡

        Returns:
            {
                seed_word: {
                    'count': æ‰©å±•è¯æ•°é‡,
                    'by_round': {round: count},
                    'by_source': {source_type: count}
                }
            }
        """
        # è·å–æ‰€æœ‰seed_wordåŠå…¶ç»Ÿè®¡
        seed_stats = self.session.query(
            Phrase.seed_word,
            Phrase.first_seen_round,
            Phrase.source_type,
            func.count(Phrase.phrase_id).label('count')
        ).filter(
            Phrase.seed_word.isnot(None)
        ).group_by(
            Phrase.seed_word,
            Phrase.first_seen_round,
            Phrase.source_type
        ).all()

        # ç»„ç»‡æ•°æ®
        result = {}
        for seed, round_num, source, count in seed_stats:
            if seed not in result:
                result[seed] = {
                    'count': 0,
                    'by_round': {},
                    'by_source': {}
                }

            result[seed]['count'] += count
            result[seed]['by_round'][round_num] = result[seed]['by_round'].get(round_num, 0) + count
            result[seed]['by_source'][source or 'unknown'] = result[seed]['by_source'].get(source or 'unknown', 0) + count

        return result

    def get_phrases_by_seed_word(
        self,
        seed_word: str,
        round_num: Optional[int] = None,
        limit: int = 100
    ) -> List[Phrase]:
        """
        è·å–æŒ‡å®šè¯æ ¹æ‰©å±•å‡ºçš„å…³é”®è¯

        Args:
            seed_word: è¯æ ¹
            round_num: ç­›é€‰ç‰¹å®šè½®æ¬¡ï¼ˆNone=æ‰€æœ‰ï¼‰
            limit: é™åˆ¶è¿”å›æ•°é‡

        Returns:
            Phraseå¯¹è±¡åˆ—è¡¨
        """
        query = self.session.query(Phrase).filter(
            Phrase.seed_word == seed_word
        )

        if round_num is not None:
            query = query.filter(Phrase.first_seen_round == round_num)

        query = query.order_by(Phrase.frequency.desc()).limit(limit)

        return query.all()

    def get_all_seed_words(self) -> List[str]:
        """è·å–æ‰€æœ‰å”¯ä¸€çš„è¯æ ¹"""
        seeds = self.session.query(Phrase.seed_word).filter(
            Phrase.seed_word.isnot(None)
        ).distinct().all()

        return [s[0] for s in seeds if s[0]]

    def get_words_seed_status(self, words: List[str]) -> Dict[str, int]:
        """
        æ‰¹é‡æŸ¥è¯¢è¯æ±‡çš„è¯æ ¹çŠ¶æ€

        Args:
            words: è¯æ±‡åˆ—è¡¨

        Returns:
            {word: expansion_count}ï¼Œexpansion_countè¡¨ç¤ºè¯¥è¯ä½œä¸ºseed_wordæ‰©å±•äº†å¤šå°‘ä¸ªphrase
            å¦‚æœexpansion_count=0ï¼Œè¡¨ç¤ºè¯¥è¯ä¸æ˜¯è¯æ ¹
        """
        # æŸ¥è¯¢æ¯ä¸ªè¯ä½œä¸ºseed_wordçš„æ‰©å±•æ•°é‡
        seed_counts = self.session.query(
            Phrase.seed_word,
            func.count(Phrase.phrase_id).label('count')
        ).filter(
            Phrase.seed_word.in_(words)
        ).group_by(Phrase.seed_word).all()

        # æ„å»ºç»“æœå­—å…¸
        result = {word: 0 for word in words}
        for seed_word, count in seed_counts:
            result[seed_word] = count

        return result


class ClusterMetaRepository:
    """èšç±»å…ƒæ•°æ®è¡¨æ“ä½œå°è£…"""

    def __init__(self, session: Session = None):
        self.session = session or get_session()
        self._should_close = session is None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self._should_close:
            self.session.close()

    def create_or_update_cluster(self, cluster_id: int, cluster_level: str,
                                  size: int, example_phrases: str,
                                  main_theme: str = None,
                                  parent_cluster_id: int = None,
                                  total_frequency: int = 0) -> ClusterMeta:
        """
        åˆ›å»ºæˆ–æ›´æ–°èšç±»å…ƒæ•°æ®

        Args:
            cluster_id: èšç±»ID
            cluster_level: èšç±»çº§åˆ«ï¼ˆ'A'æˆ–'B'ï¼‰
            size: èšç±»å¤§å°
            example_phrases: ç¤ºä¾‹çŸ­è¯­ï¼ˆåˆ†å·åˆ†éš”ï¼‰
            main_theme: AIç”Ÿæˆçš„ä¸»é¢˜æ ‡ç­¾
            parent_cluster_id: çˆ¶èšç±»IDï¼ˆä»…å¯¹Bçº§åˆ«æœ‰æ•ˆï¼‰
            total_frequency: æ€»é¢‘æ¬¡

        Returns:
            ClusterMetaå¯¹è±¡
        """
        cluster = self.session.query(ClusterMeta).filter(
            and_(ClusterMeta.cluster_id == cluster_id,
                 ClusterMeta.cluster_level == cluster_level)
        ).first()

        if cluster:
            # æ›´æ–°ç°æœ‰è®°å½•
            cluster.size = size
            cluster.example_phrases = example_phrases
            cluster.main_theme = main_theme
            cluster.parent_cluster_id = parent_cluster_id
            cluster.total_frequency = total_frequency
        else:
            # åˆ›å»ºæ–°è®°å½•
            cluster = ClusterMeta(
                cluster_id=cluster_id,
                cluster_level=cluster_level,
                size=size,
                example_phrases=example_phrases,
                main_theme=main_theme,
                parent_cluster_id=parent_cluster_id,
                total_frequency=total_frequency,
                is_selected=False,
                selection_score=None
            )
            self.session.add(cluster)

        self.session.commit()
        return cluster

    def get_selected_clusters(self, cluster_level: str = 'A') -> List[ClusterMeta]:
        """è·å–å·²é€‰ä¸­çš„èšç±»"""
        return self.session.query(ClusterMeta).filter(
            and_(ClusterMeta.cluster_level == cluster_level,
                 ClusterMeta.is_selected == True)
        ).all()

    def get_all_clusters(self, cluster_level: str = 'A') -> List[ClusterMeta]:
        """è·å–æ‰€æœ‰èšç±»"""
        return self.session.query(ClusterMeta).filter(
            ClusterMeta.cluster_level == cluster_level
        ).order_by(ClusterMeta.size.desc()).all()

    def update_selection(self, cluster_id: int, cluster_level: str,
                        is_selected: bool, selection_score: int = None) -> bool:
        """æ›´æ–°èšç±»é€‰æ‹©çŠ¶æ€"""
        try:
            cluster = self.session.query(ClusterMeta).filter(
                and_(ClusterMeta.cluster_id == cluster_id,
                     ClusterMeta.cluster_level == cluster_level)
            ).first()
            if cluster:
                cluster.is_selected = is_selected
                cluster.selection_score = selection_score
                self.session.commit()
                return True
            return False
        except Exception as e:
            self.session.rollback()
            # æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯æ‰“å°ï¼Œè®©è°ƒç”¨æ–¹å¤„ç†
            raise e

    def update_cluster_labeling(
        self,
        cluster_id: int,
        llm_label: str,
        llm_summary: str,
        primary_demand_type: str,
        secondary_demand_types: str,
        labeling_confidence: int,
        cluster_level: str = 'A'
    ) -> bool:
        """
        æ›´æ–°èšç±»çš„DeepSeekè¯­ä¹‰æ ‡æ³¨

        Args:
            cluster_id: èšç±»ID
            llm_label: ç®€çŸ­è¯­ä¹‰æ ‡ç­¾
            llm_summary: è¯¦ç»†æè¿°
            primary_demand_type: ä¸»éœ€æ±‚ç±»å‹
            secondary_demand_types: æ¬¡è¦éœ€æ±‚ç±»å‹ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
            labeling_confidence: æ ‡æ³¨ç½®ä¿¡åº¦
            cluster_level: èšç±»çº§åˆ«ï¼ˆé»˜è®¤'A'ï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            from datetime import datetime

            cluster = self.session.query(ClusterMeta).filter(
                and_(ClusterMeta.cluster_id == cluster_id,
                     ClusterMeta.cluster_level == cluster_level)
            ).first()

            if cluster:
                cluster.llm_label = llm_label
                cluster.llm_summary = llm_summary
                cluster.primary_demand_type = primary_demand_type
                cluster.secondary_demand_types = secondary_demand_types
                cluster.labeling_confidence = labeling_confidence
                cluster.labeling_timestamp = datetime.utcnow()
                self.session.commit()
                return True
            return False
        except Exception as e:
            self.session.rollback()
            raise e


class DemandRepository:
    """éœ€æ±‚å¡ç‰‡è¡¨æ“ä½œå°è£…"""

    def __init__(self, session: Session = None):
        self.session = session or get_session()
        self._should_close = session is None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self._should_close:
            self.session.close()

    def create_demand(self, title: str, description: str, user_scenario: str,
                     demand_type: str, source_cluster_A: int, source_cluster_B: int,
                     related_phrases_count: int = 0, business_value: str = 'unknown',
                     status: str = 'idea') -> Demand:
        """åˆ›å»ºéœ€æ±‚å¡ç‰‡"""
        demand = Demand(
            title=title,
            description=description,
            user_scenario=user_scenario,
            demand_type=demand_type,
            source_cluster_A=source_cluster_A,
            source_cluster_B=source_cluster_B,
            related_phrases_count=related_phrases_count,
            business_value=business_value,
            status=status
        )
        self.session.add(demand)
        self.session.commit()
        self.session.refresh(demand)  # åˆ·æ–°å¯¹è±¡ï¼Œç¡®ä¿æ‰€æœ‰å±æ€§éƒ½å·²åŠ è½½
        return demand

    def get_validated_demands(self) -> List[Demand]:
        """è·å–å·²éªŒè¯çš„éœ€æ±‚"""
        return self.session.query(Demand).filter(Demand.status == 'validated').all()

    def get_demands_by_cluster(self, cluster_id: int, cluster_level: str = 'A') -> List[Demand]:
        """è·å–æŒ‡å®šèšç±»çš„éœ€æ±‚"""
        if cluster_level == 'A':
            return self.session.query(Demand).filter(Demand.source_cluster_A == cluster_id).all()
        else:
            return self.session.query(Demand).filter(Demand.source_cluster_B == cluster_id).all()


class TokenRepository:
    """Tokenè¯åº“è¡¨æ“ä½œå°è£…"""

    def __init__(self, session: Session = None):
        self.session = session or get_session()
        self._should_close = session is None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self._should_close:
            self.session.close()

    def create_token(self, token_text: str, token_type: str,
                     in_phrase_count: int = 0, first_seen_round: int = 1,
                     verified: bool = False, notes: str = None) -> Token:
        """åˆ›å»ºtokenè®°å½•"""
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = self.session.query(Token).filter(
            Token.token_text == token_text
        ).first()

        if existing:
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            existing.in_phrase_count = max(existing.in_phrase_count, in_phrase_count)
            if notes:
                existing.notes = notes
            self.session.commit()
            return existing

        # åˆ›å»ºæ–°token
        token = Token(
            token_text=token_text,
            token_type=token_type,
            in_phrase_count=in_phrase_count,
            first_seen_round=first_seen_round,
            verified=verified,
            notes=notes
        )
        self.session.add(token)
        self.session.commit()
        return token

    def get_all_tokens(self, token_type: str = None, verified_only: bool = False) -> List[Token]:
        """è·å–æ‰€æœ‰tokens"""
        query = self.session.query(Token)

        if token_type:
            query = query.filter(Token.token_type == token_type)

        if verified_only:
            query = query.filter(Token.verified == True)

        return query.order_by(Token.in_phrase_count.desc()).all()

    def get_token_by_text(self, token_text: str) -> Optional[Token]:
        """æ ¹æ®æ–‡æœ¬è·å–token"""
        return self.session.query(Token).filter(Token.token_text == token_text).first()

    def update_verification(self, token_text: str, verified: bool, notes: str = None) -> bool:
        """æ›´æ–°tokenéªŒè¯çŠ¶æ€"""
        token = self.get_token_by_text(token_text)
        if token:
            token.verified = verified
            if notes:
                token.notes = notes
            self.session.commit()
            return True
        return False

    def bulk_insert_tokens(self, tokens: List[Dict]) -> int:
        """æ‰¹é‡æ’å…¥tokens"""
        inserted = 0
        for token_data in tokens:
            try:
                self.create_token(**token_data)
                inserted += 1
            except Exception:
                continue
        return inserted


# ä¾¿æ·å‡½æ•°


class SeedWordRepository:
    """è¯æ ¹ç®¡ç†è¡¨æ“ä½œå°è£…"""

    def __init__(self, session: Session = None):
        """åˆå§‹åŒ–Repository"""
        self.session = session or get_session()
        self._should_close = session is None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self._should_close:
            self.session.close()

    def create_or_update_seed_word(
        self,
        seed_word: str,
        token_types: list = None,  # æ”¹ä¸ºåˆ—è¡¨ï¼Œæ”¯æŒå¤šåˆ†ç±»
        primary_token_type: str = None,  # ä¸»è¦ç±»åˆ«
        definition: str = None,
        business_value: str = None,
        user_scenario: str = None,
        parent_seed_word: str = None,
        level: int = 1,
        status: str = "active",
        priority: str = "medium",
        source: str = "user_created",
        first_seen_round: int = None,
        verified: bool = False,
        confidence: str = "medium",
        tags: str = None,
        notes: str = None
    ) -> SeedWord:
        """
        åˆ›å»ºæˆ–æ›´æ–°è¯æ ¹è®°å½•

        Args:
            seed_word: è¯æ ¹æ–‡æœ¬
            token_types: Tokenç±»å‹åˆ—è¡¨ï¼ˆå¯å¤šé€‰ï¼‰å¦‚ ["intent", "action"]
            primary_token_type: ä¸»è¦Tokenç±»å‹ï¼ˆç”¨äºæ’åºå’Œç­›é€‰ï¼‰
            definition: è¯æ ¹å®šä¹‰
            business_value: å•†ä¸šä»·å€¼è¯´æ˜
            user_scenario: ç”¨æˆ·åœºæ™¯
            parent_seed_word: çˆ¶è¯æ ¹
            level: å±‚çº§
            status: çŠ¶æ€
            priority: ä¼˜å…ˆçº§
            source: æ¥æº
            first_seen_round: é¦–æ¬¡å‡ºç°è½®æ¬¡
            verified: æ˜¯å¦å·²å®¡æ ¸
            confidence: ç½®ä¿¡åº¦
            tags: æ ‡ç­¾ï¼ˆJSONæ ¼å¼ï¼‰
            notes: å¤‡æ³¨

        Returns:
            SeedWordå¯¹è±¡
        """
        import json

        existing = self.get_seed_word(seed_word)

        if existing:
            # æ›´æ–°ç°æœ‰è®°å½•ï¼ˆä»…æ›´æ–°éNoneçš„å­—æ®µï¼‰
            if token_types is not None:
                existing.token_types = json.dumps(token_types)
            if primary_token_type is not None:
                existing.primary_token_type = primary_token_type
            if definition is not None:
                existing.definition = definition
            if business_value is not None:
                existing.business_value = business_value
            if user_scenario is not None:
                existing.user_scenario = user_scenario
            if parent_seed_word is not None:
                existing.parent_seed_word = parent_seed_word
            if level is not None:
                existing.level = level
            if status is not None:
                existing.status = status
            if priority is not None:
                existing.priority = priority
            if verified is not None:
                existing.verified = verified
            if confidence is not None:
                existing.confidence = confidence
            if tags is not None:
                existing.tags = tags
            if notes is not None:
                existing.notes = notes

            self.session.commit()
            return existing
        else:
            # åˆ›å»ºæ–°è®°å½•
            new_seed = SeedWord(
                seed_word=seed_word,
                token_types=json.dumps(token_types) if token_types else None,
                primary_token_type=primary_token_type,
                definition=definition,
                business_value=business_value,
                user_scenario=user_scenario,
                parent_seed_word=parent_seed_word,
                level=level,
                status=status,
                priority=priority,
                source=source,
                first_seen_round=first_seen_round,
                verified=verified,
                confidence=confidence,
                tags=tags,
                notes=notes
            )
            self.session.add(new_seed)
            self.session.commit()
            return new_seed

    def get_seed_word(self, seed_word: str) -> Optional[SeedWord]:
        """æ ¹æ®è¯æ ¹æ–‡æœ¬æŸ¥è¯¢è®°å½•"""
        return self.session.query(SeedWord).filter(
            SeedWord.seed_word == seed_word
        ).first()

    def get_all_seed_words(
        self,
        primary_token_type: str = None,  # æ”¹ä¸ºæŒ‰ä¸»è¦ç±»åˆ«ç­›é€‰
        status: str = None,
        verified_only: bool = False,
        priority: str = None
    ) -> List[SeedWord]:
        """
        è·å–æ‰€æœ‰è¯æ ¹è®°å½•ï¼ˆæ”¯æŒç­›é€‰ï¼‰

        Args:
            primary_token_type: æŒ‰ä¸»è¦Tokenç±»å‹ç­›é€‰
            status: æŒ‰çŠ¶æ€ç­›é€‰
            verified_only: ä»…è¿”å›å·²å®¡æ ¸çš„
            priority: æŒ‰ä¼˜å…ˆçº§ç­›é€‰

        Returns:
            è¯æ ¹åˆ—è¡¨
        """
        query = self.session.query(SeedWord)

        if primary_token_type:
            query = query.filter(SeedWord.primary_token_type == primary_token_type)
        if status:
            query = query.filter(SeedWord.status == status)
        if verified_only:
            query = query.filter(SeedWord.verified == True)
        if priority:
            query = query.filter(SeedWord.priority == priority)

        return query.order_by(SeedWord.expansion_count.desc()).all()

    def get_seeds_by_type(self, token_type: str, include_secondary: bool = True) -> List[SeedWord]:
        """
        è·å–æŒ‡å®šç±»å‹çš„æ‰€æœ‰è¯æ ¹

        Args:
            token_type: ç±»å‹ï¼ˆintent/action/object/otherï¼‰
            include_secondary: æ˜¯å¦åŒ…å«æ¬¡è¦ç±»åˆ«åŒ¹é…çš„è¯æ ¹

        Returns:
            è¯æ ¹åˆ—è¡¨
        """
        import json

        if not include_secondary:
            # ä»…åŒ¹é…ä¸»è¦ç±»åˆ«
            return self.session.query(SeedWord).filter(
                SeedWord.primary_token_type == token_type
            ).order_by(SeedWord.expansion_count.desc()).all()
        else:
            # åŒ¹é…ä¸»è¦ç±»åˆ«æˆ–åŒ…å«åœ¨å¤šåˆ†ç±»ä¸­
            all_seeds = self.session.query(SeedWord).all()
            matched_seeds = []

            for seed in all_seeds:
                # æ£€æŸ¥ä¸»è¦ç±»åˆ«
                if seed.primary_token_type == token_type:
                    matched_seeds.append(seed)
                    continue

                # æ£€æŸ¥å¤šåˆ†ç±»
                if seed.token_types:
                    try:
                        types = json.loads(seed.token_types)
                        if token_type in types:
                            matched_seeds.append(seed)
                    except:
                        continue

            # æŒ‰expansion_countæ’åº
            matched_seeds.sort(key=lambda x: x.expansion_count or 0, reverse=True)
            return matched_seeds

    def update_expansion_stats(self, seed_word: str) -> bool:
        """
        æ›´æ–°è¯æ ¹çš„æ‰©å±•ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»phrasesè¡¨èšåˆï¼‰

        Args:
            seed_word: è¯æ ¹æ–‡æœ¬

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            seed_obj = self.get_seed_word(seed_word)
            if not seed_obj:
                return False

            # ç»Ÿè®¡è¯¥è¯æ ¹æ‰©å±•çš„phraseæ•°é‡
            expansion_count = self.session.query(func.count(Phrase.phrase_id)).filter(
                Phrase.seed_word == seed_word
            ).scalar() or 0

            # ç»Ÿè®¡æ€»æœç´¢é‡
            total_volume = self.session.query(func.sum(Phrase.volume)).filter(
                Phrase.seed_word == seed_word
            ).scalar() or 0

            # ç»Ÿè®¡å¹³å‡é¢‘æ¬¡
            avg_frequency = self.session.query(func.avg(Phrase.frequency)).filter(
                Phrase.seed_word == seed_word
            ).scalar() or 0

            # æ›´æ–°
            seed_obj.expansion_count = expansion_count
            seed_obj.total_volume = total_volume
            seed_obj.avg_frequency = int(avg_frequency)

            self.session.commit()
            return True
        except Exception as e:
            self.session.rollback()
            print(f"âŒ æ›´æ–°è¯æ ¹ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return False

    def batch_update_all_stats(self) -> int:
        """
        æ‰¹é‡æ›´æ–°æ‰€æœ‰è¯æ ¹çš„ç»Ÿè®¡ä¿¡æ¯

        Returns:
            æ›´æ–°æˆåŠŸçš„æ•°é‡
        """
        all_seeds = self.get_all_seed_words()
        success_count = 0

        print(f"\nğŸ“Š æ‰¹é‡æ›´æ–° {len(all_seeds)} ä¸ªè¯æ ¹çš„ç»Ÿè®¡ä¿¡æ¯...")
        for seed in tqdm(all_seeds, desc="æ›´æ–°è¿›åº¦"):
            if self.update_expansion_stats(seed.seed_word):
                success_count += 1

        print(f"âœ“ æˆåŠŸæ›´æ–° {success_count} ä¸ªè¯æ ¹")
        return success_count

    def link_demand(self, seed_word: str, demand_id: int, is_primary: bool = False) -> bool:
        """
        å…³è”è¯æ ¹ä¸éœ€æ±‚

        Args:
            seed_word: è¯æ ¹æ–‡æœ¬
            demand_id: éœ€æ±‚ID
            is_primary: æ˜¯å¦ä¸ºä¸»è¦å…³è”

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            seed_obj = self.get_seed_word(seed_word)
            if not seed_obj:
                return False

            # æ›´æ–°ä¸»è¦éœ€æ±‚ID
            if is_primary:
                seed_obj.primary_demand_id = demand_id

            # æ›´æ–°å…³è”éœ€æ±‚åˆ—è¡¨ï¼ˆJSONæ ¼å¼ï¼‰
            import json
            if seed_obj.related_demand_ids:
                demand_ids = json.loads(seed_obj.related_demand_ids)
            else:
                demand_ids = []

            if demand_id not in demand_ids:
                demand_ids.append(demand_id)

            seed_obj.related_demand_ids = json.dumps(demand_ids)
            self.session.commit()
            return True
        except Exception as e:
            self.session.rollback()
            print(f"âŒ å…³è”éœ€æ±‚å¤±è´¥: {str(e)}")
            return False

    def get_seeds_by_demand(self, demand_id: int) -> List[SeedWord]:
        """è·å–ä¸æŒ‡å®šéœ€æ±‚å…³è”çš„æ‰€æœ‰è¯æ ¹"""
        # æŸ¥è¯¢primary_demand_idåŒ¹é…çš„
        primary_seeds = self.session.query(SeedWord).filter(
            SeedWord.primary_demand_id == demand_id
        ).all()

        # æŸ¥è¯¢related_demand_idsä¸­åŒ…å«çš„ï¼ˆéœ€è¦JSONæœç´¢ï¼‰
        # æ³¨æ„ï¼šè¿™éœ€è¦æ•°æ®åº“æ”¯æŒJSONæœç´¢ï¼ŒSQLiteå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
        all_seeds = self.session.query(SeedWord).all()
        related_seeds = []

        import json
        for seed in all_seeds:
            if seed.related_demand_ids:
                try:
                    demand_ids = json.loads(seed.related_demand_ids)
                    if demand_id in demand_ids:
                        related_seeds.append(seed)
                except:
                    continue

        # åˆå¹¶å¹¶å»é‡
        result_dict = {s.seed_id: s for s in primary_seeds + related_seeds}
        return list(result_dict.values())

    def get_statistics(self) -> Dict:
        """è·å–è¯æ ¹ç»Ÿè®¡ä¿¡æ¯"""
        total = self.session.query(func.count(SeedWord.seed_id)).scalar() or 0

        # æŒ‰ä¸»è¦ç±»åˆ«ç»Ÿè®¡
        by_primary_type = {}
        for token_type in ['intent', 'action', 'object', 'other']:
            count = self.session.query(func.count(SeedWord.seed_id)).filter(
                SeedWord.primary_token_type == token_type
            ).scalar() or 0
            by_primary_type[token_type] = count

        by_status = {}
        for status in ['active', 'paused', 'archived']:
            count = self.session.query(func.count(SeedWord.seed_id)).filter(
                SeedWord.status == status
            ).scalar() or 0
            by_status[status] = count

        verified_count = self.session.query(func.count(SeedWord.seed_id)).filter(
            SeedWord.verified == True
        ).scalar() or 0

        return {
            'total': total,
            'by_primary_type': by_primary_type,
            'by_status': by_status,
            'verified_count': verified_count,
            'verified_rate': round(verified_count / total * 100, 1) if total > 0 else 0
        }


# ==================== æµ‹è¯•å·¥å…·å‡½æ•° ====================
def test_database_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        with PhraseRepository() as repo:
            count = repo.get_phrase_count()
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼å½“å‰phrasesè¡¨è®°å½•æ•°: {count}")
            return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        return False


if __name__ == "__main__":
    test_database_connection()
