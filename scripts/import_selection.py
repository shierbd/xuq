"""
Phase 3B: å¯¼å…¥ç­›é€‰ç»“æœ
è¯»å–äººå·¥è¯„åˆ†çš„CSVæ–‡ä»¶ï¼Œæ›´æ–°æ•°æ®åº“ä¸­çš„selection_scoreå’Œis_selectedå­—æ®µ

è¿è¡Œæ–¹å¼:
    python scripts/import_selection.py [--csv-file path/to/csv]

å‚æ•°:
    --csv-file: CSVæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºdata/output/cluster_selection_report.csvï¼‰
"""
import sys
import argparse
from pathlib import Path

# è®¾ç½®UTF-8ç¼–ç è¾“å‡ºï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform.startswith('win'):
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from config.settings import OUTPUT_DIR, CLUSTER_SELECTION_THRESHOLD
from storage.repository import ClusterMetaRepository
from storage.models import ClusterMeta
import pandas as pd


def validate_csv_file(csv_file: Path) -> bool:
    """
    éªŒè¯CSVæ–‡ä»¶æ ¼å¼

    Args:
        csv_file: CSVæ–‡ä»¶è·¯å¾„

    Returns:
        æ˜¯å¦éªŒè¯é€šè¿‡
    """
    if not csv_file.exists():
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
        return False

    try:
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

    # æ£€æŸ¥å¿…éœ€åˆ—
    required_columns = ['cluster_id', 'selection_score']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        print(f"âŒ CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
        return False

    # æ£€æŸ¥æ˜¯å¦æœ‰è¯„åˆ†
    if df['selection_score'].isna().all():
        print("âš ï¸  è­¦å‘Š: selection_scoreåˆ—å…¨éƒ¨ä¸ºç©ºï¼Œæ²¡æœ‰ä»»ä½•è¯„åˆ†")
        return False

    return True


def import_selections(csv_file: Path):
    """
    å¯¼å…¥ç­›é€‰ç»“æœåˆ°æ•°æ®åº“

    Args:
        csv_file: CSVæ–‡ä»¶è·¯å¾„

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print("\nã€æ­¥éª¤1ã€‘è¯»å–CSVæ–‡ä»¶...")
    print(f"  æ–‡ä»¶: {csv_file}")

    # è¯»å–CSV
    df = pd.read_csv(csv_file, encoding='utf-8-sig')
    print(f"âœ“ è¯»å–äº† {len(df)} æ¡è®°å½•")

    # ç»Ÿè®¡è¯„åˆ†æƒ…å†µ
    scored_count = df['selection_score'].notna().sum()
    print(f"  å·²è¯„åˆ†: {scored_count}/{len(df)} ({scored_count/len(df)*100:.1f}%)")

    if scored_count == 0:
        print("\nâŒ æ²¡æœ‰ä»»ä½•è¯„åˆ†ï¼Œæ— æ³•å¯¼å…¥")
        return False

    # è¿‡æ»¤å‡ºå·²è¯„åˆ†çš„è®°å½•
    df_scored = df[df['selection_score'].notna()].copy()

    # è½¬æ¢selection_scoreä¸ºæ•´æ•°
    try:
        df_scored['selection_score'] = df_scored['selection_score'].astype(int)
    except ValueError as e:
        print(f"\nâŒ selection_scoreå¿…é¡»æ˜¯æ•´æ•°: {str(e)}")
        return False

    # éªŒè¯è¯„åˆ†èŒƒå›´
    invalid_scores = df_scored[
        (df_scored['selection_score'] < 1) | (df_scored['selection_score'] > 5)
    ]
    if len(invalid_scores) > 0:
        print(f"\nâš ï¸  è­¦å‘Š: {len(invalid_scores)} æ¡è®°å½•çš„è¯„åˆ†ä¸åœ¨1-5èŒƒå›´å†…")
        print("  è¿™äº›è®°å½•å°†è¢«è·³è¿‡:")
        for _, row in invalid_scores.iterrows():
            print(f"    ç°‡ID {row['cluster_id']}: {row['selection_score']}")
        df_scored = df_scored[
            (df_scored['selection_score'] >= 1) & (df_scored['selection_score'] <= 5)
        ]

    # è®¡ç®—is_selected
    df_scored['is_selected'] = df_scored['selection_score'] >= CLUSTER_SELECTION_THRESHOLD

    selected_count = df_scored['is_selected'].sum()
    print(f"\n  é€‰ä¸­æ ‡å‡†: selection_score >= {CLUSTER_SELECTION_THRESHOLD}")
    print(f"  å°†è¢«é€‰ä¸­: {selected_count}/{len(df_scored)} ({selected_count/len(df_scored)*100:.1f}%)")

    # åˆ†æ•°åˆ†å¸ƒ
    print(f"\n  è¯„åˆ†åˆ†å¸ƒ:")
    for score in range(1, 6):
        count = (df_scored['selection_score'] == score).sum()
        print(f"    {score}åˆ†: {count} ä¸ªèšç±»")

    # æ›´æ–°æ•°æ®åº“
    print("\nã€æ­¥éª¤2ã€‘æ›´æ–°æ•°æ®åº“...")

    with ClusterMetaRepository() as repo:
        updated_count = 0
        not_found_count = 0

        for _, row in df_scored.iterrows():
            cluster_id = int(row['cluster_id'])
            selection_score = int(row['selection_score'])
            is_selected = bool(row['is_selected'])

            # æŸ¥æ‰¾èšç±»
            cluster = repo.session.query(ClusterMeta).filter(
                ClusterMeta.cluster_id == cluster_id,
                ClusterMeta.cluster_level == 'A'
            ).first()

            if cluster:
                cluster.selection_score = selection_score
                cluster.is_selected = is_selected
                updated_count += 1
            else:
                not_found_count += 1
                print(f"  âš ï¸  ç°‡ID {cluster_id} åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨")

        repo.session.commit()

    print(f"\nâœ“ æ›´æ–°å®Œæˆ")
    print(f"  æˆåŠŸæ›´æ–°: {updated_count} ä¸ªèšç±»")
    if not_found_count > 0:
        print(f"  æœªæ‰¾åˆ°: {not_found_count} ä¸ªèšç±»")

    return True


def generate_summary_report():
    """
    ç”Ÿæˆç­›é€‰æ‘˜è¦æŠ¥å‘Š
    """
    print("\nã€æ­¥éª¤3ã€‘ç”Ÿæˆç­›é€‰æ‘˜è¦...")

    with ClusterMetaRepository() as repo:
        all_clusters = repo.session.query(ClusterMeta).filter(
            ClusterMeta.cluster_level == 'A'
        ).all()

        # ç»Ÿè®¡
        total_count = len(all_clusters)
        scored_clusters = [c for c in all_clusters if c.selection_score is not None]
        scored_count = len(scored_clusters)
        selected_clusters = [c for c in all_clusters if c.is_selected]
        selected_count = len(selected_clusters)

        # é€‰ä¸­èšç±»çš„ç»Ÿè®¡
        if selected_clusters:
            selected_phrases = sum(c.size for c in selected_clusters)
            selected_frequency = sum(c.total_frequency or 0 for c in selected_clusters)
        else:
            selected_phrases = 0
            selected_frequency = 0

    report_lines = []
    report_lines.append("="*70)
    report_lines.append("Phase 3 ç­›é€‰ç»“æœæ‘˜è¦")
    report_lines.append("="*70)
    report_lines.append("")

    report_lines.append("ã€ç­›é€‰ç»Ÿè®¡ã€‘")
    report_lines.append(f"  æ€»èšç±»æ•°: {total_count}")
    report_lines.append(f"  å·²è¯„åˆ†æ•°: {scored_count} ({scored_count/total_count*100:.1f}%)")
    report_lines.append(f"  é€‰ä¸­æ•°é‡: {selected_count} ({selected_count/total_count*100:.1f}%)")
    report_lines.append("")

    report_lines.append("ã€é€‰ä¸­èšç±»ç»Ÿè®¡ã€‘")
    report_lines.append(f"  æ€»çŸ­è¯­æ•°: {selected_phrases:,}")
    report_lines.append(f"  æ€»é¢‘æ¬¡: {selected_frequency:,}")
    if selected_clusters:
        report_lines.append(f"  å¹³å‡å¤§å°: {selected_phrases/selected_count:.1f}")
    report_lines.append("")

    # è¯„åˆ†åˆ†å¸ƒ
    if scored_clusters:
        report_lines.append("ã€è¯„åˆ†åˆ†å¸ƒã€‘")
        for score in range(1, 6):
            count = sum(1 for c in scored_clusters if c.selection_score == score)
            report_lines.append(f"  {score}åˆ†: {count} ä¸ªèšç±»")
        report_lines.append("")

    # é€‰ä¸­èšç±»åˆ—è¡¨
    if selected_clusters:
        report_lines.append("ã€é€‰ä¸­èšç±»åˆ—è¡¨ã€‘")
        report_lines.append(f"{'ç°‡ID':<10} {'å¤§å°':<8} {'é¢‘æ¬¡':<12} {'è¯„åˆ†':<6} {'ä¸»é¢˜'}")
        report_lines.append("-" * 70)

        # æŒ‰è¯„åˆ†å’Œå¤§å°æ’åº
        selected_sorted = sorted(
            selected_clusters,
            key=lambda x: (x.selection_score or 0, x.size),
            reverse=True
        )

        for cluster in selected_sorted:
            theme = cluster.main_theme[:40] if cluster.main_theme else "æœªå‘½å"
            report_lines.append(
                f"{cluster.cluster_id:<10} {cluster.size:<8} "
                f"{cluster.total_frequency or 0:<12} {cluster.selection_score:<6} {theme}"
            )
        report_lines.append("")

    report_lines.append("="*70)
    report_lines.append("ä¸‹ä¸€æ­¥: è¿è¡Œ Phase 4 è¿›è¡Œå°ç»„èšç±»å’Œéœ€æ±‚å¡ç‰‡ç”Ÿæˆ")
    report_lines.append("  python scripts/run_phase4_demands.py")
    report_lines.append("="*70)

    # è¾“å‡ºæŠ¥å‘Š
    report_text = '\n'.join(report_lines)
    print('\n' + report_text)

    # ä¿å­˜åˆ°æ–‡ä»¶
    OUTPUT_DIR.mkdir(exist_ok=True)
    report_file = OUTPUT_DIR / 'phase3_selection_summary.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"\nğŸ’¾ æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return report_file


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Phase 3B: å¯¼å…¥ç­›é€‰ç»“æœ')
    parser.add_argument(
        '--csv-file',
        type=str,
        default=None,
        help='CSVæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºdata/output/cluster_selection_report.csvï¼‰'
    )

    args = parser.parse_args()

    print("\n" + "="*70)
    print("Phase 3B: å¯¼å…¥ç­›é€‰ç»“æœ".center(70))
    print("="*70)

    try:
        # ç¡®å®šCSVæ–‡ä»¶è·¯å¾„
        if args.csv_file:
            csv_file = Path(args.csv_file)
        else:
            csv_file = OUTPUT_DIR / 'cluster_selection_report.csv'

        # éªŒè¯æ–‡ä»¶
        if not validate_csv_file(csv_file):
            return False

        # å¯¼å…¥ç­›é€‰ç»“æœ
        if not import_selections(csv_file):
            return False

        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        generate_summary_report()

        # å®Œæˆ
        print("\n" + "="*70)
        print("âœ… ç­›é€‰ç»“æœå¯¼å…¥å®Œæˆï¼".center(70))
        print("="*70)

        print("\nğŸ“Œ ä¸‹ä¸€æ­¥:")
        print("  è¿è¡Œ Phase 4: python scripts/run_phase4_demands.py")

        return True

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return False
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
