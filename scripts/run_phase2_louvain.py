"""
Phase 2B: Louvainèšç±»ï¼ˆæ›¿ä»£K-Meansï¼‰
ä½¿ç”¨å›¾ç¤¾åŒºå‘ç°ç®—æ³•ç”Ÿæˆè¯­ä¹‰å¹²å‡€çš„å¤§ç»„èšç±»

è¿è¡Œæ–¹å¼:
    python scripts/run_phase2_louvain.py [é€‰é¡¹]

å‚æ•°:
    --round-id: æ•°æ®è½®æ¬¡IDï¼ˆé»˜è®¤ä¸º1ï¼‰
    --limit: é™åˆ¶å¤„ç†çš„çŸ­è¯­æ•°é‡ï¼Œç”¨äºæµ‹è¯•ï¼ˆ0=å…¨éƒ¨ï¼‰
    --k-neighbors: Kè¿‘é‚»æ•°é‡ï¼ˆé»˜è®¤20ï¼‰
    --similarity-threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼‰
    --resolution: Louvainåˆ†è¾¨ç‡å‚æ•°ï¼ˆé»˜è®¤1.0ï¼‰

ç¤ºä¾‹:
    # æµ‹è¯•æ¨¡å¼ï¼ˆ1000æ¡çŸ­è¯­ï¼‰
    python scripts/run_phase2_louvain.py --limit=1000

    # ä½¿ç”¨é»˜è®¤å‚æ•°
    python scripts/run_phase2_louvain.py
"""
import sys
import argparse
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ç¼–ç ä¿®å¤
from utils.encoding_fix import setup_encoding
setup_encoding()

from config.settings import OUTPUT_DIR, LOUVAIN_CONFIG
from core.embedding import EmbeddingService
from core.graph_clustering import cluster_phrases_louvain
from storage.repository import PhraseRepository, ClusterMetaRepository
from storage.models import Phrase


def run_phase2_louvain(
    round_id: int = 1,
    limit: int = 0,
    k_neighbors: int = None,
    similarity_threshold: float = None,
    resolution: float = None
):
    """æ‰§è¡ŒPhase 2B Louvainèšç±»"""
    print("\n" + "="*70)
    print("Phase 2B: Louvainå›¾èšç±»ï¼ˆæ›¿ä»£K-Meansï¼‰".center(70))
    print("="*70)

    # 1. ä»æ•°æ®åº“åŠ è½½çŸ­è¯­
    print("\nã€æ­¥éª¤1ã€‘ä»æ•°æ®åº“åŠ è½½çŸ­è¯­...")
    with PhraseRepository() as repo:
        query = repo.session.query(Phrase)

        if limit > 0:
            query = query.limit(limit)
            print(f"âš ï¸  æµ‹è¯•æ¨¡å¼ï¼šä»…å¤„ç†å‰ {limit} æ¡çŸ­è¯­")

        phrases_db = query.all()

        if not phrases_db:
            print("\nâŒ æ²¡æœ‰å¾…å¤„ç†çš„çŸ­è¯­ï¼")
            return False

        phrases = [{
            'phrase_id': p.phrase_id,
            'phrase': p.phrase,
            'frequency': p.frequency,
            'volume': p.volume,
        } for p in phrases_db]

        print(f"âœ“ åŠ è½½äº† {len(phrases)} æ¡å¾…èšç±»çŸ­è¯­")

    # 2. è®¡ç®—Embeddings
    print("\nã€æ­¥éª¤2ã€‘è®¡ç®—Embeddings...")
    embedding_service = EmbeddingService(use_cache=True)
    embeddings, phrase_ids = embedding_service.embed_phrases_from_db(phrases, round_id)

    assert len(embeddings) == len(phrases), "Embeddingsæ•°é‡ä¸åŒ¹é…"

    # 3. å‡†å¤‡èšç±»é…ç½®
    print("\nã€æ­¥éª¤3ã€‘å‡†å¤‡Louvainèšç±»é…ç½®...")
    config = LOUVAIN_CONFIG.copy()

    if k_neighbors is not None:
        config['k_neighbors'] = k_neighbors
    if similarity_threshold is not None:
        config['similarity_threshold'] = similarity_threshold
    if resolution is not None:
        config['resolution'] = resolution

    print(f"  Kè¿‘é‚»æ•°: {config['k_neighbors']}")
    print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {config['similarity_threshold']}")
    print(f"  Louvainåˆ†è¾¨ç‡: {config['resolution']}")

    # 4. æ‰§è¡ŒLouvainèšç±»
    print("\nã€æ­¥éª¤4ã€‘æ‰§è¡ŒLouvainèšç±»...")
    cluster_ids, cluster_info, metadata = cluster_phrases_louvain(
        embeddings, phrases, config=config
    )

    # 5. æ›´æ–°æ•°æ®åº“
    print("\nã€æ­¥éª¤5ã€‘æ›´æ–°æ•°æ®åº“...")

    # 5.1 æ›´æ–°phrasesè¡¨
    print("  æ›´æ–°phrasesè¡¨...")
    with PhraseRepository() as repo:
        success_count = 0
        for i, phrase_id in enumerate(phrase_ids):
            cluster_id = int(cluster_ids[i])
            if repo.update_cluster_assignment(phrase_id, cluster_id_A=cluster_id):
                success_count += 1

        print(f"  âœ“ å·²æ›´æ–° {success_count}/{len(phrase_ids)} æ¡è®°å½•çš„cluster_id_A")

    # 5.2 ä¿å­˜cluster_metaè¡¨
    print("  ä¿å­˜èšç±»å…ƒæ•°æ®...")
    with ClusterMetaRepository() as repo:
        for cluster_id, info in cluster_info.items():
            example_phrases_str = '; '.join(info['example_phrases'])

            repo.create_or_update_cluster(
                cluster_id=cluster_id,
                cluster_level='A',
                size=info['size'],
                example_phrases=example_phrases_str,
                main_theme=None,  # Phase 2Cä¼šç”¨DeepSeekç”Ÿæˆ
                total_frequency=info['total_frequency']
            )

        print(f"  âœ“ å·²ä¿å­˜ {len(cluster_info)} ä¸ªèšç±»çš„å…ƒæ•°æ®")

    # 6. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("\nã€æ­¥éª¤6ã€‘ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")

    report_lines = []
    report_lines.append("="*70)
    report_lines.append("Phase 2B Louvainèšç±»æŠ¥å‘Š")
    report_lines.append("="*70)
    report_lines.append("")

    # èšç±»æ¦‚å†µ
    report_lines.append("ã€èšç±»æ¦‚å†µã€‘")
    report_lines.append(f"  æ€»çŸ­è¯­æ•°: {len(phrases):,}")
    report_lines.append(f"  æœ‰æ•ˆèšç±»æ•°: {len(cluster_info)}")
    noise_count = (cluster_ids == -1).sum()
    report_lines.append(f"  å™ªéŸ³ç‚¹æ•°: {noise_count} ({noise_count/len(phrases)*100:.1f}%)")
    report_lines.append(f"  æ¨¡å—åº¦ (Modularity): {metadata['modularity']:.4f}")
    report_lines.append("")

    # é…ç½®å‚æ•°
    report_lines.append("ã€é…ç½®å‚æ•°ã€‘")
    report_lines.append(f"  Kè¿‘é‚»æ•°: {config['k_neighbors']}")
    report_lines.append(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {config['similarity_threshold']}")
    report_lines.append(f"  Louvainåˆ†è¾¨ç‡: {config['resolution']}")
    report_lines.append("")

    # å›¾ç»Ÿè®¡
    report_lines.append("ã€å›¾ç»Ÿè®¡ä¿¡æ¯ã€‘")
    graph_stats = metadata['graph_stats']
    report_lines.append(f"  èŠ‚ç‚¹æ•°: {graph_stats['n_nodes']}")
    report_lines.append(f"  è¾¹æ•°: {graph_stats['n_edges']}")
    report_lines.append(f"  å¹³å‡åº¦: {graph_stats['avg_degree']:.2f}")
    report_lines.append(f"  å›¾å¯†åº¦: {graph_stats['density']:.6f}")
    report_lines.append("")

    # èšç±»å¤§å°åˆ†å¸ƒ
    sizes = [info['size'] for info in cluster_info.values()]
    report_lines.append("ã€èšç±»å¤§å°åˆ†å¸ƒã€‘")
    report_lines.append(f"  æœ€å°: {min(sizes)}")
    report_lines.append(f"  æœ€å¤§: {max(sizes)}")
    report_lines.append(f"  å¹³å‡: {sum(sizes)/len(sizes):.1f}")
    report_lines.append(f"  ä¸­ä½æ•°: {sorted(sizes)[len(sizes)//2]}")
    report_lines.append("")

    # Top 20 æœ€å¤§èšç±»
    report_lines.append("ã€Top 20 æœ€å¤§èšç±»ã€‘")
    sorted_clusters = sorted(
        cluster_info.items(),
        key=lambda x: x[1]['size'],
        reverse=True
    )

    report_lines.append(f"{'ID':<6} {'å¤§å°':<8} {'é¢‘æ¬¡':<10} {'ç¤ºä¾‹çŸ­è¯­'}")
    report_lines.append("-" * 70)

    for cluster_id, info in sorted_clusters[:20]:
        examples = ', '.join(info['example_phrases'][:3])
        if len(examples) > 40:
            examples = examples[:37] + '...'
        report_lines.append(
            f"{cluster_id:<6} {info['size']:<8} "
            f"{info['total_frequency']:<10} {examples}"
        )

    report_lines.append("")
    report_lines.append("="*70)
    report_lines.append("âœ… èšç±»å®Œæˆï¼è´¨é‡è¯„ä¼°ï¼š")
    if metadata['modularity'] > 0.6:
        report_lines.append("  æ¨¡å—åº¦ä¼˜ç§€ (>0.6)ï¼šèšç±»è¾¹ç•Œéå¸¸æ¸…æ™°")
    elif metadata['modularity'] > 0.4:
        report_lines.append("  æ¨¡å—åº¦è‰¯å¥½ (>0.4)ï¼šèšç±»è´¨é‡è¾ƒå¥½")
    else:
        report_lines.append("  æ¨¡å—åº¦ä¸€èˆ¬ï¼šå»ºè®®è°ƒæ•´å‚æ•°")
    report_lines.append("")
    report_lines.append("ä¸‹ä¸€æ­¥:")
    report_lines.append("  1. æŸ¥çœ‹Top 20èšç±»ï¼Œäººå·¥è¯„ä¼°è¯­ä¹‰ä¸€è‡´æ€§")
    report_lines.append("  2. å¦‚æœèšç±»æ•°é‡ä¸åœ¨60-100èŒƒå›´ï¼Œè¿è¡Œå‚æ•°è°ƒä¼˜")
    report_lines.append("  3. è¿è¡ŒDeepSeekè¯­ä¹‰æ ‡æ³¨: python scripts/run_phase2_label_clusters.py")
    report_lines.append("="*70)

    # è¾“å‡ºæŠ¥å‘Š
    report_text = '\n'.join(report_lines)
    print('\n' + report_text)

    # ä¿å­˜æŠ¥å‘Š
    OUTPUT_DIR.mkdir(exist_ok=True)
    report_file = OUTPUT_DIR / f'phase2b_louvain_report_round{round_id}.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    # 7. å®Œæˆ
    print("\n" + "="*70)
    print("âœ… Phase 2B Louvainèšç±»å®Œæˆï¼".center(70))
    print("="*70)

    print("\nğŸ“Š èšç±»æ‘˜è¦:")
    print(f"  - å¤„ç†çŸ­è¯­æ•°: {len(phrases):,}")
    print(f"  - ç”Ÿæˆèšç±»æ•°: {len(cluster_info)}")
    print(f"  - æ¨¡å—åº¦: {metadata['modularity']:.4f}")

    return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Phase 2B: Louvainèšç±»')
    parser.add_argument('--round-id', type=int, default=1, help='æ•°æ®è½®æ¬¡ID')
    parser.add_argument('--limit', type=int, default=0, help='é™åˆ¶å¤„ç†æ•°é‡ï¼ˆ0=å…¨éƒ¨ï¼‰')
    parser.add_argument('--k-neighbors', type=int, default=None, help='Kè¿‘é‚»æ•°é‡')
    parser.add_argument('--similarity-threshold', type=float, default=None, help='ç›¸ä¼¼åº¦é˜ˆå€¼')
    parser.add_argument('--resolution', type=float, default=None, help='Louvainåˆ†è¾¨ç‡å‚æ•°')

    args = parser.parse_args()

    try:
        success = run_phase2_louvain(
            round_id=args.round_id,
            limit=args.limit,
            k_neighbors=args.k_neighbors,
            similarity_threshold=args.similarity_threshold,
            resolution=args.resolution
        )
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        import traceback
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
