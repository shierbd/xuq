"""
Phase 0 - Experiment C: åŒä¹‰å†—ä½™ç‡æµ‹é‡
Redundancy Rate Measurement

ç›®æ ‡ï¼šæµ‹é‡åŒä¸€éœ€æ±‚çš„ä¸åŒè¡¨è¾¾å æ¯”

åˆ¤æ–­æ ‡å‡†ï¼š
- å†—ä½™ç‡<10% â†’ æš‚ä¸éœ€è¦è¯çº§è§„èŒƒåŒ–å»é‡
- å†—ä½™ç‡>20% â†’ éœ€è¦å®æ–½Phase 2.1è¯çº§è§„èŒƒåŒ–å»é‡

åˆ›å»ºæ—¥æœŸï¼š2025-12-23
"""

import json
import random
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set
import sys

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from storage.repository import PhraseRepository


def group_synonyms_interactive(sample_phrases: List[str]) -> List[List[int]]:
    """
    äº¤äº’å¼åŒä¹‰è¯åˆ†ç»„

    Args:
        sample_phrases: æŠ½æ ·çŸ­è¯­åˆ—è¡¨

    Returns:
        åŒä¹‰ç»„åˆ—è¡¨ï¼Œæ¯ç»„åŒ…å«çŸ­è¯­çš„ç´¢å¼•
        ç¤ºä¾‹: [[0, 5, 12], [3, 8], ...]
    """
    print("\n" + "="*70)
    print("åŒä¹‰è¯åˆ†ç»„è¯´æ˜")
    print("="*70)
    print("""
æ‚¨éœ€è¦è¯†åˆ«"ç›¸åŒéœ€æ±‚çš„ä¸åŒè¡¨è¾¾"ã€‚

ç¤ºä¾‹ï¼š
  - "best calculator" å’Œ "calculator best" â†’ åŒä¹‰ï¼ˆè¯åºä¸åŒï¼‰
  - "image compressor" å’Œ "compress image" â†’ åŒä¹‰ï¼ˆè¯å½¢å˜åŒ–ï¼‰
  - "best calculator" å’Œ "free calculator" â†’ ä¸åŒä¹‰ï¼ˆæ„å›¾ä¸åŒï¼šæ¨è vs å…è´¹ï¼‰

åˆ¤æ–­æ ‡å‡†ï¼š
  âœ“ åŒä¹‰ï¼šå»æ‰åœç”¨è¯åï¼Œæ ¸å¿ƒè¯ç›¸åŒä¸”æ„å›¾ç›¸åŒ
  âœ— ä¸åŒä¹‰ï¼šæ„å›¾ä¸åŒã€å¯¹è±¡ä¸åŒã€æˆ–é™å®šæ¡ä»¶ä¸åŒ

æ“ä½œè¯´æ˜ï¼š
  1. æ¯æ¬¡æ˜¾ç¤ºä¸€ä¸ªçŸ­è¯­
  2. å¦‚æœå®ƒä¸ä¹‹å‰æŸä¸ªçŸ­è¯­åŒä¹‰ï¼Œè¾“å…¥é‚£ä¸ªçŸ­è¯­çš„ç¼–å·
  3. å¦‚æœå®ƒæ˜¯æ–°çš„ç‹¬ç«‹éœ€æ±‚ï¼Œç›´æ¥æŒ‰Enter
  4. è¾“å…¥ 'q' æå‰ç»“æŸ
    """)

    input("\nå‡†å¤‡å¥½äº†å—ï¼ŸæŒ‰ Enter é”®å¼€å§‹...")

    # å­˜å‚¨åŒä¹‰ç»„ï¼š{group_id: [phrase_indices]}
    synonym_groups = {}
    phrase_to_group = {}  # {phrase_idx: group_id}
    next_group_id = 1

    for idx, phrase in enumerate(sample_phrases):
        print("\n" + "="*70)
        print(f"è¿›åº¦: {idx + 1}/{len(sample_phrases)}")
        print("="*70)
        print(f"\nå½“å‰çŸ­è¯­ [{idx}]: {phrase}")

        # æ˜¾ç¤ºå·²æœ‰çš„ç›¸ä¼¼çŸ­è¯­ï¼ˆä¾›å‚è€ƒï¼‰
        if phrase_to_group:
            print("\nå·²æ ‡è®°çš„çŸ­è¯­ï¼ˆå‰20ä¸ªï¼‰ï¼š")
            displayed_count = 0
            for prev_idx in range(idx):
                if displayed_count >= 20:
                    print("  ...")
                    break
                if prev_idx in phrase_to_group:
                    group_id = phrase_to_group[prev_idx]
                    print(f"  [{prev_idx}] {sample_phrases[prev_idx]} (ç»„{group_id})")
                    displayed_count += 1

        # ç”¨æˆ·è¾“å…¥
        user_input = input("\nä¸å“ªä¸ªçŸ­è¯­åŒä¹‰ï¼Ÿè¾“å…¥ç¼–å·ï¼Œæˆ–æŒ‰Enterè·³è¿‡ï¼Œæˆ–'q'é€€å‡º: ").strip().lower()

        if user_input == 'q':
            print("\næå‰ç»“æŸæ ‡æ³¨")
            break

        if user_input == '':
            # æ–°çš„ç‹¬ç«‹éœ€æ±‚ï¼Œä¸æ ‡è®°ä¸ºåŒä¹‰ç»„
            continue

        try:
            # ç”¨æˆ·æŒ‡å®šäº†åŒä¹‰çŸ­è¯­
            synonym_idx = int(user_input)

            if synonym_idx < 0 or synonym_idx >= idx:
                print(f"âš ï¸  æ— æ•ˆç¼–å·ï¼Œè·³è¿‡")
                continue

            # æ‰¾åˆ°æˆ–åˆ›å»ºåŒä¹‰ç»„
            if synonym_idx in phrase_to_group:
                # åŠ å…¥å·²æœ‰ç»„
                group_id = phrase_to_group[synonym_idx]
            else:
                # åˆ›å»ºæ–°ç»„ï¼ŒåŒ…å«ä¸¤ä¸ªçŸ­è¯­
                group_id = next_group_id
                next_group_id += 1
                synonym_groups[group_id] = [synonym_idx]
                phrase_to_group[synonym_idx] = group_id

            # å°†å½“å‰çŸ­è¯­åŠ å…¥ç»„
            synonym_groups[group_id].append(idx)
            phrase_to_group[idx] = group_id

            print(f"âœ“ å·²æ ‡è®°ä¸ºåŒä¹‰ï¼ˆç»„{group_id}ï¼‰")

        except ValueError:
            print(f"âš ï¸  æ— æ•ˆè¾“å…¥ï¼Œè·³è¿‡")
            continue

    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
    result = list(synonym_groups.values())
    return result


def run_experiment_c() -> Dict:
    """
    æ‰§è¡Œå®éªŒCï¼šåŒä¹‰å†—ä½™ç‡æµ‹é‡

    Returns:
        å®éªŒç»“æœå­—å…¸
    """
    print("\n" + "="*70)
    print("Phase 0 - Experiment C: åŒä¹‰å†—ä½™ç‡æµ‹é‡")
    print("="*70)

    # 1. åŠ è½½æ‰€æœ‰çŸ­è¯­
    print("\n1. åŠ è½½çŸ­è¯­æ•°æ®...")

    with PhraseRepository() as phrase_repo:
        all_phrases = phrase_repo.get_all()

    total_phrases = len(all_phrases)
    print(f"âœ“ çŸ­è¯­æ€»æ•°: {total_phrases:,}")

    # 2. éšæœºæŠ½æ ·1000æ¡
    sample_size = min(1000, total_phrases)

    print(f"\n2. éšæœºæŠ½æ · {sample_size} æ¡çŸ­è¯­...")

    random.seed(42)  # å›ºå®šç§å­ï¼Œä¾¿äºå¤ç°
    sample_phrases_obj = random.sample(all_phrases, sample_size)
    sample_phrases = [p.phrase for p in sample_phrases_obj]

    print(f"âœ“ æŠ½æ ·å®Œæˆ")

    # 3. äº¤äº’å¼åŒä¹‰è¯æ ‡æ³¨
    print("\n3. å¼€å§‹åŒä¹‰è¯æ ‡æ³¨...")

    synonym_groups = group_synonyms_interactive(sample_phrases)

    # 4. ç»Ÿè®¡ç»“æœ
    print("\n" + "="*70)
    print("æ ‡æ³¨ç»“æœç»Ÿè®¡")
    print("="*70)

    total_groups = len(synonym_groups)
    phrases_in_groups = sum(len(group) for group in synonym_groups)
    redundancy_rate = phrases_in_groups / sample_size if sample_size > 0 else 0

    print(f"\nåŒä¹‰ç»„æ•°é‡: {total_groups}")
    print(f"åŒä¹‰ç»„å†…çŸ­è¯­æ•°: {phrases_in_groups}")
    print(f"å†—ä½™ç‡: {redundancy_rate:.1%} ({phrases_in_groups}/{sample_size})")

    # æ˜¾ç¤ºåŒä¹‰ç»„ç¤ºä¾‹
    if synonym_groups:
        print(f"\nåŒä¹‰ç»„ç¤ºä¾‹ï¼ˆå‰5ç»„ï¼‰ï¼š")
        for i, group in enumerate(synonym_groups[:5], 1):
            print(f"\n  ç»„{i}:")
            for idx in group:
                print(f"    [{idx}] {sample_phrases[idx]}")

    # 5. ç”Ÿæˆç»“æœ
    result = {
        'experiment': 'C',
        'name': 'åŒä¹‰å†—ä½™ç‡',
        'timestamp': datetime.now().isoformat(),
        'sample_size': sample_size,
        'total_phrases': total_phrases,
        'synonym_groups_count': total_groups,
        'phrases_in_groups': phrases_in_groups,
        'redundancy_rate': round(redundancy_rate, 4),
        'synonym_groups': [
            {
                'group_id': i,
                'phrases': [sample_phrases[idx] for idx in group]
            }
            for i, group in enumerate(synonym_groups, 1)
        ]
    }

    # 6. åˆ¤æ–­æ˜¯å¦éœ€è¦è§„èŒƒåŒ–
    if redundancy_rate < 0.10:
        result['recommendation'] = 'ok'
        result['recommendation_detail'] = f'å†—ä½™ç‡{redundancy_rate:.1%}ï¼Œæš‚ä¸éœ€è¦è¯çº§è§„èŒƒåŒ–å»é‡'
    elif redundancy_rate > 0.20:
        result['recommendation'] = 'need_canonicalization'
        result['recommendation_detail'] = f'å†—ä½™ç‡{redundancy_rate:.1%}ï¼Œå»ºè®®å®æ–½Phase 2.1è¯çº§è§„èŒƒåŒ–å»é‡'
    else:
        result['recommendation'] = 'moderate'
        result['recommendation_detail'] = f'å†—ä½™ç‡{redundancy_rate:.1%}ï¼Œå¯è€ƒè™‘é€‚åº¦è§„èŒƒåŒ–'

    # 7. ä¿å­˜ç»“æœ
    output_dir = project_root / 'data' / 'phase0_results'
    output_dir.mkdir(parents=True, exist_ok=True)

    result_file = output_dir / 'experiment_c_result.json'
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    # 8. æ˜¾ç¤ºç»“æœ
    print("\n" + "="*70)
    print("å®éªŒCç»“æœ")
    print("="*70)
    print(f"æŠ½æ ·æ•°é‡:       {result['sample_size']:,}")
    print(f"åŒä¹‰ç»„æ•°:       {result['synonym_groups_count']}")
    print(f"åŒä¹‰çŸ­è¯­æ•°:     {result['phrases_in_groups']}")
    print(f"å†—ä½™ç‡:         {result['redundancy_rate']:.1%}")
    print(f"\nåˆ¤æ–­ç»“æœ:       {result['recommendation']}")
    print(f"å»ºè®®:           {result['recommendation_detail']}")
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    print("="*70)

    return result


if __name__ == "__main__":
    try:
        result = run_experiment_c()

        print("\nâœ… å®éªŒCå®Œæˆï¼")
        print(f"\nğŸ“Œ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œå®éªŒDï¼ˆæœç´¢æ„å›¾åˆ†å¸ƒç»Ÿè®¡ï¼‰")
        print(f"   å‘½ä»¤: python scripts/phase0_experiment_d_intent_distribution.py")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  å®éªŒè¢«ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å®éªŒæ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
