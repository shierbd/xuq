# éœ€æ±‚æº¯æºç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ

## 1. è®¾è®¡ç›®æ ‡

ä¸ºå¤šç»´åº¦éœ€æ±‚åˆ†æå·¥å…·å»ºç«‹å®Œæ•´çš„æº¯æºä½“ç³»,å®ç°:

1. **æ¥æºè¿½è¸ª**: è®°å½•æ¯ä¸ªéœ€æ±‚ä»å“ªä¸ªPhaseã€å“ªä¸ªæ–¹æ³•å‘ç°
2. **æ•°æ®æº¯æº**: è¿½è¸ªéœ€æ±‚å…³è”çš„åŸå§‹æ•°æ®(çŸ­è¯­ã€å•†å“ã€Redditæ¿å—ç­‰)
3. **æ¼”åŒ–å†å²**: è®°å½•éœ€æ±‚çš„ç½®ä¿¡åº¦å˜åŒ–ã€éªŒè¯è¿‡ç¨‹
4. **å…³ç³»è¿½è¸ª**: è¿½è¸ªéœ€æ±‚ä¸è¯ã€äº§å“çš„å¤šå¯¹å¤šå…³è”
5. **å®¡è®¡æ—¥å¿—**: è®°å½•æ‰€æœ‰å…³é”®æ“ä½œçš„å†å²

## 2. æ ¸å¿ƒæ¦‚å¿µ

### 2.1 éœ€æ±‚ä¸‰è§’å…³ç³»

```
       Demand (éœ€æ±‚)
      /      |      \
     /       |       \
  Phrase   Token   Product
  (è¯ç»„)   (è¯æ ¹)   (å•†å“)
```

### 2.2 æº¯æºç»´åº¦

- **Phaseç»´åº¦**: phase1-7, manual (æ‰‹åŠ¨åˆ›å»º)
- **Methodç»´åº¦**:
  - keyword_clustering (å…³é”®è¯èšç±»)
  - reddit_analysis (Redditæ¿å—åˆ†æ)
  - product_reverse_engineering (å•†å“åå‘å·¥ç¨‹)
  - manual_creation (äººå·¥åˆ›å»º)
  - ai_inference (AIæ¨æ–­)
- **Sourceç»´åº¦**: å…·ä½“çš„æ•°æ®æºID (phrase_id, product_id, subreddit_idç­‰)
- **Timeç»´åº¦**: å‘ç°æ—¶é—´ã€æ›´æ–°æ—¶é—´ã€éªŒè¯æ—¶é—´

## 3. æ•°æ®åº“è®¾è®¡

### 3.1 æ‰©å±•Demandè¡¨ (demands)

åœ¨ç°æœ‰Demandè¡¨åŸºç¡€ä¸Šæ–°å¢æº¯æºå­—æ®µ:

```python
class Demand(Base):
    # ... ç°æœ‰å­—æ®µ ...

    # ========== æ–°å¢: æº¯æºå­—æ®µ ==========

    # æ¥æºè¿½è¸ª
    source_phase = Column(String(20), index=True)  # phase1-7, manual
    source_method = Column(String(50), index=True)  # å‘ç°æ–¹æ³•
    source_data_ids = Column(Text)  # JSONæ•°ç»„: æºæ•°æ®IDåˆ—è¡¨

    # ç½®ä¿¡åº¦è¿½è¸ª
    confidence_score = Column(DECIMAL(3, 2), default=Decimal("0.5"))  # 0.00-1.00
    confidence_history = Column(Text)  # JSONæ•°ç»„: ç½®ä¿¡åº¦å˜åŒ–å†å²

    # æ—¶é—´è¿½è¸ª
    discovered_at = Column(TIMESTAMP, nullable=False, default=datetime.utcnow)
    last_validated_at = Column(TIMESTAMP)
    validation_count = Column(Integer, default=0)

    # éªŒè¯çŠ¶æ€
    is_validated = Column(Boolean, default=False, index=True)
    validated_by = Column(String(100))  # user, ai, system
    validation_notes = Column(Text)
```

### 3.2 æ–°å»º: DemandPhraseMapping (éœ€æ±‚-çŸ­è¯­å…³è”è¡¨)

```python
class DemandPhraseMapping(Base):
    """éœ€æ±‚ä¸çŸ­è¯­çš„å¤šå¯¹å¤šå…³è”è¡¨"""

    __tablename__ = "demand_phrase_mappings"

    # ä¸»é”®
    mapping_id = Column(Integer, primary_key=True, autoincrement=True)

    # å…³è”å…³ç³»
    demand_id = Column(Integer, ForeignKey('demands.demand_id'), nullable=False, index=True)
    phrase_id = Column(BigInteger, ForeignKey('phrases.phrase_id'), nullable=False, index=True)

    # å…³è”å¼ºåº¦
    relevance_score = Column(DECIMAL(3, 2))  # 0.00-1.00

    # æº¯æºä¿¡æ¯
    mapping_source = Column(String(50), index=True)  # clustering, manual, ai_inference
    created_by_phase = Column(String(20))  # å“ªä¸ªPhaseåˆ›å»ºçš„å…³è”
    created_by_method = Column(String(50))  # å“ªä¸ªæ–¹æ³•åˆ›å»ºçš„å…³è”

    # éªŒè¯çŠ¶æ€
    is_validated = Column(Boolean, default=False, index=True)
    validated_at = Column(TIMESTAMP)
    validated_by = Column(String(100))

    # å…ƒæ•°æ®
    created_at = Column(TIMESTAMP, nullable=False, default=datetime.utcnow)
    notes = Column(Text)

    # å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_demand_phrase', 'demand_id', 'phrase_id'),
        Index('idx_source_validated', 'mapping_source', 'is_validated'),
    )
```

### 3.3 æ–°å»º: DemandProductMapping (éœ€æ±‚-å•†å“å…³è”è¡¨)

```python
class DemandProductMapping(Base):
    """éœ€æ±‚ä¸å•†å“çš„å¤šå¯¹å¤šå…³è”è¡¨"""

    __tablename__ = "demand_product_mappings"

    # ä¸»é”®
    mapping_id = Column(Integer, primary_key=True, autoincrement=True)

    # å…³è”å…³ç³»
    demand_id = Column(Integer, ForeignKey('demands.demand_id'), nullable=False, index=True)
    product_id = Column(BigInteger, ForeignKey('products.product_id'), nullable=False, index=True)

    # é€‚é…åº¦è¯„åˆ†
    fit_score = Column(DECIMAL(3, 2))  # 0.00-1.00
    fit_level = enum_column(
        "fit_level",
        ["high", "medium", "low"],
        enum_name="fit_level_enum",
        index=True
    )

    # æº¯æºä¿¡æ¯
    mapping_source = Column(String(50), index=True)  # product_analysis, manual, ai_inference
    created_by_phase = Column(String(20))
    created_by_method = Column(String(50))

    # éªŒè¯çŠ¶æ€
    is_validated = Column(Boolean, default=False, index=True)
    validated_at = Column(TIMESTAMP)
    validated_by = Column(String(100))
    validation_notes = Column(Text)

    # å…ƒæ•°æ®
    created_at = Column(TIMESTAMP, nullable=False, default=datetime.utcnow)

    # å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_demand_product', 'demand_id', 'product_id'),
        Index('idx_fit_validated', 'fit_level', 'is_validated'),
    )
```

### 3.4 æ–°å»º: DemandTokenMapping (éœ€æ±‚-è¯æ ¹å…³è”è¡¨)

```python
class DemandTokenMapping(Base):
    """éœ€æ±‚ä¸Tokençš„å¤šå¯¹å¤šå…³è”è¡¨"""

    __tablename__ = "demand_token_mappings"

    # ä¸»é”®
    mapping_id = Column(Integer, primary_key=True, autoincrement=True)

    # å…³è”å…³ç³»
    demand_id = Column(Integer, ForeignKey('demands.demand_id'), nullable=False, index=True)
    token_id = Column(Integer, ForeignKey('tokens.token_id'), nullable=False, index=True)

    # å…³è”ç±»å‹
    token_role = enum_column(
        "token_role",
        ["core", "supporting", "context"],
        enum_name="token_role_enum",
        index=True
    )  # core=æ ¸å¿ƒè¯, supporting=æ”¯æ’‘è¯, context=ä¸Šä¸‹æ–‡è¯

    # é‡è¦æ€§è¯„åˆ†
    importance_score = Column(DECIMAL(3, 2))  # 0.00-1.00

    # æº¯æºä¿¡æ¯
    mapping_source = Column(String(50), index=True)
    created_by_phase = Column(String(20))
    created_by_method = Column(String(50))

    # éªŒè¯çŠ¶æ€
    is_validated = Column(Boolean, default=False, index=True)
    validated_at = Column(TIMESTAMP)

    # å…ƒæ•°æ®
    created_at = Column(TIMESTAMP, nullable=False, default=datetime.utcnow)

    # å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_demand_token', 'demand_id', 'token_id'),
        Index('idx_role_validated', 'token_role', 'is_validated'),
    )
```

### 3.5 æ–°å»º: DemandProvenance (éœ€æ±‚æº¯æºå®¡è®¡è¡¨)

```python
class DemandProvenance(Base):
    """éœ€æ±‚æº¯æºå®¡è®¡è¡¨ - è®°å½•éœ€æ±‚çš„æ‰€æœ‰å˜æ›´å†å²"""

    __tablename__ = "demand_provenance"

    # ä¸»é”®
    provenance_id = Column(Integer, primary_key=True, autoincrement=True)

    # å…³è”éœ€æ±‚
    demand_id = Column(Integer, ForeignKey('demands.demand_id'), nullable=False, index=True)

    # äº‹ä»¶ç±»å‹
    event_type = enum_column(
        "event_type",
        [
            "created",           # åˆ›å»º
            "updated",           # æ›´æ–°
            "validated",         # éªŒè¯
            "merged",            # åˆå¹¶
            "split",             # æ‹†åˆ†
            "linked_phrase",     # å…³è”çŸ­è¯­
            "linked_product",    # å…³è”å•†å“
            "linked_token",      # å…³è”è¯æ ¹
            "confidence_changed", # ç½®ä¿¡åº¦å˜åŒ–
            "status_changed"     # çŠ¶æ€å˜åŒ–
        ],
        enum_name="event_type_enum",
        nullable=False,
        index=True
    )

    # äº‹ä»¶è¯¦æƒ…
    event_description = Column(Text)
    old_value = Column(Text)  # JSONæ ¼å¼: å˜æ›´å‰çš„å€¼
    new_value = Column(Text)  # JSONæ ¼å¼: å˜æ›´åçš„å€¼

    # æº¯æºä¿¡æ¯
    triggered_by_phase = Column(String(20))
    triggered_by_method = Column(String(50))
    triggered_by_user = Column(String(100))  # user, ai, system

    # å…³è”æ•°æ®
    related_data_type = Column(String(50))  # phrase, product, token, cluster
    related_data_id = Column(Integer)

    # å…ƒæ•°æ®
    created_at = Column(TIMESTAMP, nullable=False, default=datetime.utcnow, index=True)

    # ç´¢å¼•
    __table_args__ = (
        Index('idx_demand_event', 'demand_id', 'event_type'),
        Index('idx_demand_time', 'demand_id', 'created_at'),
    )
```

## 4. æ ¸å¿ƒåŠŸèƒ½å®ç°

### 4.1 éœ€æ±‚åˆ›å»ºæ—¶çš„æº¯æºè®°å½•

```python
class DemandProvenanceService:
    """éœ€æ±‚æº¯æºæœåŠ¡"""

    def create_demand_with_provenance(
        self,
        title: str,
        description: str,
        source_phase: str,
        source_method: str,
        source_data_ids: List[int],
        confidence_score: float = 0.5
    ) -> int:
        """
        åˆ›å»ºéœ€æ±‚å¹¶è®°å½•æº¯æºä¿¡æ¯

        Args:
            title: éœ€æ±‚æ ‡é¢˜
            description: éœ€æ±‚æè¿°
            source_phase: æ¥æºPhase (phase1-7, manual)
            source_method: å‘ç°æ–¹æ³•
            source_data_ids: æºæ•°æ®IDåˆ—è¡¨
            confidence_score: åˆå§‹ç½®ä¿¡åº¦

        Returns:
            demand_id: åˆ›å»ºçš„éœ€æ±‚ID
        """
        # 1. åˆ›å»ºéœ€æ±‚
        demand = Demand(
            title=title,
            description=description,
            source_phase=source_phase,
            source_method=source_method,
            source_data_ids=json.dumps(source_data_ids),
            confidence_score=Decimal(str(confidence_score)),
            confidence_history=json.dumps([{
                'score': confidence_score,
                'timestamp': datetime.utcnow().isoformat(),
                'reason': 'initial_creation'
            }]),
            discovered_at=datetime.utcnow()
        )

        session.add(demand)
        session.flush()

        # 2. è®°å½•æº¯æºäº‹ä»¶
        provenance = DemandProvenance(
            demand_id=demand.demand_id,
            event_type='created',
            event_description=f'éœ€æ±‚ç”±{source_method}æ–¹æ³•å‘ç°',
            new_value=json.dumps({
                'title': title,
                'source_phase': source_phase,
                'source_method': source_method,
                'confidence_score': confidence_score
            }),
            triggered_by_phase=source_phase,
            triggered_by_method=source_method,
            triggered_by_user='system'
        )

        session.add(provenance)
        session.commit()

        return demand.demand_id
```

### 4.2 å»ºç«‹éœ€æ±‚-çŸ­è¯­å…³è”

```python
def link_demand_to_phrases(
    self,
    demand_id: int,
    phrase_ids: List[int],
    relevance_scores: List[float],
    source: str,
    phase: str,
    method: str
) -> List[int]:
    """
    å»ºç«‹éœ€æ±‚ä¸çŸ­è¯­çš„å…³è”

    Args:
        demand_id: éœ€æ±‚ID
        phrase_ids: çŸ­è¯­IDåˆ—è¡¨
        relevance_scores: ç›¸å…³æ€§è¯„åˆ†åˆ—è¡¨
        source: å…³è”æ¥æº (clustering, manual, ai_inference)
        phase: åˆ›å»ºå…³è”çš„Phase
        method: åˆ›å»ºå…³è”çš„æ–¹æ³•

    Returns:
        mapping_ids: åˆ›å»ºçš„å…³è”IDåˆ—è¡¨
    """
    mapping_ids = []

    for phrase_id, score in zip(phrase_ids, relevance_scores):
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = session.query(DemandPhraseMapping).filter_by(
            demand_id=demand_id,
            phrase_id=phrase_id
        ).first()

        if existing:
            # æ›´æ–°è¯„åˆ†
            existing.relevance_score = Decimal(str(score))
            mapping_id = existing.mapping_id
        else:
            # åˆ›å»ºæ–°å…³è”
            mapping = DemandPhraseMapping(
                demand_id=demand_id,
                phrase_id=phrase_id,
                relevance_score=Decimal(str(score)),
                mapping_source=source,
                created_by_phase=phase,
                created_by_method=method
            )
            session.add(mapping)
            session.flush()
            mapping_id = mapping.mapping_id

        mapping_ids.append(mapping_id)

        # è®°å½•æº¯æºäº‹ä»¶
        provenance = DemandProvenance(
            demand_id=demand_id,
            event_type='linked_phrase',
            event_description=f'å…³è”çŸ­è¯­ (ID: {phrase_id})',
            new_value=json.dumps({
                'phrase_id': phrase_id,
                'relevance_score': score,
                'source': source
            }),
            triggered_by_phase=phase,
            triggered_by_method=method,
            triggered_by_user='system',
            related_data_type='phrase',
            related_data_id=phrase_id
        )
        session.add(provenance)

    session.commit()
    return mapping_ids
```

### 4.3 ç½®ä¿¡åº¦æ›´æ–°ä¸å†å²è¿½è¸ª

```python
def update_confidence_score(
    self,
    demand_id: int,
    new_score: float,
    reason: str,
    triggered_by: str = 'system'
) -> None:
    """
    æ›´æ–°éœ€æ±‚ç½®ä¿¡åº¦å¹¶è®°å½•å†å²

    Args:
        demand_id: éœ€æ±‚ID
        new_score: æ–°ç½®ä¿¡åº¦ (0.0-1.0)
        reason: å˜æ›´åŸå› 
        triggered_by: è§¦å‘è€… (user, ai, system)
    """
    demand = session.query(Demand).get(demand_id)

    if not demand:
        raise ValueError(f"Demand {demand_id} not found")

    # è®°å½•æ—§å€¼
    old_score = float(demand.confidence_score)

    # æ›´æ–°ç½®ä¿¡åº¦
    demand.confidence_score = Decimal(str(new_score))

    # æ›´æ–°å†å²
    history = json.loads(demand.confidence_history or '[]')
    history.append({
        'score': new_score,
        'timestamp': datetime.utcnow().isoformat(),
        'reason': reason,
        'triggered_by': triggered_by
    })
    demand.confidence_history = json.dumps(history)

    # è®°å½•æº¯æºäº‹ä»¶
    provenance = DemandProvenance(
        demand_id=demand_id,
        event_type='confidence_changed',
        event_description=f'ç½®ä¿¡åº¦ä» {old_score:.2f} å˜æ›´ä¸º {new_score:.2f}',
        old_value=json.dumps({'confidence_score': old_score}),
        new_value=json.dumps({'confidence_score': new_score, 'reason': reason}),
        triggered_by_user=triggered_by
    )

    session.add(provenance)
    session.commit()
```

### 4.4 éœ€æ±‚éªŒè¯

```python
def validate_demand(
    self,
    demand_id: int,
    validated_by: str,
    validation_notes: str = None
) -> None:
    """
    éªŒè¯éœ€æ±‚

    Args:
        demand_id: éœ€æ±‚ID
        validated_by: éªŒè¯è€… (user, ai)
        validation_notes: éªŒè¯å¤‡æ³¨
    """
    demand = session.query(Demand).get(demand_id)

    if not demand:
        raise ValueError(f"Demand {demand_id} not found")

    # æ›´æ–°éªŒè¯çŠ¶æ€
    demand.is_validated = True
    demand.validated_by = validated_by
    demand.last_validated_at = datetime.utcnow()
    demand.validation_count += 1
    demand.validation_notes = validation_notes

    # æå‡ç½®ä¿¡åº¦
    old_confidence = float(demand.confidence_score)
    new_confidence = min(1.0, old_confidence + 0.2)  # éªŒè¯åæå‡20%
    demand.confidence_score = Decimal(str(new_confidence))

    # è®°å½•æº¯æºäº‹ä»¶
    provenance = DemandProvenance(
        demand_id=demand_id,
        event_type='validated',
        event_description=f'éœ€æ±‚å·²è¢«{validated_by}éªŒè¯',
        old_value=json.dumps({
            'is_validated': False,
            'confidence_score': old_confidence
        }),
        new_value=json.dumps({
            'is_validated': True,
            'confidence_score': new_confidence,
            'validated_by': validated_by,
            'notes': validation_notes
        }),
        triggered_by_user=validated_by
    )

    session.add(provenance)
    session.commit()
```

## 5. æŸ¥è¯¢æ¥å£

### 5.1 è·å–éœ€æ±‚çš„å®Œæ•´æº¯æºä¿¡æ¯

```python
def get_demand_provenance(self, demand_id: int) -> Dict:
    """
    è·å–éœ€æ±‚çš„å®Œæ•´æº¯æºä¿¡æ¯

    Returns:
        {
            'demand': {...},  # éœ€æ±‚åŸºæœ¬ä¿¡æ¯
            'source': {...},  # æ¥æºä¿¡æ¯
            'related_phrases': [...],  # å…³è”çš„çŸ­è¯­
            'related_products': [...],  # å…³è”çš„å•†å“
            'related_tokens': [...],  # å…³è”çš„è¯æ ¹
            'confidence_history': [...],  # ç½®ä¿¡åº¦å†å²
            'event_timeline': [...]  # äº‹ä»¶æ—¶é—´çº¿
        }
    """
    demand = session.query(Demand).get(demand_id)

    if not demand:
        raise ValueError(f"Demand {demand_id} not found")

    # 1. åŸºæœ¬ä¿¡æ¯
    result = {
        'demand': {
            'demand_id': demand.demand_id,
            'title': demand.title,
            'description': demand.description,
            'status': demand.status,
            'is_validated': demand.is_validated
        },
        'source': {
            'phase': demand.source_phase,
            'method': demand.source_method,
            'discovered_at': demand.discovered_at.isoformat(),
            'confidence_score': float(demand.confidence_score)
        }
    }

    # 2. å…³è”çš„çŸ­è¯­
    phrase_mappings = session.query(DemandPhraseMapping).filter_by(
        demand_id=demand_id
    ).all()

    result['related_phrases'] = [{
        'phrase_id': m.phrase_id,
        'phrase': session.query(Phrase).get(m.phrase_id).phrase,
        'relevance_score': float(m.relevance_score),
        'mapping_source': m.mapping_source,
        'is_validated': m.is_validated
    } for m in phrase_mappings]

    # 3. å…³è”çš„å•†å“
    product_mappings = session.query(DemandProductMapping).filter_by(
        demand_id=demand_id
    ).all()

    result['related_products'] = [{
        'product_id': m.product_id,
        'product_name': session.query(Product).get(m.product_id).product_name,
        'fit_score': float(m.fit_score),
        'fit_level': m.fit_level,
        'is_validated': m.is_validated
    } for m in product_mappings]

    # 4. å…³è”çš„è¯æ ¹
    token_mappings = session.query(DemandTokenMapping).filter_by(
        demand_id=demand_id
    ).all()

    result['related_tokens'] = [{
        'token_id': m.token_id,
        'token_text': session.query(Token).get(m.token_id).token_text,
        'token_role': m.token_role,
        'importance_score': float(m.importance_score)
    } for m in token_mappings]

    # 5. ç½®ä¿¡åº¦å†å²
    result['confidence_history'] = json.loads(demand.confidence_history or '[]')

    # 6. äº‹ä»¶æ—¶é—´çº¿
    events = session.query(DemandProvenance).filter_by(
        demand_id=demand_id
    ).order_by(DemandProvenance.created_at).all()

    result['event_timeline'] = [{
        'event_type': e.event_type,
        'description': e.event_description,
        'timestamp': e.created_at.isoformat(),
        'triggered_by': e.triggered_by_user
    } for e in events]

    return result
```

### 5.2 æŒ‰æ¥æºç»Ÿè®¡éœ€æ±‚

```python
def get_demands_by_source(self) -> Dict:
    """
    æŒ‰æ¥æºç»Ÿè®¡éœ€æ±‚åˆ†å¸ƒ

    Returns:
        {
            'by_phase': {...},
            'by_method': {...},
            'by_validation_status': {...}
        }
    """
    # æŒ‰Phaseç»Ÿè®¡
    by_phase = {}
    phase_stats = session.query(
        Demand.source_phase,
        func.count(Demand.demand_id).label('count'),
        func.avg(Demand.confidence_score).label('avg_confidence')
    ).group_by(Demand.source_phase).all()

    for phase, count, avg_conf in phase_stats:
        by_phase[phase] = {
            'count': count,
            'avg_confidence': float(avg_conf) if avg_conf else 0
        }

    # æŒ‰Methodç»Ÿè®¡
    by_method = {}
    method_stats = session.query(
        Demand.source_method,
        func.count(Demand.demand_id).label('count')
    ).group_by(Demand.source_method).all()

    for method, count in method_stats:
        by_method[method] = count

    # æŒ‰éªŒè¯çŠ¶æ€ç»Ÿè®¡
    validation_stats = session.query(
        Demand.is_validated,
        func.count(Demand.demand_id).label('count')
    ).group_by(Demand.is_validated).all()

    by_validation = {
        'validated': 0,
        'unvalidated': 0
    }

    for is_validated, count in validation_stats:
        if is_validated:
            by_validation['validated'] = count
        else:
            by_validation['unvalidated'] = count

    return {
        'by_phase': by_phase,
        'by_method': by_method,
        'by_validation_status': by_validation
    }
```

## 6. UIå±•ç¤ºè®¾è®¡

### 6.1 éœ€æ±‚è¯¦æƒ…é¡µ - æº¯æºä¿¡æ¯å±•ç¤º

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éœ€æ±‚è¯¦æƒ…: [éœ€æ±‚æ ‡é¢˜]                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚ ğŸ“ æ¥æºä¿¡æ¯                                               â”‚
â”‚   â€¢ å‘ç°é˜¶æ®µ: Phase 7 - å•†å“åå‘å·¥ç¨‹                      â”‚
â”‚   â€¢ å‘ç°æ–¹æ³•: product_reverse_engineering                 â”‚
â”‚   â€¢ å‘ç°æ—¶é—´: 2026-01-17 10:30:25                        â”‚
â”‚   â€¢ ç½®ä¿¡åº¦: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80%                               â”‚
â”‚                                                           â”‚
â”‚ ğŸ”— å…³è”æ•°æ®                                               â”‚
â”‚   â€¢ å…³è”çŸ­è¯­: 15ä¸ª (æŸ¥çœ‹è¯¦æƒ…)                            â”‚
â”‚   â€¢ å…³è”å•†å“: 8ä¸ª (æŸ¥çœ‹è¯¦æƒ…)                             â”‚
â”‚   â€¢ å…³è”è¯æ ¹: 5ä¸ª (æŸ¥çœ‹è¯¦æƒ…)                             â”‚
â”‚                                                           â”‚
â”‚ ğŸ“Š ç½®ä¿¡åº¦æ¼”åŒ–                                             â”‚
â”‚   [æŠ˜çº¿å›¾æ˜¾ç¤ºç½®ä¿¡åº¦éšæ—¶é—´å˜åŒ–]                            â”‚
â”‚                                                           â”‚
â”‚ ğŸ“œ äº‹ä»¶æ—¶é—´çº¿                                             â”‚
â”‚   2026-01-17 10:30  âœ¨ éœ€æ±‚åˆ›å»º (åˆå§‹ç½®ä¿¡åº¦: 50%)        â”‚
â”‚   2026-01-17 11:15  ğŸ”— å…³è”8ä¸ªå•†å“                       â”‚
â”‚   2026-01-17 14:20  ğŸ“ˆ ç½®ä¿¡åº¦æå‡è‡³ 65% (AIéªŒè¯)         â”‚
â”‚   2026-01-18 09:00  âœ… äººå·¥éªŒè¯é€šè¿‡ (ç½®ä¿¡åº¦: 80%)        â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 éœ€æ±‚ä¸­å¿ƒ - æ¥æºåˆ†å¸ƒè§†å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éœ€æ±‚ä¸­å¿ƒ - æ¥æºåˆ†å¸ƒ                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚ æŒ‰Phaseåˆ†å¸ƒ:                                              â”‚
â”‚   Phase 1-5 (å…³é”®è¯èšç±»)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  45ä¸ª (60%)   â”‚
â”‚   Phase 6 (Redditåˆ†æ)    â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  12ä¸ª (16%)   â”‚
â”‚   Phase 7 (å•†å“åˆ†æ)      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  18ä¸ª (24%)   â”‚
â”‚                                                           â”‚
â”‚ æŒ‰éªŒè¯çŠ¶æ€:                                               â”‚
â”‚   å·²éªŒè¯   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  30ä¸ª (40%)                    â”‚
â”‚   æœªéªŒè¯   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  45ä¸ª (60%)                    â”‚
â”‚                                                           â”‚
â”‚ å¹³å‡ç½®ä¿¡åº¦: 67%                                           â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 7. å®æ–½è®¡åˆ’

### Phase 1: æ•°æ®åº“è¿ç§» (1-2å¤©)
- [ ] åˆ›å»º4ä¸ªæ–°è¡¨çš„migrationè„šæœ¬
- [ ] æ‰©å±•Demandè¡¨å­—æ®µ
- [ ] æµ‹è¯•MySQLå’ŒSQLiteå…¼å®¹æ€§
- [ ] æ‰§è¡Œæ•°æ®åº“è¿ç§»

### Phase 2: æ ¸å¿ƒæœåŠ¡å®ç° (2-3å¤©)
- [ ] å®ç°DemandProvenanceServiceç±»
- [ ] å®ç°éœ€æ±‚åˆ›å»ºæ—¶çš„æº¯æºè®°å½•
- [ ] å®ç°å…³è”å…³ç³»å»ºç«‹
- [ ] å®ç°ç½®ä¿¡åº¦æ›´æ–°æœºåˆ¶
- [ ] å®ç°éªŒè¯åŠŸèƒ½

### Phase 3: æŸ¥è¯¢æ¥å£ (1-2å¤©)
- [ ] å®ç°æº¯æºä¿¡æ¯æŸ¥è¯¢
- [ ] å®ç°ç»Ÿè®¡åˆ†ææ¥å£
- [ ] å®ç°æ—¶é—´çº¿æŸ¥è¯¢
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•

### Phase 4: UIé›†æˆ (2-3å¤©)
- [ ] åˆ›å»ºéœ€æ±‚è¯¦æƒ…é¡µæº¯æºå±•ç¤º
- [ ] åˆ›å»ºéœ€æ±‚ä¸­å¿ƒæ¥æºåˆ†å¸ƒè§†å›¾
- [ ] æ·»åŠ ç½®ä¿¡åº¦æ¼”åŒ–å›¾è¡¨
- [ ] æ·»åŠ äº‹ä»¶æ—¶é—´çº¿ç»„ä»¶

### Phase 5: æ•°æ®è¿ç§» (1å¤©)
- [ ] ä¸ºç°æœ‰éœ€æ±‚è¡¥å……æº¯æºä¿¡æ¯
- [ ] ä¸ºç°æœ‰å…³è”å…³ç³»è¡¥å……å…ƒæ•°æ®
- [ ] æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥

## 8. æ³¨æ„äº‹é¡¹

1. **æ€§èƒ½è€ƒè™‘**:
   - DemandProvenanceè¡¨ä¼šå¿«é€Ÿå¢é•¿,éœ€è¦å®šæœŸå½’æ¡£
   - å¤åˆç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
   - è€ƒè™‘ä½¿ç”¨ç¼“å­˜å‡å°‘æ•°æ®åº“æŸ¥è¯¢

2. **æ•°æ®ä¸€è‡´æ€§**:
   - ä½¿ç”¨äº‹åŠ¡ç¡®ä¿éœ€æ±‚åˆ›å»ºå’Œæº¯æºè®°å½•çš„åŸå­æ€§
   - å®šæœŸæ£€æŸ¥å…³è”å…³ç³»çš„æœ‰æ•ˆæ€§

3. **æ‰©å±•æ€§**:
   - é¢„ç•™å­—æ®µæ”¯æŒæœªæ¥æ–°çš„Phaseå’ŒMethod
   - JSONå­—æ®µæ”¯æŒçµæ´»çš„å…ƒæ•°æ®å­˜å‚¨

4. **éšç§å’Œå®‰å…¨**:
   - å®¡è®¡æ—¥å¿—ä¸å¯åˆ é™¤,åªèƒ½å½’æ¡£
   - æ•æ„Ÿæ“ä½œéœ€è¦è®°å½•æ“ä½œè€…ä¿¡æ¯
