# MVPç‰ˆæœ¬å®æ–½æ–¹æ¡ˆï¼ˆåŸºäºGPTåé¦ˆè°ƒæ•´ï¼‰

**è°ƒæ•´æ—¥æœŸ**: 2024-12-19
**è°ƒæ•´åŸå› **: åŸæ–¹æ¡ˆè¿‡åº¦è®¾è®¡ï¼Œç°èšç„¦MVPå¿«é€ŸéªŒè¯
**æ ¸å¿ƒç›®æ ‡**: 2å‘¨å†…å®ŒæˆPhase 1-4ï¼Œäº§å‡ºç¬¬ä¸€æ‰¹éœ€æ±‚å¡ç‰‡

---

## ğŸ¯ æ ¸å¿ƒå˜åŒ–æ€»ç»“

### å˜åŒ–å¯¹æ¯”è¡¨

| ç»´åº¦ | åŸæ–¹æ¡ˆ | MVPæ–¹æ¡ˆ | å˜åŒ–åŸå›  |
|------|--------|---------|----------|
| **æ¶æ„æ¨¡å—** | 10+æ¨¡å— | 4ä¸ªæ ¸å¿ƒæ¨¡å— | é™ä½ç»´æŠ¤å¤æ‚åº¦ |
| **æ•°æ®è¡¨å­—æ®µ** | demands 17å­—æ®µ | demands 9å­—æ®µ | å»é™¤æœªä½¿ç”¨çš„å•†ä¸šåŒ–å­—æ®µ |
| **UIæ–¹æ¡ˆ** | Webç•Œé¢ | å¯¼å‡º+æ‰‹å·¥+å›å†™ | å¿«é€ŸéªŒè¯ï¼Œé¿å…å‰ç«¯å¼€å‘ |
| **å¼€å‘å‘¨æœŸ** | 3-4å‘¨ | 2å‘¨ | èšç„¦æ ¸å¿ƒæµç¨‹ |
| **PhaseèŒƒå›´** | Phase 1-6 | Phase 1-4 + ç®€åŒ–5/7 | ä¼˜å…ˆçº§é‡æ’ |

---

## ğŸ“¦ ä¸€ã€ç®€åŒ–åçš„æ¶æ„

### 1.1 ç›®å½•ç»“æ„ï¼ˆä»10+æ¨¡å—ç¼©å‡åˆ°4ä¸ªæ ¸å¿ƒï¼‰

```
è¯æ ¹èšç±»éœ€æ±‚æŒ–æ˜/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py              # ç»Ÿä¸€é…ç½®ï¼ˆæ•°æ®åº“ã€èšç±»ã€LLMï¼‰
â”‚
â”œâ”€â”€ core/                         # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_integration.py       # æ•°æ®æ•´åˆæ¸…æ´—
â”‚   â”œâ”€â”€ clustering.py             # å¤§ç»„+å°ç»„èšç±»å¼•æ“
â”‚   â”œâ”€â”€ embedding.py              # EmbeddingæœåŠ¡ï¼ˆå¸¦ç¼“å­˜ï¼‰
â”‚   â””â”€â”€ incremental.py            # å¢é‡æ›´æ–°é€»è¾‘
â”‚
â”œâ”€â”€ storage/                      # æ•°æ®åº“è®¿é—®å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                 # SQLAlchemyæ¨¡å‹ï¼ˆPhrase, Demand, Token, ClusterMetaï¼‰
â”‚   â””â”€â”€ repository.py             # æ•°æ®åº“CRUDå°è£…
â”‚
â”œâ”€â”€ ai/                           # LLMé›†æˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ client.py                 # LLM APIè°ƒç”¨å°è£…
â”‚   â””â”€â”€ prompts.py                # Promptæ¨¡æ¿
â”‚
â”œâ”€â”€ scripts/                      # å…¥å£è„šæœ¬
â”‚   â”œâ”€â”€ run_phase1_import.py      # è¿è¡Œé˜¶æ®µ1ï¼šæ•°æ®å¯¼å…¥
â”‚   â”œâ”€â”€ run_phase2_clustering.py  # è¿è¡Œé˜¶æ®µ2ï¼šå¤§ç»„èšç±»
â”‚   â”œâ”€â”€ run_phase3_selection.py   # è¿è¡Œé˜¶æ®µ3ï¼šå¯¼å‡ºå¤§ç»„æŠ¥å‘Š
â”‚   â”œâ”€â”€ run_phase4_demands.py     # è¿è¡Œé˜¶æ®µ4ï¼šå°ç»„+éœ€æ±‚å¡ç‰‡
â”‚   â”œâ”€â”€ import_selection.py       # å¯¼å…¥äººå·¥é€‰æ‹©ç»“æœ
â”‚   â””â”€â”€ run_incremental.py        # å¢é‡æ›´æ–°
â”‚
â”œâ”€â”€ utils/                        # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ helpers.py                # æ–‡æœ¬å¤„ç†ã€å¯¼å‡ºç­‰
â”‚
â”œâ”€â”€ data/                         # æ•°æ®ç›®å½•ï¼ˆ.gitignoreæ’é™¤ï¼‰
â”œâ”€â”€ docs/                         # æ–‡æ¡£
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

**å¯¹æ¯”åŸæ–¹æ¡ˆ**ï¼š
- âŒ åˆ é™¤ï¼šservices/ï¼ˆè¿‡åº¦å°è£…ï¼‰
- âŒ åˆ é™¤ï¼špipelines/ï¼ˆç”¨scripts/æ›¿ä»£ï¼‰
- âŒ åˆ é™¤ï¼šui/ï¼ˆWebç•Œé¢æš‚ä¸å®ç°ï¼‰
- âŒ åˆ é™¤ï¼štests/ï¼ˆMVPå…ˆè·‘é€šå†è¡¥æµ‹è¯•ï¼‰
- âŒ åˆ é™¤ï¼šmigrations/ï¼ˆç›´æ¥åˆ›å»ºè¡¨ï¼Œä¸éœ€è¦è¿ç§»ï¼‰

---

## ğŸ—„ï¸ äºŒã€MVPç‰ˆæ•°æ®è¡¨è®¾è®¡

### 2.1 phrasesè¡¨ï¼ˆçŸ­è¯­æ€»åº“ï¼‰

**ä¿ç•™å­—æ®µ**ï¼ˆä»17ä¸ªç¼©å‡åˆ°13ä¸ªï¼‰ï¼š

```sql
CREATE TABLE phrases (
    phrase_id BIGINT PRIMARY KEY AUTO_INCREMENT,
    phrase VARCHAR(255) UNIQUE NOT NULL,

    -- æ¥æºä¿¡æ¯
    seed_word VARCHAR(100),
    source_type ENUM('semrush', 'dropdown', 'related_search'),
    first_seen_round INT NOT NULL,

    -- ç»Ÿè®¡æ•°æ®
    frequency BIGINT DEFAULT 1,
    volume BIGINT DEFAULT 0,

    -- èšç±»åˆ†é…
    cluster_id_A INT,
    cluster_id_B INT,

    -- éœ€æ±‚å…³è”
    mapped_demand_id INT,

    -- å¤„ç†çŠ¶æ€
    processed_status ENUM('unseen', 'reviewed', 'assigned', 'archived') DEFAULT 'unseen',

    -- å…ƒæ•°æ®
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    INDEX idx_cluster_A (cluster_id_A),
    INDEX idx_status (processed_status),
    INDEX idx_round (first_seen_round)
);
```

**åˆ é™¤å­—æ®µ**ï¼ˆæš‚ä¸å®ç°ï¼‰ï¼š
- âŒ cpc, keyword_difficultyï¼ˆå•†ä¸šåŒ–æŒ‡æ ‡ï¼‰
- âŒ word_count, phrase_length, query_typeï¼ˆç‰¹å¾å·¥ç¨‹æš‚ä¸ç”¨ï¼‰
- âŒ has_question_wordï¼ˆç‰¹å¾å·¥ç¨‹æš‚ä¸ç”¨ï¼‰

---

### 2.2 demandsè¡¨ï¼ˆéœ€æ±‚å¡ç‰‡åº“ï¼‰

**MVPç‰ˆå­—æ®µ**ï¼ˆä»17ä¸ªç¼©å‡åˆ°9ä¸ªæ ¸å¿ƒå­—æ®µï¼‰ï¼š

```sql
CREATE TABLE demands (
    demand_id INT PRIMARY KEY AUTO_INCREMENT,

    -- éœ€æ±‚æè¿°ï¼ˆæ ¸å¿ƒï¼‰
    title VARCHAR(255) NOT NULL,
    description TEXT,
    user_scenario TEXT,

    -- åˆ†ç±»
    demand_type ENUM('tool', 'content', 'service', 'education', 'other'),

    -- å…³è”ä¿¡æ¯
    source_cluster_A INT,
    source_cluster_B INT,
    related_phrases_count INT DEFAULT 0,

    -- å•†ä¸šè¯„ä¼°ï¼ˆç®€åŒ–ï¼‰
    business_value ENUM('high', 'medium', 'low', 'unknown') DEFAULT 'unknown',

    -- çŠ¶æ€è¿½è¸ª
    status ENUM('idea', 'validated', 'in_progress', 'archived') DEFAULT 'idea',

    -- å…ƒæ•°æ®
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    INDEX idx_status (status),
    INDEX idx_type (demand_type),
    INDEX idx_cluster_A (source_cluster_A)
);
```

**åˆ é™¤å­—æ®µ**ï¼ˆPhase 6å†åŠ ï¼‰ï¼š
- âŒ monetization_potentialï¼ˆæš‚æ— æ³•è¯„ä¼°ï¼‰
- âŒ competition_levelï¼ˆæš‚æ— æ³•è¯„ä¼°ï¼‰
- âŒ revenue, landing_url, product_idï¼ˆè¿˜æ²¡äº§å“ï¼‰
- âŒ tags, main_tokensï¼ˆJSONå­—æ®µæš‚ä¸ç”¨ï¼‰
- âŒ priorityï¼ˆç®€åŒ–ä¸ºbusiness_valueï¼‰

---

### 2.3 tokensè¡¨ï¼ˆéœ€æ±‚æ¡†æ¶è¯åº“ï¼‰

**MVPç‰ˆå­—æ®µ**ï¼ˆä»13ä¸ªç¼©å‡åˆ°7ä¸ªï¼‰ï¼š

```sql
CREATE TABLE tokens (
    token_id INT PRIMARY KEY AUTO_INCREMENT,
    token_text VARCHAR(100) UNIQUE NOT NULL,

    -- åˆ†ç±»ï¼ˆæ ¸å¿ƒï¼‰
    token_type ENUM('intent', 'action', 'object', 'attribute', 'condition', 'other') NOT NULL,

    -- ç»Ÿè®¡ä¿¡æ¯
    in_phrase_count INT DEFAULT 0,

    -- æ¥æºè¿½è¸ª
    first_seen_round INT NOT NULL,

    -- éªŒè¯çŠ¶æ€
    verified BOOLEAN DEFAULT FALSE,
    notes TEXT,

    -- å…ƒæ•°æ®
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_type (token_type),
    INDEX idx_frequency (in_phrase_count DESC)
);
```

**åˆ é™¤å­—æ®µ**ï¼ˆPhase 5å®Œæ•´ç‰ˆå†åŠ ï¼‰ï¼š
- âŒ sub_categoryï¼ˆæš‚ä¸ç»†åˆ†ï¼‰
- âŒ in_demand_count, total_frequencyï¼ˆPhase 5å†ç»Ÿè®¡ï¼‰
- âŒ synonyms, related_tokensï¼ˆJSONå…³è”æš‚ä¸åšï¼‰
- âŒ commercial_value, avg_cpc, avg_competitionï¼ˆå•†ä¸šåŒ–æŒ‡æ ‡æš‚ä¸ç”¨ï¼‰

---

### 2.4 cluster_metaè¡¨ï¼ˆèšç±»å…ƒæ•°æ®ï¼‰

**MVPç‰ˆå­—æ®µ**ï¼ˆç®€åŒ–ä¸º10ä¸ªæ ¸å¿ƒå­—æ®µï¼‰ï¼š

```sql
CREATE TABLE cluster_meta (
    cluster_id INT PRIMARY KEY,
    cluster_level ENUM('A', 'B') NOT NULL,
    parent_cluster_id INT,

    -- ç»Ÿè®¡ä¿¡æ¯
    size INT,
    total_frequency BIGINT,

    -- ä»£è¡¨ä¿¡æ¯
    example_phrases TEXT,
    main_theme VARCHAR(255),

    -- é€‰æ‹©çŠ¶æ€ï¼ˆå…³é”®ï¼ï¼‰
    is_selected BOOLEAN DEFAULT FALSE,
    selection_score INT,

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_level (cluster_level),
    INDEX idx_selected (is_selected)
);
```

**åˆ é™¤å­—æ®µ**ï¼š
- âŒ seed_words_in_clusterï¼ˆæš‚ä¸ç»Ÿè®¡ï¼‰
- âŒ cohesion_score, noise_ratioï¼ˆè´¨é‡æŒ‡æ ‡Phase 2å®Œæ•´ç‰ˆå†åŠ ï¼‰
- âŒ selection_reasonï¼ˆå…ˆç”¨selection_scoreæ•°å­—å³å¯ï¼‰

---

## ğŸ”„ ä¸‰ã€MVPç‰ˆå·¥ä½œæµç¨‹

### 3.1 Phase 1ï¼šæ•°æ®å¯¼å…¥ï¼ˆ1å¤©ï¼‰

**è„šæœ¬**: `scripts/run_phase1_import.py`

```python
# ä¼ªä»£ç ç¤ºä¾‹
from core.data_integration import DataIntegrator
from storage.repository import PhraseRepository

def main():
    # 1. è¯»å–ä¸‰ç§æ•°æ®æº
    integrator = DataIntegrator()
    semrush_data = integrator.load_semrush("åŸå§‹è¯/små¯¼å‡ºè¯")
    dropdown_data = integrator.load_dropdown("åŸå§‹è¯/ä¸‹æ‹‰è¯")
    related_data = integrator.load_related("åŸå§‹è¯/ç›¸å…³æœç´¢.xlsx")

    # 2. åˆå¹¶ã€æ¸…æ´—ã€å»é‡
    merged = integrator.merge_all([semrush_data, dropdown_data, related_data])
    cleaned = integrator.clean(merged)

    # 3. å†™å…¥æ•°æ®åº“
    repo = PhraseRepository()
    repo.bulk_insert(cleaned, first_seen_round=1)

    print(f"âœ“ å¯¼å…¥å®Œæˆï¼š{len(cleaned)} æ¡çŸ­è¯­")
```

**è¾“å‡º**ï¼š
- æ•°æ®åº“ phrases è¡¨å¡«å……å®Œæ¯•
- æ—¥å¿—ï¼šdata/logs/phase1_import.log

---

### 3.2 Phase 2ï¼šå¤§ç»„èšç±»ï¼ˆ1å¤©ï¼‰

**è„šæœ¬**: `scripts/run_phase2_clustering.py`

```python
from core.clustering import ClusteringEngine
from core.embedding import EmbeddingService
from storage.repository import PhraseRepository, ClusterMetaRepository

def main():
    # 1. ä»æ•°æ®åº“è¯»å–æ‰€æœ‰çŸ­è¯­
    repo = PhraseRepository()
    phrases = repo.get_all()

    # 2. èšç±»å¼•æ“
    embedding_service = EmbeddingService(model='all-MiniLM-L6-v2')
    clustering = ClusteringEngine(embedding_service)

    # 3. å¤§ç»„èšç±»
    labels, cluster_meta = clustering.fit_large_clusters(
        phrases,
        min_cluster_size=30,
        min_samples=3
    )

    # 4. æ›´æ–°æ•°æ®åº“
    repo.update_cluster_A(phrases, labels)
    ClusterMetaRepository().save_batch(cluster_meta)

    print(f"âœ“ å¤§ç»„èšç±»å®Œæˆï¼š{len(set(labels))} ä¸ªå¤§ç»„")
```

**è¾“å‡º**ï¼š
- phrases.cluster_id_A æ›´æ–°
- cluster_meta è¡¨å¡«å……ï¼ˆcluster_level='A'ï¼‰
- ç¼“å­˜ï¼šdata/cache/embeddings_round1.npz

---

### 3.3 Phase 3ï¼šå¤§ç»„ç­›é€‰ï¼ˆåŠå¤© + äººå·¥æ—¶é—´ï¼‰

**æ­¥éª¤Aï¼šè„šæœ¬ç”ŸæˆæŠ¥å‘Š**

`scripts/run_phase3_selection.py`

```python
from ai.client import LLMClient
from storage.repository import ClusterMetaRepository
import pandas as pd

def main():
    # 1. è¯»å–å¤§ç»„å…ƒæ•°æ®
    clusters = ClusterMetaRepository().get_all_level_A()

    # 2. AIç”Ÿæˆä¸»é¢˜æ ‡ç­¾
    llm = LLMClient(provider='openai')
    for cluster in clusters:
        theme = llm.generate_cluster_theme(
            example_phrases=cluster.example_phrases.split('; '),
            cluster_size=cluster.size
        )
        cluster.main_theme = theme['theme']

    # 3. ç”ŸæˆHTMLæŠ¥å‘Š
    df = pd.DataFrame([{
        'cluster_id': c.cluster_id,
        'size': c.size,
        'total_frequency': c.total_frequency,
        'main_theme': c.main_theme,
        'example_phrases': c.example_phrases,
        'selection_score': '',  # ç©ºç™½ï¼Œä¾›äººå·¥å¡«å†™
    } for c in clusters])

    df.to_html('data/output/cluster_selection_report.html', index=False)
    df.to_csv('data/output/cluster_selection_report.csv', index=False)

    print("âœ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œè¯·åœ¨CSVä¸­å¡«å†™ selection_score (1-5)")
    print("  é€‰ä¸­çš„å¤§ç»„æ‰“åˆ† 4-5ï¼Œå…¶ä»–æ‰“åˆ† 1-3")
```

**æ­¥éª¤Bï¼šäººå·¥æ“ä½œ**

1. æ‰“å¼€ `data/output/cluster_selection_report.html`ï¼ˆæµè§ˆå™¨ç¿»è¯‘ï¼‰
2. åœ¨ `cluster_selection_report.csv` ä¸­ï¼š
   - é˜…è¯» main_theme å’Œ example_phrases
   - åœ¨ selection_score åˆ—å¡«å†™ 1-5 åˆ†
   - 4-5åˆ† = é€‰ä¸­ï¼Œ1-3åˆ† = ä¸é€‰ä¸­
3. ä¿å­˜CSV

**æ­¥éª¤Cï¼šå¯¼å…¥é€‰æ‹©ç»“æœ**

`scripts/import_selection.py`

```python
import pandas as pd
from storage.repository import ClusterMetaRepository

def main():
    # è¯»å–äººå·¥æ‰“åˆ†
    df = pd.read_csv('data/output/cluster_selection_report.csv')

    # æ›´æ–°æ•°æ®åº“
    repo = ClusterMetaRepository()
    for _, row in df.iterrows():
        repo.update(
            cluster_id=row['cluster_id'],
            selection_score=row['selection_score'],
            is_selected=(row['selection_score'] >= 4)
        )

    selected_count = len(df[df['selection_score'] >= 4])
    print(f"âœ“ é€‰ä¸­ {selected_count} ä¸ªå¤§ç»„")
```

---

### 3.4 Phase 4ï¼šå°ç»„èšç±» + éœ€æ±‚å¡ç‰‡ï¼ˆ2-3å¤©ï¼‰

**æ­¥éª¤Aï¼šå°ç»„èšç±» + AIç”Ÿæˆéœ€æ±‚åˆç¨¿**

`scripts/run_phase4_demands.py`

```python
from core.clustering import ClusteringEngine
from ai.client import LLMClient
from storage.repository import (
    ClusterMetaRepository, PhraseRepository, DemandRepository
)

def main():
    # 1. è¯»å–é€‰ä¸­çš„å¤§ç»„
    selected_clusters = ClusterMetaRepository().get_selected()

    clustering = ClusteringEngine()
    llm = LLMClient()
    demands = []

    # 2. å¯¹æ¯ä¸ªé€‰ä¸­çš„å¤§ç»„
    for cluster_A in selected_clusters:
        # 2.1 è·å–è¯¥å¤§ç»„çš„çŸ­è¯­
        phrases = PhraseRepository().get_by_cluster_A(cluster_A.cluster_id)

        # 2.2 å°ç»„èšç±»
        labels_B = clustering.fit_small_clusters(
            phrases,
            parent_cluster_id=cluster_A.cluster_id
        )
        PhraseRepository().update_cluster_B(phrases, labels_B)

        # 2.3 ä¸ºæ¯ä¸ªå°ç»„ç”Ÿæˆéœ€æ±‚å¡ç‰‡åˆç¨¿
        for cluster_B_id in set(labels_B):
            if cluster_B_id == -1:  # è·³è¿‡å™ªéŸ³
                continue

            phrases_in_B = [p for p, label in zip(phrases, labels_B) if label == cluster_B_id]

            # AIç”Ÿæˆéœ€æ±‚å¡ç‰‡
            demand_draft = llm.generate_demand_card(
                phrases=[p.phrase for p in phrases_in_B],
                cluster_theme=cluster_A.main_theme
            )

            # ä¿å­˜åˆ°æ•°æ®åº“
            demand = DemandRepository().create(
                title=demand_draft['title'],
                description=demand_draft['description'],
                user_scenario=demand_draft.get('user_scenario', ''),
                demand_type=demand_draft.get('demand_type', 'other'),
                source_cluster_A=cluster_A.cluster_id,
                source_cluster_B=cluster_B_id,
                status='idea'
            )
            demands.append(demand)

    # 3. å¯¼å‡ºéœ€æ±‚å¡ç‰‡ä¾›å®¡æ ¸
    df = pd.DataFrame([{
        'demand_id': d.demand_id,
        'title': d.title,
        'description': d.description,
        'user_scenario': d.user_scenario,
        'demand_type': d.demand_type,
        'related_phrases_count': d.related_phrases_count,
        'business_value': '',  # ä¾›äººå·¥å¡«å†™
        'status': 'idea',      # ä¾›äººå·¥ä¿®æ”¹
    } for d in demands])

    df.to_csv('data/output/demands_draft.csv', index=False)
    print(f"âœ“ ç”Ÿæˆ {len(demands)} ä¸ªéœ€æ±‚å¡ç‰‡åˆç¨¿")
    print("  è¯·åœ¨ demands_draft.csv ä¸­å®¡æ ¸å¹¶ä¿®æ”¹")
```

**æ­¥éª¤Bï¼šäººå·¥å®¡æ ¸**

1. æ‰“å¼€ `data/output/demands_draft.csv`
2. å¯¹æ¯ä¸ªéœ€æ±‚ï¼š
   - é˜…è¯» title, description, user_scenario
   - ä¿®æ”¹ä¸å‡†ç¡®çš„æè¿°
   - å¡«å†™ business_value (high/medium/low)
   - ä¿®æ”¹ statusï¼š
     - `validated` = ç¡®è®¤æœ‰æ•ˆ
     - `archived` = åˆ é™¤/æ— æ•ˆ
3. ä¿å­˜CSV

**æ­¥éª¤Cï¼šå¯¼å…¥å®¡æ ¸ç»“æœ**

```python
# åœ¨ run_phase4_demands.py æœ«å°¾æ·»åŠ 
def import_reviewed_demands():
    df = pd.read_csv('data/output/demands_draft.csv')
    repo = DemandRepository()

    for _, row in df.iterrows():
        repo.update(
            demand_id=row['demand_id'],
            title=row['title'],
            description=row['description'],
            business_value=row['business_value'],
            status=row['status']
        )

        # æ›´æ–°phrasesçš„mapped_demand_id
        if row['status'] == 'validated':
            phrases = PhraseRepository().get_by_cluster_B(row['source_cluster_B'])
            PhraseRepository().map_to_demand(phrases, row['demand_id'])

    print("âœ“ éœ€æ±‚å¡ç‰‡å®¡æ ¸å®Œæˆ")
```

---

### 3.5 Phase 5ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼štokensæå–ï¼ˆ1å¤©ï¼‰

**ä»…æå–æ ¸å¿ƒtokensï¼Œä¸åšå¤æ‚åˆ†ç±»**

```python
from utils.helpers import extract_tokens
from ai.client import LLMClient
from storage.repository import TokenRepository

def main():
    # 1. è·å–å·²éªŒè¯éœ€æ±‚çš„çŸ­è¯­
    phrases = PhraseRepository().get_mapped_to_demands()

    # 2. ç²—æ‹†è¯
    candidate_tokens = extract_tokens([p.phrase for p in phrases])

    # 3. AIæ‰¹é‡åˆ†ç±»ï¼ˆç®€åŒ–ç‰ˆï¼šåªåˆ†intent/action/object/otherï¼‰
    llm = LLMClient()
    classifications = llm.batch_classify_tokens(
        tokens=[t['text'] for t in candidate_tokens],
        batch_size=50
    )

    # 4. ä¿å­˜
    repo = TokenRepository()
    for candidate, classification in zip(candidate_tokens, classifications):
        repo.create(
            token_text=candidate['text'],
            token_type=classification['token_type'],
            in_phrase_count=candidate['frequency'],
            first_seen_round=1,
            verified=False
        )

    print(f"âœ“ æå– {len(candidate_tokens)} ä¸ªtokens")
```

---

### 3.6 Phase 7ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼šå¢é‡æ›´æ–°ï¼ˆ1å¤©ï¼‰

**åªå®ç°æ ¸å¿ƒï¼šå¯¼å…¥+å»é‡+åˆ†é…å¤§ç»„+æ ‡è®°çŠ¶æ€**

```python
from core.incremental import IncrementalUpdater

def main():
    updater = IncrementalUpdater(round_id=2)

    # 1. å¯¼å…¥æ–°æ•°æ®
    new_phrases, updated_phrases = updater.import_new_data([
        "åŸå§‹è¯/ç¬¬äºŒè½®/små¯¼å‡ºè¯",
        "åŸå§‹è¯/ç¬¬äºŒè½®/ä¸‹æ‹‰è¯"
    ])

    # 2. åˆ†é…åˆ°å¤§ç»„
    updater.assign_to_large_clusters(new_phrases)

    # 3. è¿‡æ»¤ï¼šåªå¤„ç†æœªå¤„ç†çš„æ–°çŸ­è¯­
    actionable = updater.filter_actionable(new_phrases)

    print(f"âœ“ æ–°å¢ {len(new_phrases)} æ¡çŸ­è¯­")
    print(f"  å¾…å¤„ç†: {len(actionable)} æ¡")
    print("  åç»­å¯è¿è¡Œ Phase 4 å¯¹è¿™äº›æ–°çŸ­è¯­ç”Ÿæˆéœ€æ±‚")
```

**å°ç»„é‡èšç±»**æš‚ä¸è‡ªåŠ¨åšï¼Œç­‰éœ€è¦æ—¶æ‰‹åŠ¨è¿è¡ŒPhase 4è„šæœ¬

---

## â±ï¸ å››ã€MVPå¼€å‘æ—¶é—´è¡¨

### 4.1 ç¬¬ä¸€å‘¨

| å¤©æ•° | ä»»åŠ¡ | äº§å‡º |
|------|------|------|
| Day 1 | æ­å»ºæ¶æ„ã€åˆ›å»ºæ•°æ®åº“è¡¨ | ç›®å½•ç»“æ„ã€models.py |
| Day 2 | Phase 1 å®ç° | æ•°æ®å¯¼å…¥è„šæœ¬ã€phrasesè¡¨æœ‰æ•°æ® |
| Day 3 | Phase 2 å®ç° | å¤§ç»„èšç±»è„šæœ¬ã€cluster_metaæœ‰æ•°æ® |
| Day 4 | Phase 3 å®ç° | å¤§ç»„æŠ¥å‘Šç”Ÿæˆã€AIä¸»é¢˜æ ‡ç­¾ |
| Day 5 | äººå·¥ç­›é€‰å¤§ç»„ | é€‰å‡º10-15ä¸ªç›®æ ‡å¤§ç»„ |

### 4.2 ç¬¬äºŒå‘¨

| å¤©æ•° | ä»»åŠ¡ | äº§å‡º |
|------|------|------|
| Day 6-7 | Phase 4 å®ç°ï¼ˆå°ç»„+éœ€æ±‚ï¼‰ | éœ€æ±‚å¡ç‰‡åˆç¨¿ |
| Day 8 | äººå·¥å®¡æ ¸éœ€æ±‚å¡ç‰‡ | ç¡®è®¤10-20ä¸ªæœ‰æ•ˆéœ€æ±‚ |
| Day 9 | Phase 5 ç®€åŒ–å®ç°ï¼ˆå¯é€‰ï¼‰ | tokensåŸºç¡€è¯åº“ |
| Day 10 | Phase 7 ç®€åŒ–å®ç° + æµ‹è¯• | å¢é‡æ›´æ–°è„šæœ¬ |

**æ€»è®¡**: 10ä¸ªå·¥ä½œæ—¥ï¼ˆ2å‘¨ï¼‰

---

## ğŸ” äº”ã€å…³é”®å®ç°ç»†èŠ‚ï¼ˆå¿…é¡»éµå®ˆï¼‰

### 5.1 ä¸¥ç¦ç‰©ç†åˆ é™¤å¤§ç»„

```python
# âŒ ç¦æ­¢è¿™æ ·åš
def delete_cluster(cluster_id):
    db.execute("DELETE FROM cluster_meta WHERE cluster_id = ?", cluster_id)
    db.execute("UPDATE phrases SET cluster_id_A = NULL WHERE cluster_id_A = ?", cluster_id)

# âœ… æ­£ç¡®åšæ³•ï¼šåªæ”¹æ ‡è®°
def unselect_cluster(cluster_id):
    ClusterMetaRepository().update(
        cluster_id=cluster_id,
        is_selected=False,
        selection_score=0
    )
```

### 5.2 å¢é‡è¿‡æ»¤è§„åˆ™ï¼ˆå†™æ­»ä¸å˜ï¼‰

```python
def filter_actionable_phrases(phrases):
    """åªå¤„ç†çœŸæ­£éœ€è¦å¤„ç†çš„æ–°çŸ­è¯­"""
    actionable = []

    for phrase in phrases:
        # è§„åˆ™1: å¿…é¡»æ˜¯æœªå¤„ç†çš„
        if phrase.processed_status != 'unseen':
            continue

        # è§„åˆ™2: å¦‚æœå·²å…³è”éœ€æ±‚ï¼Œæ£€æŸ¥éœ€æ±‚çŠ¶æ€
        if phrase.mapped_demand_id:
            demand = DemandRepository().get(phrase.mapped_demand_id)
            # å¦‚æœéœ€æ±‚å·²ç¨³å®šï¼Œä¸å†å¤„ç†
            if demand.status in ['validated', 'in_progress']:
                phrase.processed_status = 'archived'
                PhraseRepository().update(phrase)
                continue

        # è§„åˆ™3: å™ªéŸ³ç‚¹ä¸”é¢‘æ¬¡å¾ˆä½ï¼Œç›´æ¥å½’æ¡£
        if phrase.cluster_id_A == -1 and phrase.frequency < 10:
            phrase.processed_status = 'archived'
            PhraseRepository().update(phrase)
            continue

        actionable.append(phrase)

    return actionable
```

### 5.3 Embeddingæ¨¡å‹ç‰ˆæœ¬å›ºå®š

```python
# config/settings.py
EMBEDDING_MODEL = 'all-MiniLM-L6-v2'
EMBEDDING_MODEL_VERSION = '2.2.0'  # è®°å½•ç‰ˆæœ¬

# core/embedding.py
class EmbeddingService:
    def __init__(self):
        self.model_name = EMBEDDING_MODEL
        self.model_version = EMBEDDING_MODEL_VERSION

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦åŒ¹é…ç‰ˆæœ¬
        if os.path.exists('data/cache/model_version.txt'):
            cached_version = open('data/cache/model_version.txt').read()
            if cached_version != self.model_version:
                raise ValueError(
                    f"Embeddingæ¨¡å‹ç‰ˆæœ¬ä¸åŒ¹é…ï¼\n"
                    f"ç¼“å­˜ç‰ˆæœ¬: {cached_version}\n"
                    f"å½“å‰ç‰ˆæœ¬: {self.model_version}\n"
                    f"è¯·åˆ é™¤ç¼“å­˜æˆ–é‡æ–°ç”Ÿæˆembeddings"
                )
```

---

## ğŸ“Š å…­ã€MVPæˆåŠŸæ ‡å‡†

å®Œæˆä»¥ä¸‹æ ‡å‡†ï¼Œå³è®¤ä¸ºMVPæˆåŠŸï¼š

### 6.1 æ•°æ®éªŒè¯
- [x] phrases è¡¨æœ‰ 50,000+ æ¡æ•°æ®
- [x] cluster_meta è¡¨æœ‰ 60-100 ä¸ªå¤§ç»„
- [x] é€‰ä¸­ 10-15 ä¸ªç›®æ ‡å¤§ç»„
- [x] demands è¡¨æœ‰ 20-50 ä¸ªéœ€æ±‚å¡ç‰‡
- [x] è‡³å°‘10ä¸ªéœ€æ±‚ status='validated'

### 6.2 æµç¨‹éªŒè¯
- [x] Phase 1-4 å…¨éƒ¨è·‘é€š
- [x] äººå·¥ç­›é€‰æµç¨‹ï¼ˆå¯¼å‡ºâ†’æ‰‹å·¥â†’å¯¼å…¥ï¼‰å¯ç”¨
- [x] AIç”Ÿæˆçš„éœ€æ±‚å¡ç‰‡å‡†ç¡®ç‡ >60%
- [x] å¢é‡æ›´æ–°ä¸ä¼šé‡å¤å¤„ç†å·²æœ‰éœ€æ±‚

### 6.3 å¯ç”¨æ€§éªŒè¯
- [x] ä»5ä¸‡è¯äº§å‡º10-20ä¸ªå¯è½åœ°çš„éœ€æ±‚æƒ³æ³•
- [x] æ¯ä¸ªéœ€æ±‚ä¸‹æœ‰çœŸå®çš„æœç´¢çŸ­è¯­æ”¯æ’‘
- [x] èƒ½å¤Ÿå¿«é€Ÿå®šä½"å“ªäº›è¯å±äºåŒä¸€éœ€æ±‚"

---

## ğŸš€ ä¸ƒã€MVPä¹‹åçš„è¿­ä»£è·¯å¾„

å®ŒæˆMVPåï¼ŒæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§è¿­ä»£ï¼š

### ç¬¬äºŒè½®è¿­ä»£ï¼ˆ+2å‘¨ï¼‰
1. **Phase 5 å®Œæ•´ç‰ˆ**ï¼štokensè¯åº“å®Œå–„
2. **Phase 7 å®Œæ•´ç‰ˆ**ï¼šå¢é‡å°ç»„é‡èšç±»
3. **æ•°æ®è¡¨å­—æ®µæ‰©å±•**ï¼šæ·»åŠ  tags, main_tokens (JSON)

### ç¬¬ä¸‰è½®è¿­ä»£ï¼ˆ+2å‘¨ï¼‰
4. **Web UI**ï¼šClusterSelector, DemandEditor
5. **æ‰¹é‡æ“ä½œåŠŸèƒ½**ï¼šåˆå¹¶éœ€æ±‚ã€æ‰¹é‡æ ‡è®°
6. **å¯¼å‡ºå·¥å…·**ï¼šSEOè¯è¡¨ã€Landing Pageç´ æ

### ç¬¬å››è½®è¿­ä»£ï¼ˆæœ‰äº§å“åï¼‰
7. **Phase 6**ï¼šå•†ä¸šåŒ–å­—æ®µï¼ˆrevenue, landing_urlï¼‰
8. **æ•°æ®å¯è§†åŒ–**ï¼šéœ€æ±‚åœ°å›¾ã€è¯äº‘ã€è¶‹åŠ¿å›¾
9. **è‡ªåŠ¨åŒ–Pipeline**ï¼šå®šæœŸæ‰«ææ–°è¯ã€è‡ªåŠ¨æ¨é€æŠ¥å‘Š

---

## ğŸ“ å…«ã€æ€»ç»“

### ä¸åŸæ–¹æ¡ˆå¯¹æ¯”

| ç»´åº¦ | åŸæ–¹æ¡ˆ | MVPæ–¹æ¡ˆ | æ”¶ç›Š |
|------|--------|---------|------|
| å¼€å‘å‘¨æœŸ | 3-4å‘¨ | 2å‘¨ | â±ï¸ èŠ‚çœ50%æ—¶é—´ |
| æ¶æ„æ¨¡å— | 10+æ¨¡å— | 4ä¸ªæ ¸å¿ƒæ¨¡å— | ğŸ§© é™ä½70%å¤æ‚åº¦ |
| ä»£ç é‡ | ~5000è¡Œ | ~2000è¡Œ | ğŸ“‰ å‡å°‘60%ä»£ç  |
| æ•°æ®è¡¨å­—æ®µ | 47ä¸ªå­—æ®µ | 29ä¸ªå­—æ®µ | ğŸ—„ï¸ å‡å°‘40%å­—æ®µ |
| UIå·¥ä½œé‡ | Webç•Œé¢ | å¯¼å‡º+æ‰‹å·¥ | ğŸ¨ çœå»å‰ç«¯å¼€å‘ |
| é¦–æ¬¡äº§å‡º | Phase 1-6 | Phase 1-4 | ğŸ¯ æ›´å¿«éªŒè¯ä»·å€¼ |

### æ ¸å¿ƒä¿ç•™

âœ… **æµç¨‹é€»è¾‘**ï¼š0-7é˜¶æ®µå®Œå…¨ä¿ç•™
âœ… **ä¸‰å¼ è¡¨**ï¼šphrases/demands/tokensæ¶æ„ä¿ç•™
âœ… **å…³é”®ç­–ç•¥**ï¼š
  - å¤§ç»„ä¸åˆ é™¤ï¼Œç”¨is_selectedæ ‡è®°
  - å¢é‡è¿‡æ»¤é¿å…é‡å¤å¤„ç†
  - Embeddingæ¨¡å‹ç‰ˆæœ¬å›ºå®š

### æ ¸å¿ƒç®€åŒ–

âœ… **æ¶æ„**ï¼šä»10+æ¨¡å—å‡å°‘åˆ°4ä¸ªæ ¸å¿ƒæ¨¡å—
âœ… **å­—æ®µ**ï¼šåˆ é™¤40%æš‚ä¸ä½¿ç”¨çš„å­—æ®µ
âœ… **UI**ï¼šç”¨å¯¼å‡º+æ‰‹å·¥æ›¿ä»£Webç•Œé¢
âœ… **ä¼˜å…ˆçº§**ï¼šPhase 1-4 å¿…åšï¼Œ5/7 ç®€åŒ–ï¼Œ6 å»¶å

---

**æœ€åæ›´æ–°**: 2024-12-19
**ç‰ˆæœ¬**: MVP v1.0ï¼ˆåŸºäºGPTåé¦ˆè°ƒæ•´ï¼‰
**é¢„è®¡å®Œæˆ**: 2å‘¨å†…äº§å‡ºç¬¬ä¸€æ‰¹éœ€æ±‚å¡ç‰‡
