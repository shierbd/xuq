# Phase 2 实验结果分析报告

**日期**: 2026-02-02
**实验**: P7.1 双文本策略（数据驱动属性词发现）
**状态**: ⚠️ 效果不佳，需要调整策略

---

## 📊 实验结果总结

### 核心数据对比

| 指标 | Phase 1 基线 | Phase 2 结果 | 变化 | 目标 | 达成情况 |
|------|-------------|-------------|------|------|---------|
| **总簇数** | 1,392 | 1,349 | -43 (-3.1%) | 300-500 | ❌ 未达成 |
| **主要簇** (≥10) | 215 | 211 | -4 (-1.9%) | 60-80% | ❌ 15.6% |
| **次级簇** (5-9) | 458 | 461 | +3 (+0.7%) | - | - |
| **微型簇** (3-4) | 719 | 677 | -42 (-5.8%) | <100 | ❌ 50.2% |
| **噪音点** | 4,473 (28.3%) | 4,631 (29.3%) | +158 (+3.5%) | 30-40% | ✅ 可接受 |

### 属性词发现结果

**发现的5个属性词**：
1. **template** (分散度: 0.522) - 出现在52.2%的簇中
2. **digital** (分散度: 0.463) - 出现在46.3%的簇中
3. **download** (分散度: 0.408) - 出现在40.8%的簇中
4. **bundle** (分散度: 0.361) - 出现在36.1%的簇中
5. **canva** (分散度: 0.310) - 出现在31.0%的簇中

**未被识别但分散度较高的词**：
- templates (0.289) - 刚好低于阈值
- editable (0.249)
- pdf (0.213)
- business (0.148)
- planner (0.142)

---

## 🔍 问题诊断

### 1. 为什么改善效果这么小？(3.1%)

#### 原因分析：

**A. 属性词数量太少 (5个)**
- 只识别出5个属性词，覆盖面不够
- 阈值0.3可能太高，漏掉了很多重要属性词
- 例如：templates (0.289)、editable (0.249) 都是明显的属性词

**B. 属性词类型单一**
- 发现的5个词主要是"产品类型"和"交付方式"
- 缺少其他维度的属性词：
  - ❌ 颜色词：pink, blue, green, purple, etc.
  - ❌ 风格词：modern, vintage, minimalist, retro, etc.
  - ❌ 材质词：watercolor, hand-drawn, geometric, etc.
  - ❌ 格式词：pdf, psd, ai, svg, etc.

**C. 初始聚类质量问题**
- 初始聚类本身就有1,392个簇（太碎）
- 在碎片化的基础上发现属性词，效果有限
- 需要先改善初始聚类质量

### 2. 为什么微型簇还这么多？(677个)

#### 根本原因：

**Stage 2/3 的设计问题**（Phase 1 已识别）：
- Stage 2/3 会为噪音点创建新的小簇
- 这些小簇往往是"长尾商品"或"独特商品"
- 双文本策略无法解决这个结构性问题

**示例**：
```
Stage 1: "Pink Retro Shopify Theme" → 噪音点
Stage 2: 创建新簇 "Pink Retro Shopify Theme" (3个商品)
         ↓
即使去除 "template"，仍然是：
Stage 2: 创建新簇 "Pink Retro Shopify" (3个商品)
```

### 3. 为什么噪音点反而增加了？(+158)

#### 可能原因：

**去除属性词后，文本变得更短**：
- 原文本: "Pink Retro Shopify Theme Template"
- 新文本: "Pink Retro Shopify"
- 更短的文本 → 语义信息减少 → 更难聚类 → 更多噪音

**示例**：
```
原文本: "Canva Template 1" → 有足够信息聚类
新文本: "1" → 信息太少，变成噪音
```

---

## 💡 关键洞察

### 1. 双文本策略的局限性

**理论假设**：
- 去除属性词 → 按需求主题聚类 → 簇数量减少

**实际情况**：
- ✅ 属性词发现算法有效（识别出5个高分散度词）
- ❌ 但只去除5个词，对整体聚类影响很小
- ❌ 需要去除更多属性词才能看到明显效果

### 2. 阈值设置的权衡

**当前阈值: 0.3 (30%)**

**如果降低阈值 (例如 0.2)**：
- ✅ 会识别出更多属性词 (templates, editable, pdf, etc.)
- ✅ 可能带来更大的改善
- ⚠️ 但可能误伤一些重要的主题词

**如果提高阈值 (例如 0.4)**：
- ✅ 只保留最明确的属性词
- ❌ 但改善效果会更小

### 3. 真正的问题在哪里？

**Phase 1 的诊断是正确的**：

1. **预处理策略** (P7.1 双文本策略)
   - ✅ 方向正确
   - ⚠️ 但单独使用效果有限 (3.1%)
   - 💡 需要配合其他优化

2. **Stage 2/3 设计** (P7.3)
   - ❌ 这是更根本的问题
   - ❌ 制造了677个微型簇
   - 🔴 必须优先解决

---

## 🎯 下一步行动建议

### 方案A: 调整双文本策略参数 (快速测试)

**调整内容**：
1. 降低分散度阈值: 0.3 → 0.2
2. 增加关键词提取数量: top 20 → top 30
3. 添加词性过滤（只保留形容词和名词）

**预期效果**：
- 识别出15-20个属性词
- 簇数量减少: 1,349 → 1,000-1,200 (预计)
- 改善幅度: 3.1% → 10-15% (预计)

**优点**: 快速验证，成本低
**缺点**: 仍然无法达到目标 (300-500)

---

### 方案B: 实施 P7.3 Stage 2/3 重新设计 (推荐) 🔴

**核心思路**：
- Stage 1: 保持不变（生成主要簇）
- Stage 2: **归并到最近主题簇**（不再创建新簇）
- Stage 3: **质量门控**（只保留可命名簇）

**具体设计**：

#### Stage 2: 归并策略
```python
for noise_point in stage1_noise:
    # 找到最近的主题簇
    nearest_cluster = find_nearest_cluster(noise_point, stage1_clusters)

    # 计算相似度
    similarity = cosine_similarity(noise_point, nearest_cluster_centroid)

    if similarity > threshold:  # 例如 0.6
        # 归并到该簇
        assign_to_cluster(noise_point, nearest_cluster)
    else:
        # 保持为噪音
        keep_as_noise(noise_point)
```

#### Stage 3: 质量门控
```python
for cluster in all_clusters:
    # 检查簇质量
    if is_nameable(cluster):  # 簇内商品语义一致
        keep_cluster(cluster)
    else:
        # 将商品标记为噪音
        mark_as_noise(cluster.products)
```

**预期效果**：
- 消除677个微型簇
- 簇数量: 1,349 → 400-600 (预计)
- 改善幅度: 3.1% → 50-60% (预计)

**优点**: 解决根本问题，效果显著
**缺点**: 需要重新设计和实现

---

### 方案C: 组合策略 (最佳方案) ⭐

**第一步**: 调整双文本策略参数 (方案A)
- 降低阈值到 0.2
- 识别出更多属性词

**第二步**: 实施 Stage 2/3 重新设计 (方案B)
- 归并策略 + 质量门控
- 消除微型簇

**第三步**: 参数优化 (P7.4)
- 提高 stage1_min_size: 10 → 15
- 改用 eom 方法
- 关闭 epsilon

**预期效果**：
- 簇数量: 1,349 → 300-500 ✅
- 微型簇: 677 → <100 ✅
- 可命名簇比例: ~50% → >80% ✅

---

## 📋 具体实施计划

### 立即执行 (今天)

**实验 4: 调整双文本策略参数**
- [ ] 降低分散度阈值: 0.3 → 0.2
- [ ] 运行测试
- [ ] 分析结果
- [ ] 评估是否需要进一步调整

**预计时间**: 30分钟

---

### 短期计划 (本周)

**实验 5: 实施 Stage 2/3 重新设计**
- [ ] 设计归并算法
- [ ] 实现质量门控
- [ ] 运行测试
- [ ] 对比效果

**预计时间**: 2-3小时

---

### 中期计划 (下周)

**实验 6: 组合优化**
- [ ] 结合双文本策略 + Stage 2/3 重新设计
- [ ] 参数调优
- [ ] 最终验证

**预计时间**: 1-2小时

---

## 🎓 经验教训

### 1. 单一优化效果有限

**教训**:
- 双文本策略单独使用只带来3.1%的改善
- 需要组合多个优化策略才能达到目标

**启示**:
- 不要期待"银弹"解决方案
- 系统性问题需要系统性解决

### 2. 数据驱动方法有效

**成功点**:
- ✅ 属性词发现算法工作正常
- ✅ 识别出的5个词确实是高分散度词
- ✅ 数据驱动比预定义词表更灵活

**改进空间**:
- 需要调整阈值以识别更多属性词
- 可以考虑多维度属性词分类

### 3. 结构性问题需要结构性解决

**核心问题**:
- Stage 2/3 制造微型簇是结构性问题
- 预处理优化无法完全解决
- 必须重新设计 Stage 2/3

---

## 📊 附录：详细数据

### A. 初始聚类分布 (full_text)

```
主要簇 (>=10):  215 个 (15.4%)
次级簇 (5-9):   458 个 (32.9%)
微型簇 (3-4):   719 个 (51.6%)
噪音点:        4,473 个 (28.3%)
```

### B. 最终聚类分布 (topic_text)

```
主要簇 (>=10):  211 个 (15.6%)
次级簇 (5-9):   461 个 (34.2%)
微型簇 (3-4):   677 个 (50.2%)
噪音点:        4,631 个 (29.3%)
```

### C. 属性词分散度分析

| 词 | 分散度 | 是否识别 | 类型 |
|----|--------|---------|------|
| template | 0.522 | ✅ | 产品类型 |
| digital | 0.463 | ✅ | 交付方式 |
| download | 0.408 | ✅ | 交付方式 |
| bundle | 0.361 | ✅ | 产品类型 |
| canva | 0.310 | ✅ | 平台 |
| templates | 0.289 | ❌ | 产品类型 |
| editable | 0.249 | ❌ | 属性 |
| pdf | 0.213 | ❌ | 格式 |
| business | 0.148 | ❌ | 用途 |
| planner | 0.142 | ❌ | 产品类型 |

---

**创建者**: Claude Sonnet 4.5
**创建日期**: 2026-02-02
**实验耗时**: 约32分钟
**数据集**: 15,792个商品

---

**结论**: Phase 2 双文本策略方向正确，但单独使用效果有限 (3.1%)。建议立即实施 P7.3 (Stage 2/3 重新设计) 以解决根本问题。
