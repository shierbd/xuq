# Phase 1 ä½¿ç”¨æŒ‡å—

## ğŸ“Š æ•°æ®ç»“æœä½ç½®

### 1. æ•°æ®åº“ï¼ˆä¸»è¦å­˜å‚¨ï¼‰

**ä½ç½®**: MySQLæ•°æ®åº“
```
æ•°æ®åº“å: keyword_clustering
è¡¨å: phrases
è®°å½•æ•°: 55,275æ¡
```

**æŸ¥çœ‹æ•°æ®**:
```bash
# æŸ¥çœ‹æ€»æ•°
mysql -u root -p123456 -e "SELECT COUNT(*) FROM keyword_clustering.phrases;"

# æŸ¥çœ‹å‰10æ¡
mysql -u root -p123456 -e "SELECT phrase, frequency, volume, source_type FROM keyword_clustering.phrases LIMIT 10;"

# æŒ‰æ¥æºç»Ÿè®¡
mysql -u root -p123456 -e "SELECT source_type, COUNT(*) as count FROM keyword_clustering.phrases GROUP BY source_type;"
```

### 2. CSVæ–‡ä»¶ï¼ˆå¤‡ä»½/æŸ¥çœ‹ï¼‰

**ä½ç½®**: `data/processed/integrated_round1.csv`

**æŸ¥çœ‹æ–¹å¼**:
- Excelæ‰“å¼€: åŒå‡»æ–‡ä»¶
- å‘½ä»¤è¡ŒæŸ¥çœ‹: `type data\processed\integrated_round1.csv | more`
- ä½¿ç”¨pandas:
  ```python
  import pandas as pd
  df = pd.read_csv('data/processed/integrated_round1.csv')
  print(df.head(20))
  ```

## ğŸ“ è¿è¡Œä»£ç ä½ç½®

### Phase 1 å…¥å£è„šæœ¬
**æ–‡ä»¶**: `scripts/run_phase1_import.py`

## ğŸš€ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: æŸ¥çœ‹å·²å¯¼å…¥çš„æ•°æ®

è¿è¡ŒæŸ¥çœ‹è„šæœ¬:
```bash
python view_phase1_results.py
```

è¾“å‡ºåŒ…æ‹¬:
- æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
- æŒ‰æ•°æ®æºåˆ†å¸ƒ
- é«˜é¢‘çŸ­è¯­Top 20
- å„æ•°æ®æºæ ·æœ¬
- èšç±»çŠ¶æ€

### åœºæ™¯2: é‡æ–°å¯¼å…¥æ•°æ®ï¼ˆæ¸…ç©ºé‡æ¥ï¼‰

```bash
# 1. æ¸…ç©ºæ•°æ®åº“è¡¨
mysql -u root -p123456 -e "TRUNCATE TABLE keyword_clustering.phrases;"

# 2. é‡æ–°è¿è¡Œå¯¼å…¥
python scripts/run_phase1_import.py

# 3. éªŒè¯å¯¼å…¥
python view_phase1_results.py
```

### åœºæ™¯3: å¯¼å…¥æ–°ä¸€è½®æ•°æ®ï¼ˆå¢é‡æ›´æ–°ï¼‰

```bash
# 1. å°†æ–°æ•°æ®æ”¾åˆ° data/raw/ ç›®å½•

# 2. è¿è¡Œå¢é‡å¯¼å…¥ï¼ˆround_id=2ï¼‰
python scripts/run_phase1_import.py --round-id 2

# æ³¨æ„ï¼šç›¸åŒçŸ­è¯­ä¼šè¢«å¿½ç•¥ï¼ˆuniqueçº¦æŸï¼‰ï¼Œåªä¼šå¯¼å…¥æ–°çŸ­è¯­
```

### åœºæ™¯4: æµ‹è¯•å¯¼å…¥ï¼ˆä¸å†™å…¥æ•°æ®åº“ï¼‰

```bash
# ä½¿ç”¨dry-runæ¨¡å¼
python scripts/run_phase1_import.py --dry-run

# ä¼šæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ä½†ä¸æ’å…¥æ•°æ®åº“
```

### åœºæ™¯5: å¯¼å‡ºæ•°æ®åˆ°Excelåˆ†æ

**æ–¹æ³•1: ç›´æ¥ä½¿ç”¨CSVæ–‡ä»¶**
```bash
# æ–‡ä»¶å·²ç»å­˜åœ¨
start data\processed\integrated_round1.csv
```

**æ–¹æ³•2: ä»æ•°æ®åº“å¯¼å‡ºç‰¹å®šæ•°æ®**
```python
# export_phrases.py
import pandas as pd
from storage.repository import PhraseRepository
from storage.models import Phrase

with PhraseRepository() as repo:
    # å¯¼å‡ºSEMRUSHæ•°æ®ï¼ˆæœ‰æœç´¢é‡ï¼‰
    semrush = repo.session.query(Phrase).filter(
        Phrase.source_type == 'semrush'
    ).all()

    df = pd.DataFrame([{
        'phrase': p.phrase,
        'frequency': p.frequency,
        'volume': p.volume,
        'seed_word': p.seed_word,
    } for p in semrush])

    df.to_excel('data/output/semrush_phrases.xlsx', index=False)
    print(f"å·²å¯¼å‡º {len(df)} æ¡SEMRUSHæ•°æ®")
```

### åœºæ™¯6: æŸ¥è¯¢ç‰¹å®šçŸ­è¯­

```python
# query_phrase.py
from storage.repository import PhraseRepository

with PhraseRepository() as repo:
    # æŸ¥è¯¢å•ä¸ªçŸ­è¯­
    phrase = repo.get_phrase_by_text("how to change a tire")
    if phrase:
        print(f"çŸ­è¯­: {phrase.phrase}")
        print(f"é¢‘æ¬¡: {phrase.frequency}")
        print(f"æœç´¢é‡: {phrase.volume}")
        print(f"æ¥æº: {phrase.source_type}")
        print(f"èšç±»ID: {phrase.cluster_id_A}")
```

### åœºæ™¯7: æŒ‰ç§å­è¯æŸ¥è¯¢

```python
# query_by_seed.py
from storage.models import Phrase
from storage.repository import PhraseRepository

with PhraseRepository() as repo:
    # æŸ¥è¯¢ç‰¹å®šç§å­è¯çš„æ‰€æœ‰çŸ­è¯­
    phrases = repo.session.query(Phrase).filter(
        Phrase.seed_word == 'connector'
    ).order_by(Phrase.frequency.desc()).all()

    print(f"ç§å­è¯ 'connector' çš„çŸ­è¯­æ•°: {len(phrases)}")
    for p in phrases[:10]:
        print(f"  - {p.phrase} (é¢‘æ¬¡:{p.frequency})")
```

## ğŸ“Š æ•°æ®ç»Ÿè®¡æ‘˜è¦

### å¯¼å…¥æ•°æ®æ¦‚å†µ
- **æ€»è®°å½•æ•°**: 55,275æ¡
- **æ•°æ®æºåˆ†å¸ƒ**:
  - SEMRUSH: 8,973æ¡ (16.2%) - æœ‰æœç´¢é‡æ•°æ®
  - Dropdown: 45,866æ¡ (83.0%) - ä¸‹æ‹‰è¯
  - Related Search: 436æ¡ (0.8%) - ç›¸å…³æœç´¢

### é«˜é¢‘çŸ­è¯­Top 5
1. how to change a tire - 1,830,000
2. image search techniques - 1,000,000
3. list crawler - 550,000
4. online casinos toptiercasinos.com 2025 - 368,000
5. 213 area code - 368,000

### æ•°æ®è´¨é‡
- æœ‰æœç´¢é‡çš„è®°å½•: 8,973æ¡ (16.2%)
- å¹³å‡é¢‘æ¬¡: 2,011
- å½“å‰çŠ¶æ€: å…¨éƒ¨æ ‡è®°ä¸º `unseen`ï¼Œç­‰å¾…Phase 2èšç±»å¤„ç†

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ä¿®æ”¹æ•°æ®åº“å¯†ç ï¼Ÿ
ä¿®æ”¹ `.env` æ–‡ä»¶ä¸­çš„ `DB_PASSWORD=123456`

### Q2: å¦‚ä½•ä½¿ç”¨SQLiteä»£æ›¿MySQLï¼Ÿ
ä¿®æ”¹ `.env` æ–‡ä»¶:
```
DB_TYPE=sqlite
```
ç„¶åé‡æ–°è¿è¡Œ `python init_database.py`

### Q3: æ•°æ®å¯¼å…¥å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
```bash
# 1. æ£€æŸ¥æ•°æ®åº“è¿æ¥
mysql -u root -p123456 -e "SELECT 1;"

# 2. æ£€æŸ¥æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
python init_database.py

# 3. ä½¿ç”¨dry-runæ¨¡å¼æµ‹è¯•
python scripts/run_phase1_import.py --dry-run
```

### Q4: å¦‚ä½•å¤‡ä»½æ•°æ®ï¼Ÿ
```bash
# å¤‡ä»½æ•°æ®åº“
mysqldump -u root -p123456 keyword_clustering > backup.sql

# æˆ–å¤åˆ¶CSVæ–‡ä»¶
copy data\processed\integrated_round1.csv backup\
```

### Q5: å¦‚ä½•æ¢å¤æ•°æ®ï¼Ÿ
```bash
# ä»SQLå¤‡ä»½æ¢å¤
mysql -u root -p123456 keyword_clustering < backup.sql
```

## ğŸ“Œ ä¸‹ä¸€æ­¥

æ•°æ®å·²å‡†å¤‡å®Œæˆï¼Œå¯ä»¥è¿›è¡Œï¼š
1. **Phase 2**: è¿è¡Œ `python scripts/run_phase2_clustering.py` è¿›è¡Œå¤§ç»„èšç±»
2. **æ•°æ®åˆ†æ**: ä½¿ç”¨ `view_phase1_results.py` æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
3. **è‡ªå®šä¹‰æŸ¥è¯¢**: å‚è€ƒä¸Šè¿°ä»£ç ç¤ºä¾‹ç¼–å†™è‡ªå·±çš„æŸ¥è¯¢è„šæœ¬

## ğŸ“š ç›¸å…³æ–‡ä»¶

- `scripts/run_phase1_import.py` - Phase 1ä¸»è„šæœ¬
- `view_phase1_results.py` - æŸ¥çœ‹ç»“æœè„šæœ¬
- `core/data_integration.py` - æ•°æ®æ•´åˆæ¨¡å—
- `storage/repository.py` - æ•°æ®åº“æ“ä½œæ¨¡å—
- `storage/models.py` - æ•°æ®è¡¨æ¨¡å‹
- `.env` - é…ç½®æ–‡ä»¶ï¼ˆåŒ…å«æ•°æ®åº“å¯†ç ï¼‰
