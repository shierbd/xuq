# ç³»ç»Ÿæ¶æ„ä¼˜åŒ– - æ‰§è¡Œæ¸…å•

**æ—¥æœŸ**: 2026-01-05
**åˆ†æ”¯**: `refactor/eliminate-duplicate-segmentation`

---

## âœ… å‡†å¤‡å·¥ä½œ

- [ ] å¤‡ä»½æ•°æ®åº“
  ```bash
  cp data/xuq_keywords.db data/xuq_keywords.db.backup_20260105
  ```

- [ ] åˆ›å»ºæ–°åˆ†æ”¯
  ```bash
  git checkout -b refactor/eliminate-duplicate-segmentation
  ```

- [ ] ç¡®è®¤Phase 0å½“å‰é…ç½®
  - [ ] æ£€æŸ¥`extract_ngrams`é»˜è®¤å€¼
  - [ ] ç¡®è®¤`min_ngram_frequency`é»˜è®¤å€¼

---

## ğŸ”§ æ ¸å¿ƒæ”¹é€ ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

### 1ï¸âƒ£ Phase 0: ç¡®ä¿N-gramæå–å¼€å¯

**æ–‡ä»¶**: `ui/pages/phase0_expansion.py`

- [ ] ä¿®æ”¹é»˜è®¤å€¼
  ```python
  extract_ngrams = st.checkbox(
      "æå–çŸ­è¯­ï¼ˆN-gramsï¼‰",
      value=True,  # â† æ”¹ä¸ºTrue
      ...
  )
  ```

- [ ] å¢åŠ ç»Ÿè®¡æ˜¾ç¤º
  ```python
  # æ˜¾ç¤ºå•è¯/çŸ­è¯­åˆ†å¸ƒ
  st.metric("å•è¯æ•°é‡ï¼ˆ1-gramï¼‰", word_count_1)
  st.metric("çŸ­è¯­æ•°é‡ï¼ˆ2-6-gramï¼‰", ngram_count)
  ```

**æµ‹è¯•**:
- [ ] æ‰§è¡Œåˆ†è¯ï¼Œç¡®è®¤`word_segments`è¡¨åŒ…å«çŸ­è¯­
- [ ] æ£€æŸ¥`word_count`å­—æ®µï¼ˆ1=å•è¯ï¼Œ2/3/4/5/6=çŸ­è¯­ï¼‰

---

### 2ï¸âƒ£ Phase 2E Tab 0: ä»word_segmentsè¯»å–

**æ–‡ä»¶**: `ui/pages/phase2e_junyan.py`

- [ ] æ›¿æ¢åˆ†è¯é€»è¾‘ï¼ˆlines 121-155ï¼‰
  ```python
  # âŒ åˆ é™¤é‡å¤åˆ†è¯
  # if segment_btn:
  #     for phrase in phrases:
  #         words = segment_keywords(phrase)

  # âœ… ä»æ•°æ®åº“åŠ è½½
  if load_btn:
      with WordSegmentRepository() as ws_repo:
          word_counter, ngram_counter, ... = ws_repo.load_segmentation_results(...)

      # åˆå¹¶å•è¯å’ŒçŸ­è¯­
      all_candidates = Counter()
      all_candidates.update(word_counter)
      all_candidates.update(ngram_counter)
  ```

- [ ] ä¿®æ”¹æŒ‰é’®æ–‡å­—
  ```python
  load_btn = st.button(
      "ğŸ“¥ ä»Phase 0åŠ è½½åˆ†è¯ç»“æœ",  # â† æ”¹å
      type="primary"
  )
  ```

- [ ] å¢åŠ æ–°é²œåº¦æ£€æŸ¥
  ```python
  if not check_segmentation_freshness():
      st.error("è¯·å…ˆå‰å¾€ Phase 0 Tab 1 æ‰§è¡Œåˆ†è¯")
      return
  ```

**æµ‹è¯•**:
- [ ] åŠ è½½é€Ÿåº¦ < 3ç§’
- [ ] å€™é€‰ç§å­è¯åŒ…æ‹¬å•è¯å’ŒçŸ­è¯­
- [ ] æ˜¾ç¤ºæ­£ç¡®çš„é¢‘æ¬¡

---

### 3ï¸âƒ£ Phase 4: ä»word_segmentsè¯»å–

**æ–‡ä»¶**: `core/token_extraction.py`

- [ ] æ–°å¢å‡½æ•°
  ```python
  def extract_tokens_from_word_segments(min_frequency: int = 3):
      """ä»word_segmentsæå–Tokens"""
      with WordSegmentRepository() as ws_repo:
          word_counter, ngram_counter, ... = ws_repo.load_segmentation_results(...)

      all_tokens = Counter()
      all_tokens.update(word_counter)
      all_tokens.update(ngram_counter)

      return all_tokens.most_common()
  ```

**æ–‡ä»¶**: `ui/pages/phase4_tokens.py`

- [ ] åˆ é™¤é‡‡æ ·åŠŸèƒ½ï¼ˆlines 70-102ï¼‰
  ```python
  # âŒ åˆ é™¤
  # sample_size = st.number_input(...)
  ```

- [ ] ç®€åŒ–å‚æ•°
  ```python
  min_frequency = st.slider("æœ€å°è¯é¢‘", 1, 20, 3)
  ```

- [ ] è°ƒç”¨æ–°å‡½æ•°
  ```python
  tokens = extract_tokens_from_word_segments(min_frequency)
  ```

**æµ‹è¯•**:
- [ ] åŠ è½½é€Ÿåº¦ < 3ç§’
- [ ] TokensåŒ…æ‹¬å•è¯å’ŒçŸ­è¯­
- [ ] LLMåˆ†ç±»æ­£å¸¸å·¥ä½œ

---

### 4ï¸âƒ£ åˆ é™¤Phase 2D

**æ–‡ä»¶**: `web_ui.py`

- [ ] åˆ é™¤å¯¼èˆªé¡¹ï¼ˆline 146ï¼‰
  ```python
  # âŒ åˆ é™¤è¿™ä¸€è¡Œ
  # "ğŸ¯ Phase 2D: æ¨¡æ¿å‘ç°",
  ```

- [ ] åˆ é™¤è·¯ç”±ï¼ˆlines 339-341ï¼‰
  ```python
  # âŒ åˆ é™¤è¿™ä¸ªelifå—
  # elif page == "ğŸ¯ Phase 2D: æ¨¡æ¿å‘ç°":
  #     from ui.pages import phase2d_templates
  #     phase2d_templates.render_page()
  ```

- [ ] ä¿®æ”¹Phase 2å‘½å
  ```python
  "ğŸ”„ Phase 2A: å¤§ç»„èšç±»-HDBSCAN",  # â† æ”¹å
  "ğŸ¯ Phase 2E: å¤§ç»„èšç±»-å›è¨€æ–¹æ³•",  # â† æ”¹å
  ```

**å¯é€‰**ï¼š
- [ ] åˆ é™¤æ–‡ä»¶ï¼š`ui/pages/phase2d_templates.py`
- [ ] ä¿ç•™åº•å±‚ä»£ç ï¼š`core/template_discovery.py`ï¼ˆä½œä¸ºå‚è€ƒï¼‰

**æµ‹è¯•**:
- [ ] å¯¼èˆªæ­£å¸¸è·³è½¬
- [ ] æ‰€æœ‰é¡µé¢éƒ½èƒ½è®¿é—®
- [ ] Phase 2Dä¸å†å‡ºç°

---

### 5ï¸âƒ£ æ–°å¢å·¥å…·å‡½æ•°

**æ–‡ä»¶**: `utils/segmentation_check.py`ï¼ˆæ–°å»ºï¼‰

- [ ] åˆ›å»ºæ£€æŸ¥å‡½æ•°
  ```python
  def check_segmentation_freshness() -> bool:
      """æ£€æŸ¥åˆ†è¯ç»“æœæ˜¯å¦å¯ç”¨"""
      with PhraseRepository() as phrase_repo:
          total_phrases = phrase_repo.session.query(Phrase).count()

      with WordSegmentRepository() as ws_repo:
          stats = ws_repo.get_statistics()
          total_words = stats.get('total_words', 0)

      if total_words == 0:
          st.error("âŒ æœªæ‰¾åˆ°åˆ†è¯ç»“æœï¼")
          return False

      st.info(f"ğŸ“Š {total_words} ä¸ªè¯/çŸ­è¯­")
      return True
  ```

- [ ] åœ¨Phase 2Eå’ŒPhase 4ä¸­ä½¿ç”¨

---

## ğŸ§ª æµ‹è¯•æ¸…å•

### å®Œæ•´æµç¨‹æµ‹è¯•
- [ ] Phase 1: å¯¼å…¥CSVæ•°æ®
- [ ] Phase 0 Tab 1: æ‰§è¡Œåˆ†è¯ï¼ˆç¡®è®¤åŒ…å«çŸ­è¯­ï¼‰
- [ ] Phase 2E Tab 0: åŠ è½½ç§å­è¯ï¼ˆç¡®è®¤æ— é‡å¤åˆ†è¯ï¼‰
- [ ] Phase 2E: æå–æ¨¡æ¿å’Œå˜é‡
- [ ] Phase 4: æå–Tokensï¼ˆç¡®è®¤æ— é‡å¤åˆ†è¯ï¼‰
- [ ] Phase 4: LLMåˆ†ç±»

### æ€§èƒ½æµ‹è¯•
- [ ] Phase 0åˆ†è¯è€—æ—¶ï¼š____åˆ†é’Ÿï¼ˆ125Kæ•°æ®ï¼‰
- [ ] Phase 2E Tab 0åŠ è½½ï¼š____ç§’
- [ ] Phase 4åŠ è½½ï¼š____ç§’
- [ ] æ€»ä½“è€—æ—¶å¯¹æ¯”ï¼šä¼˜åŒ–å‰ ____ vs ä¼˜åŒ–å ____

### æ•°æ®ä¸€è‡´æ€§
- [ ] åŒä¸€ä¸ªè¯åœ¨Phase 0ã€2Eã€4æ˜¾ç¤ºçš„é¢‘æ¬¡ä¸€è‡´
- [ ] å¢é‡åˆ†è¯åé¢‘æ¬¡æ­£ç¡®ç´¯åŠ 
- [ ] çŸ­è¯­æ­£ç¡®æ˜¾ç¤ºï¼ˆå¦‚"running shoes"ï¼‰

---

## ğŸ“ æäº¤æ¸…å•

- [ ] æäº¤ä»£ç 
  ```bash
  git add .
  git commit -m "Refactor: æ¶ˆé™¤é‡å¤åˆ†è¯ï¼Œç»Ÿä¸€ä»word_segmentsè¯»å–"
  ```

- [ ] æ¨é€åˆ°GitHub
  ```bash
  git push origin refactor/eliminate-duplicate-segmentation
  ```

- [ ] åˆ›å»ºPull Request
  - æ ‡é¢˜ï¼š`Refactor: æ¶ˆé™¤é‡å¤åˆ†è¯æ“ä½œ`
  - æè¿°ï¼šå¼•ç”¨`docs/ç³»ç»Ÿæ¶æ„ä¼˜åŒ–è®¡åˆ’.md`

---

## ğŸ“Š éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] Phase 0åˆ†è¯åï¼Œ`word_segments`åŒ…å«å•è¯å’ŒçŸ­è¯­ âœ…
- [ ] Phase 2E Tab 0èƒ½åŠ è½½å•è¯å’ŒçŸ­è¯­ä½œä¸ºç§å­è¯ âœ…
- [ ] Phase 4èƒ½åŠ è½½Tokensï¼ˆå•è¯+çŸ­è¯­ï¼‰âœ…
- [ ] Phase 2Då·²åˆ é™¤ï¼Œå¯¼èˆªæ­£å¸¸ âœ…

### æ€§èƒ½éªŒæ”¶
- [ ] Phase 2E Tab 0åŠ è½½ < 3ç§’ âœ…
- [ ] Phase 4åŠ è½½ < 3ç§’ âœ…
- [ ] æ€»ä½“è€—æ—¶å‡å°‘ > 50% âœ…

### æ•°æ®è´¨é‡
- [ ] è¯é¢‘ç»Ÿè®¡å‡†ç¡® âœ…
- [ ] çŸ­è¯­æå–è´¨é‡è‰¯å¥½ âœ…
- [ ] æ— æ•°æ®ä¸¢å¤± âœ…

---

**å®Œæˆæ—¶é—´**: ____________
**æµ‹è¯•äºº**: ____________
**å¤‡æ³¨**: ____________
