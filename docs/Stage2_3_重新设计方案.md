# Stage 2/3 é‡æ–°è®¾è®¡æ–¹æ¡ˆ

**æ—¥æœŸ**: 2026-02-02
**ç›®æ ‡**: æ¶ˆé™¤677ä¸ªå¾®å‹ç°‡ï¼Œå°†ç°‡æ•°é‡ä»1,349é™ä½åˆ°400-600

---

## ğŸ¯ æ ¸å¿ƒæ€è·¯

### å½“å‰é—®é¢˜

**Stage 2/3 åˆ¶é€ å¾®å‹ç°‡**ï¼š
```
Stage 1: ç”Ÿæˆ215ä¸ªä¸»è¦ç°‡ + 10,957ä¸ªå™ªéŸ³ç‚¹
Stage 2: å¯¹å™ªéŸ³ç‚¹èšç±» â†’ åˆ›å»º461ä¸ªæ¬¡çº§ç°‡ + 7,299ä¸ªå™ªéŸ³ç‚¹
Stage 3: å¯¹å™ªéŸ³ç‚¹èšç±» â†’ åˆ›å»º677ä¸ªå¾®å‹ç°‡ + 4,631ä¸ªå™ªéŸ³ç‚¹

ç»“æœ: 1,349ä¸ªç°‡ï¼ˆå¤ªå¤šï¼ï¼‰
```

### æ–°è®¾è®¡

**å½’å¹¶ + è´¨é‡é—¨æ§**ï¼š
```
Stage 1: ç”Ÿæˆä¸»è¦ç°‡ï¼ˆä¿æŒä¸å˜ï¼‰
Stage 2: å½’å¹¶åˆ°æœ€è¿‘ä¸»é¢˜ç°‡ï¼ˆä¸åˆ›å»ºæ–°ç°‡ï¼‰
Stage 3: è´¨é‡é—¨æ§ï¼ˆåªä¿ç•™å¯å‘½åç°‡ï¼‰

é¢„æœŸ: 300-500ä¸ªç°‡
```

---

## ğŸ“ Stage 2: å½’å¹¶ç­–ç•¥

### ç®—æ³•è®¾è®¡

**ç›®æ ‡**: å°†å™ªéŸ³ç‚¹å½’å¹¶åˆ°æœ€è¿‘çš„ä¸»é¢˜ç°‡ï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°ç°‡

**æ­¥éª¤**:

1. **è®¡ç®—ç°‡ä¸­å¿ƒï¼ˆCentroidsï¼‰**
   ```python
   for cluster_id in stage1_clusters:
       cluster_points = embeddings[labels == cluster_id]
       centroid = np.mean(cluster_points, axis=0)
       centroids[cluster_id] = centroid
   ```

2. **å¯¹æ¯ä¸ªå™ªéŸ³ç‚¹æ‰¾æœ€è¿‘ç°‡**
   ```python
   for noise_point in stage1_noise:
       # è®¡ç®—ä¸æ‰€æœ‰ç°‡ä¸­å¿ƒçš„ç›¸ä¼¼åº¦
       similarities = cosine_similarity(noise_point, centroids)

       # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ç°‡
       nearest_cluster = argmax(similarities)
       max_similarity = similarities[nearest_cluster]

       # å¦‚æœç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼Œå½’å¹¶
       if max_similarity > threshold:
           assign_to_cluster(noise_point, nearest_cluster)
       else:
           keep_as_noise(noise_point)
   ```

3. **é˜ˆå€¼è®¾ç½®**
   - **é«˜é˜ˆå€¼ (0.7-0.8)**: ä¸¥æ ¼å½’å¹¶ï¼Œä¿ç•™æ›´å¤šå™ªéŸ³
   - **ä¸­é˜ˆå€¼ (0.5-0.6)**: å¹³è¡¡å½’å¹¶ï¼Œæ¨è
   - **ä½é˜ˆå€¼ (0.3-0.4)**: æ¿€è¿›å½’å¹¶ï¼Œå¯èƒ½è¯¯å½’å¹¶

   **å»ºè®®**: ä» 0.5 å¼€å§‹ï¼Œæ ¹æ®ç»“æœè°ƒæ•´

### é¢„æœŸæ•ˆæœ

**å½’å¹¶å‰**:
- Stage 1: 215ä¸ªä¸»è¦ç°‡ + 10,957ä¸ªå™ªéŸ³ç‚¹

**å½’å¹¶å** (é˜ˆå€¼=0.5):
- é¢„è®¡å½’å¹¶: 6,000-8,000ä¸ªç‚¹
- å‰©ä½™å™ªéŸ³: 3,000-5,000ä¸ªç‚¹
- ä¸å†åˆ›å»º461+677=1,138ä¸ªæ–°ç°‡

---

## ğŸ” Stage 3: è´¨é‡é—¨æ§

### ç®—æ³•è®¾è®¡

**ç›®æ ‡**: åªä¿ç•™"å¯å‘½å"çš„é«˜è´¨é‡ç°‡

**è´¨é‡æŒ‡æ ‡**:

#### 1. ç°‡å†…ä¸€è‡´æ€§ï¼ˆCohesionï¼‰

**å®šä¹‰**: ç°‡å†…ç‚¹ä¹‹é—´çš„å¹³å‡ç›¸ä¼¼åº¦

```python
def calculate_cohesion(cluster_points):
    """è®¡ç®—ç°‡å†…ä¸€è‡´æ€§"""
    n = len(cluster_points)
    if n < 2:
        return 0.0

    # è®¡ç®—æ‰€æœ‰ç‚¹å¯¹ä¹‹é—´çš„ç›¸ä¼¼åº¦
    similarities = []
    for i in range(n):
        for j in range(i+1, n):
            sim = cosine_similarity(cluster_points[i], cluster_points[j])
            similarities.append(sim)

    return np.mean(similarities)
```

**é˜ˆå€¼**: cohesion > 0.5ï¼ˆä¸­ç­‰ä¸€è‡´æ€§ï¼‰

#### 2. ç°‡å¤§å°ï¼ˆSizeï¼‰

**å®šä¹‰**: ç°‡ä¸­çš„å•†å“æ•°é‡

```python
def check_size(cluster_size, min_size=3):
    """æ£€æŸ¥ç°‡å¤§å°"""
    return cluster_size >= min_size
```

**é˜ˆå€¼**: size >= 3ï¼ˆè‡³å°‘3ä¸ªå•†å“ï¼‰

#### 3. ç°‡åŒºåˆ†åº¦ï¼ˆSeparationï¼‰

**å®šä¹‰**: ç°‡ä¸­å¿ƒä¸æœ€è¿‘ç°‡ä¸­å¿ƒçš„è·ç¦»

```python
def calculate_separation(cluster_centroid, all_centroids):
    """è®¡ç®—ç°‡åŒºåˆ†åº¦"""
    # è®¡ç®—ä¸æ‰€æœ‰å…¶ä»–ç°‡ä¸­å¿ƒçš„è·ç¦»
    distances = []
    for other_centroid in all_centroids:
        if not np.array_equal(cluster_centroid, other_centroid):
            dist = 1 - cosine_similarity(cluster_centroid, other_centroid)
            distances.append(dist)

    # è¿”å›æœ€è¿‘è·ç¦»
    return min(distances) if distances else 1.0
```

**é˜ˆå€¼**: separation > 0.3ï¼ˆä¸æœ€è¿‘ç°‡æœ‰æ˜æ˜¾åŒºåˆ†ï¼‰

### è´¨é‡é—¨æ§æµç¨‹

```python
def quality_gate(cluster_id, cluster_points, all_centroids):
    """è´¨é‡é—¨æ§"""
    # æ£€æŸ¥ç°‡å¤§å°
    if len(cluster_points) < 3:
        return False, "size_too_small"

    # æ£€æŸ¥ç°‡å†…ä¸€è‡´æ€§
    cohesion = calculate_cohesion(cluster_points)
    if cohesion < 0.5:
        return False, "low_cohesion"

    # æ£€æŸ¥ç°‡åŒºåˆ†åº¦
    centroid = np.mean(cluster_points, axis=0)
    separation = calculate_separation(centroid, all_centroids)
    if separation < 0.3:
        return False, "low_separation"

    return True, "passed"
```

### é¢„æœŸæ•ˆæœ

**é—¨æ§å‰**:
- 215ä¸ªä¸»è¦ç°‡ï¼ˆStage 1ï¼‰

**é—¨æ§å**:
- é¢„è®¡ä¿ç•™: 150-200ä¸ªé«˜è´¨é‡ç°‡
- æ·˜æ±°: 15-65ä¸ªä½è´¨é‡ç°‡
- æ·˜æ±°çš„ç°‡ä¸­çš„å•†å“æ ‡è®°ä¸ºå™ªéŸ³

---

## ğŸ“Š æ•´ä½“æµç¨‹

### å®Œæ•´æµç¨‹å›¾

```
è¾“å…¥: 15,792ä¸ªå•†å“

â†“

[Stage 1] ä¸»è¦èšç±» (min_size=10)
  â†’ 215ä¸ªä¸»è¦ç°‡
  â†’ 10,957ä¸ªå™ªéŸ³ç‚¹

â†“

[Stage 2] å½’å¹¶ç­–ç•¥ (threshold=0.5)
  â†’ å½’å¹¶ 6,000-8,000ä¸ªç‚¹åˆ°ä¸»è¦ç°‡
  â†’ å‰©ä½™ 3,000-5,000ä¸ªå™ªéŸ³ç‚¹
  â†’ ä¸åˆ›å»ºæ–°ç°‡

â†“

[Stage 3] è´¨é‡é—¨æ§
  â†’ æ£€æŸ¥215ä¸ªç°‡çš„è´¨é‡
  â†’ ä¿ç•™ 150-200ä¸ªé«˜è´¨é‡ç°‡
  â†’ æ·˜æ±° 15-65ä¸ªä½è´¨é‡ç°‡

â†“

è¾“å‡º: 150-200ä¸ªé«˜è´¨é‡ç°‡ + 3,000-5,000ä¸ªå™ªéŸ³ç‚¹
```

### é¢„æœŸç»“æœ

| æŒ‡æ ‡ | å½“å‰ (Phase 2) | é¢„æœŸ (Stage 2/3é‡æ–°è®¾è®¡) | æ”¹å–„ |
|------|---------------|------------------------|------|
| **æ€»ç°‡æ•°** | 1,349 | 150-200 | -85% to -89% |
| **ä¸»è¦ç°‡** | 211 (15.6%) | 150-200 (100%) | +84% |
| **å¾®å‹ç°‡** | 677 (50.2%) | 0 (0%) | -100% |
| **å™ªéŸ³ç‚¹** | 4,631 (29.3%) | 3,000-5,000 (19-32%) | å¯æ¥å— |

---

## ğŸ”§ å®ç°ç»†èŠ‚

### å…³é”®å‡½æ•°

#### 1. è®¡ç®—ç°‡ä¸­å¿ƒ
```python
def calculate_cluster_centroids(
    embeddings: np.ndarray,
    labels: np.ndarray
) -> Dict[int, np.ndarray]:
    """è®¡ç®—æ¯ä¸ªç°‡çš„ä¸­å¿ƒå‘é‡"""
    centroids = {}
    unique_labels = set(labels) - {-1}

    for label in unique_labels:
        cluster_mask = labels == label
        cluster_points = embeddings[cluster_mask]
        centroid = np.mean(cluster_points, axis=0)
        centroids[label] = centroid

    return centroids
```

#### 2. å½’å¹¶å™ªéŸ³ç‚¹
```python
def merge_noise_to_clusters(
    embeddings: np.ndarray,
    labels: np.ndarray,
    centroids: Dict[int, np.ndarray],
    threshold: float = 0.5
) -> np.ndarray:
    """å°†å™ªéŸ³ç‚¹å½’å¹¶åˆ°æœ€è¿‘çš„ç°‡"""
    from sklearn.metrics.pairwise import cosine_similarity

    new_labels = labels.copy()
    noise_mask = labels == -1
    noise_indices = np.where(noise_mask)[0]

    for idx in noise_indices:
        noise_point = embeddings[idx].reshape(1, -1)

        # è®¡ç®—ä¸æ‰€æœ‰ç°‡ä¸­å¿ƒçš„ç›¸ä¼¼åº¦
        max_sim = -1
        best_cluster = -1

        for cluster_id, centroid in centroids.items():
            centroid_reshaped = centroid.reshape(1, -1)
            sim = cosine_similarity(noise_point, centroid_reshaped)[0][0]

            if sim > max_sim:
                max_sim = sim
                best_cluster = cluster_id

        # å¦‚æœç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼Œå½’å¹¶
        if max_sim > threshold:
            new_labels[idx] = best_cluster

    return new_labels
```

#### 3. è´¨é‡é—¨æ§
```python
def apply_quality_gate(
    embeddings: np.ndarray,
    labels: np.ndarray,
    min_size: int = 3,
    min_cohesion: float = 0.5,
    min_separation: float = 0.3
) -> np.ndarray:
    """åº”ç”¨è´¨é‡é—¨æ§ï¼Œæ·˜æ±°ä½è´¨é‡ç°‡"""
    from sklearn.metrics.pairwise import cosine_similarity

    new_labels = labels.copy()
    unique_labels = set(labels) - {-1}

    # è®¡ç®—æ‰€æœ‰ç°‡ä¸­å¿ƒ
    centroids = calculate_cluster_centroids(embeddings, labels)

    for cluster_id in unique_labels:
        cluster_mask = labels == cluster_id
        cluster_points = embeddings[cluster_mask]

        # æ£€æŸ¥ç°‡å¤§å°
        if len(cluster_points) < min_size:
            new_labels[cluster_mask] = -1
            continue

        # æ£€æŸ¥ç°‡å†…ä¸€è‡´æ€§
        cohesion = calculate_cohesion(cluster_points)
        if cohesion < min_cohesion:
            new_labels[cluster_mask] = -1
            continue

        # æ£€æŸ¥ç°‡åŒºåˆ†åº¦
        separation = calculate_separation(
            centroids[cluster_id],
            list(centroids.values())
        )
        if separation < min_separation:
            new_labels[cluster_mask] = -1
            continue

    return new_labels
```

---

## ğŸ¯ å‚æ•°è°ƒä¼˜

### å…³é”®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è°ƒä¼˜èŒƒå›´ | å½±å“ |
|------|--------|---------|------|
| **merge_threshold** | 0.5 | 0.4-0.7 | å½’å¹¶ä¸¥æ ¼ç¨‹åº¦ |
| **min_cohesion** | 0.5 | 0.4-0.6 | ç°‡å†…ä¸€è‡´æ€§è¦æ±‚ |
| **min_separation** | 0.3 | 0.2-0.4 | ç°‡åŒºåˆ†åº¦è¦æ±‚ |
| **min_size** | 3 | 3-5 | æœ€å°ç°‡å¤§å° |

### è°ƒä¼˜ç­–ç•¥

**å¦‚æœç°‡å¤ªå¤š** (>500):
- æé«˜ merge_threshold (0.5 â†’ 0.6)
- æé«˜ min_cohesion (0.5 â†’ 0.6)
- æé«˜ min_separation (0.3 â†’ 0.4)

**å¦‚æœç°‡å¤ªå°‘** (<300):
- é™ä½ merge_threshold (0.5 â†’ 0.4)
- é™ä½ min_cohesion (0.5 â†’ 0.4)
- é™ä½ min_separation (0.3 â†’ 0.2)

---

## ğŸ“‹ å®æ–½è®¡åˆ’

### ç¬¬ä¸€æ­¥ï¼šå®ç°æ ¸å¿ƒå‡½æ•°
- [ ] calculate_cluster_centroids()
- [ ] merge_noise_to_clusters()
- [ ] calculate_cohesion()
- [ ] calculate_separation()
- [ ] apply_quality_gate()

### ç¬¬äºŒæ­¥ï¼šé›†æˆåˆ°èšç±»æœåŠ¡
- [ ] ä¿®æ”¹ perform_three_stage_clustering()
- [ ] æ·»åŠ  use_merge_strategy å‚æ•°
- [ ] æ·»åŠ  use_quality_gate å‚æ•°

### ç¬¬ä¸‰æ­¥ï¼šæµ‹è¯•éªŒè¯
- [ ] è¿è¡Œæµ‹è¯•ï¼ˆé»˜è®¤å‚æ•°ï¼‰
- [ ] åˆ†æç»“æœ
- [ ] è°ƒä¼˜å‚æ•°ï¼ˆå¦‚éœ€è¦ï¼‰

### ç¬¬å››æ­¥ï¼šæ–‡æ¡£å’Œæäº¤
- [ ] æ›´æ–°æ–‡æ¡£
- [ ] ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
- [ ] æäº¤åˆ°Git

---

**åˆ›å»ºè€…**: Claude Sonnet 4.5
**åˆ›å»ºæ—¥æœŸ**: 2026-02-02
**é¢„è®¡å®æ–½æ—¶é—´**: 2-3å°æ—¶
